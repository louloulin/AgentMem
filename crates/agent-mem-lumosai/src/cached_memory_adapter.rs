//! Cached Memory Adapter - å¸¦ç¼“å­˜çš„AgentMem Backend
//!
//! å®ç°å¤šçº§ç¼“å­˜ï¼ˆL1å†…å­˜ç¼“å­˜ + L2 Redisç¼“å­˜ï¼‰ä»¥å¤§å¹…æå‡æ£€ç´¢æ€§èƒ½

use agent_mem::{AddMemoryOptions, GetAllOptions, Memory as AgentMemApi, SearchOptions};
use async_trait::async_trait;
use lumosai_core::llm::Message as LumosMessage;
use lumosai_core::llm::Role as LumosRole;
use lumosai_core::memory::{Memory as LumosMemory, MemoryConfig};
use lumosai_core::Result as LumosResult;
use lru::LruCache;
use std::collections::hash_map::DefaultHasher;
use std::hash::{Hash, Hasher};
use std::num::NonZeroUsize;
use std::sync::Arc;
use std::time::Duration;
use tokio::sync::RwLock;
use tracing::{debug, info, warn};

/// ç¼“å­˜é…ç½®
#[derive(Debug, Clone)]
pub struct CacheConfig {
    /// å¯ç”¨L1å†…å­˜ç¼“å­˜
    pub enable_l1_cache: bool,
    /// L1ç¼“å­˜æœ€å¤§æ¡ç›®æ•°
    pub l1_cache_max_size: usize,
    /// å¯ç”¨L2 Redisç¼“å­˜
    pub enable_l2_cache: bool,
    /// L2ç¼“å­˜TTLï¼ˆç§’ï¼‰
    pub l2_cache_ttl_seconds: u64,
}

impl Default for CacheConfig {
    fn default() -> Self {
        Self {
            enable_l1_cache: true,
            l1_cache_max_size: 1000,
            enable_l2_cache: false, // éœ€è¦Redisè¿æ¥ï¼Œé»˜è®¤å…³é—­
            l2_cache_ttl_seconds: 300, // 5åˆ†é’Ÿ
        }
    }
}

/// å¸¦ç¼“å­˜çš„AgentMem Backend
pub struct CachedAgentMemBackend {
    /// åº•å±‚AgentMem API
    memory_api: Arc<AgentMemApi>,
    /// Agent ID
    agent_id: String,
    /// User ID
    user_id: String,
    /// L1å†…å­˜ç¼“å­˜ï¼ˆLRUï¼‰
    l1_cache: Arc<RwLock<LruCache<String, Vec<LumosMessage>>>>,
    /// ç¼“å­˜é…ç½®
    config: CacheConfig,
}

impl CachedAgentMemBackend {
    /// åˆ›å»ºæ–°çš„ç¼“å­˜é€‚é…å™¨
    pub fn new(
        memory_api: Arc<AgentMemApi>,
        agent_id: String,
        user_id: String,
        config: CacheConfig,
    ) -> Self {
        let cache_size = NonZeroUsize::new(config.l1_cache_max_size)
            .unwrap_or(NonZeroUsize::new(1000).unwrap());
        let l1_cache = Arc::new(RwLock::new(LruCache::new(cache_size)));

        Self {
            memory_api,
            agent_id,
            user_id,
            l1_cache,
            config,
        }
    }

    /// ä½¿ç”¨é»˜è®¤é…ç½®åˆ›å»º
    pub fn with_defaults(
        memory_api: Arc<AgentMemApi>,
        agent_id: String,
        user_id: String,
    ) -> Self {
        Self::new(memory_api, agent_id, user_id, CacheConfig::default())
    }

    /// æ„å»ºç¼“å­˜é”®
    fn build_cache_key(&self, config: &MemoryConfig) -> String {
        let mut hasher = DefaultHasher::new();
        self.agent_id.hash(&mut hasher);
        self.user_id.hash(&mut hasher);
        config.query.hash(&mut hasher);
        config.last_messages.hash(&mut hasher);
        config.namespace.hash(&mut hasher);
        config.store_id.hash(&mut hasher);
        format!("cache:{}", hasher.finish())
    }

    /// ä»AgentMemæ£€ç´¢ï¼ˆæ— ç¼“å­˜ï¼‰
    async fn retrieve_from_backend(
        &self,
        config: &MemoryConfig,
    ) -> LumosResult<Vec<LumosMessage>> {
        use crate::memory_adapter::AgentMemBackend;
        let backend = AgentMemBackend::new(
            self.memory_api.clone(),
            self.agent_id.clone(),
            self.user_id.clone(),
        );
        backend.retrieve(config).await
    }

    /// è½¬æ¢MemoryItemä¸ºLumosMessageï¼ˆä»memory_adapterå¤åˆ¶é€»è¾‘ï¼‰
    fn convert_to_messages(&self, items: Vec<agent_mem::MemoryItem>) -> Vec<LumosMessage> {
        items
            .into_iter()
            .filter_map(|mem| {
                let role_str = mem
                    .metadata
                    .get("role")
                    .and_then(|v| v.as_str())
                    .unwrap_or("user");

                let role = match role_str {
                    "system" => LumosRole::System,
                    "assistant" => LumosRole::Assistant,
                    "tool" => LumosRole::Tool,
                    _ => LumosRole::User,
                };

                let content = if mem.content.starts_with('[') {
                    mem.content
                        .splitn(2, "]: ")
                        .nth(1)
                        .unwrap_or(&mem.content)
                        .to_string()
                } else {
                    mem.content
                };

                Some(LumosMessage {
                    role,
                    content,
                    metadata: None,
                    name: None,
                })
            })
            .collect()
    }
}

#[async_trait]
impl LumosMemory for CachedAgentMemBackend {
    async fn store(&self, message: &LumosMessage) -> LumosResult<()> {
        // å­˜å‚¨æ“ä½œä¸ç¼“å­˜ï¼Œç›´æ¥è°ƒç”¨åº•å±‚API
        // ä½†éœ€è¦ä½¿ç›¸å…³ç¼“å­˜å¤±æ•ˆ
        let cache_key_prefix = format!("cache:{}:{}", self.agent_id, self.user_id);
        
        // æ¸…é™¤ç›¸å…³ç¼“å­˜ï¼ˆç®€åŒ–å®ç°ï¼šæ¸…é™¤æ‰€æœ‰è¯¥agent/userçš„ç¼“å­˜ï¼‰
        if self.config.enable_l1_cache {
            let mut cache = self.l1_cache.write().await;
            // æ¸…é™¤æ‰€æœ‰åŒ¹é…çš„ç¼“å­˜æ¡ç›®ï¼ˆç®€åŒ–ï¼šæ¸…é™¤æ‰€æœ‰ï¼‰
            cache.clear();
        }

        // è°ƒç”¨åº•å±‚å­˜å‚¨
        use crate::memory_adapter::AgentMemBackend;
        let backend = AgentMemBackend::new(
            self.memory_api.clone(),
            self.agent_id.clone(),
            self.user_id.clone(),
        );
        backend.store(message).await
    }

    async fn retrieve(&self, config: &MemoryConfig) -> LumosResult<Vec<LumosMessage>> {
        let retrieve_start = std::time::Instant::now();

        // 1. æ£€æŸ¥L1ç¼“å­˜
        if self.config.enable_l1_cache {
            let cache_key = self.build_cache_key(config);
            let cache = self.l1_cache.read().await;
            if let Some(cached) = cache.peek(&cache_key) {
                let cache_hit_duration = retrieve_start.elapsed();
                info!(
                    "âœ… [CACHE-L1-HIT] Retrieved from cache in {:?}",
                    cache_hit_duration
                );
                debug!("   Cache key: {}", cache_key);
                return Ok(cached.clone());
            }
            drop(cache);
        }

        // 2. L2ç¼“å­˜ï¼ˆRedisï¼‰æš‚ä¸å®ç°ï¼Œéœ€è¦Redisè¿æ¥

        // 3. ä»åç«¯æ£€ç´¢
        info!("ğŸ” [CACHE-MISS] Retrieving from backend");
        let backend_start = std::time::Instant::now();
        let results = self.retrieve_from_backend(config).await?;
        let backend_duration = backend_start.elapsed();

        info!(
            "   Backend retrieval: {:?}, Found: {} messages",
            backend_duration,
            results.len()
        );

        // 4. æ›´æ–°L1ç¼“å­˜
        if self.config.enable_l1_cache {
            let cache_key = self.build_cache_key(config);
            let mut cache = self.l1_cache.write().await;
            cache.put(cache_key.clone(), results.clone());
            debug!("   Cached with key: {}", cache_key);
        }

        let total_duration = retrieve_start.elapsed();
        info!(
            "âœ… [CACHE-RETRIEVE] Total: {:?} (Backend: {:?}, Cache: {:?})",
            total_duration,
            backend_duration,
            total_duration - backend_duration
        );

        Ok(results)
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use agent_mem::Memory as AgentMemApi;

    #[tokio::test]
    async fn test_cache_hit() {
        // è¿™ä¸ªæµ‹è¯•éœ€è¦mock AgentMemApiï¼Œç®€åŒ–å®ç°
        // å®é™…æµ‹è¯•åº”è¯¥åœ¨é›†æˆæµ‹è¯•ä¸­å®Œæˆ
    }

    #[tokio::test]
    async fn test_cache_miss() {
        // è¿™ä¸ªæµ‹è¯•éœ€è¦mock AgentMemApiï¼Œç®€åŒ–å®ç°
    }
}

