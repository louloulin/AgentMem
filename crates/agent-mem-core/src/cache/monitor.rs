//! ç¼“å­˜æ€§èƒ½ç›‘æ§ç³»ç»Ÿ
//!
//! æä¾›å®æ—¶çš„ç¼“å­˜æ€§èƒ½æŒ‡æ ‡æ”¶é›†ã€åˆ†æå’ŒæŠ¥å‘ŠåŠŸèƒ½

use super::{CacheLevel, CacheStats};
use serde::{Deserialize, Serialize};
use std::collections::VecDeque;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::RwLock;
use tracing::{debug, info, warn};

/// æ€§èƒ½æŒ‡æ ‡å¿«ç…§
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceSnapshot {
    /// å¿«ç…§æ—¶é—´æˆ³
    pub timestamp: u64,

    /// L1 ç¼“å­˜ç»Ÿè®¡
    pub l1_stats: Option<CacheStats>,

    /// L2 ç¼“å­˜ç»Ÿè®¡
    pub l2_stats: Option<CacheStats>,

    /// æ€»ä½“ç»Ÿè®¡
    pub combined_stats: CacheStats,

    /// å¹³å‡å“åº”æ—¶é—´ (æ¯«ç§’)
    pub avg_response_time_ms: f64,

    /// P50 å“åº”æ—¶é—´ (æ¯«ç§’)
    pub p50_response_time_ms: f64,

    /// P95 å“åº”æ—¶é—´ (æ¯«ç§’)
    pub p95_response_time_ms: f64,

    /// P99 å“åº”æ—¶é—´ (æ¯«ç§’)
    pub p99_response_time_ms: f64,

    /// æ¯ç§’è¯·æ±‚æ•°
    pub requests_per_second: f64,
}

/// å“åº”æ—¶é—´è®°å½•
#[derive(Debug, Clone)]
struct ResponseTimeRecord {
    timestamp: Instant,
    duration_ms: f64,
    cache_level: Option<CacheLevel>,
    hit: bool,
}

/// ç¼“å­˜ç›‘æ§é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MonitorConfig {
    /// å¯ç”¨ç›‘æ§
    pub enabled: bool,

    /// å¿«ç…§é—´éš”ï¼ˆç§’ï¼‰
    pub snapshot_interval_secs: u64,

    /// ä¿ç•™å¿«ç…§æ•°é‡
    pub max_snapshots: usize,

    /// å“åº”æ—¶é—´è®°å½•çª—å£å¤§å°
    pub response_time_window: usize,

    /// æ…¢æŸ¥è¯¢é˜ˆå€¼ï¼ˆæ¯«ç§’ï¼‰
    pub slow_query_threshold_ms: f64,

    /// å¯ç”¨æ…¢æŸ¥è¯¢æ—¥å¿—
    pub enable_slow_query_log: bool,

    /// å¯ç”¨æŠ¥è­¦
    pub enable_alerts: bool,

    /// å‘½ä¸­ç‡æŠ¥è­¦é˜ˆå€¼
    pub hit_rate_alert_threshold: f64,
}

impl Default for MonitorConfig {
    fn default() -> Self {
        Self {
            enabled: true,
            snapshot_interval_secs: 60, // æ¯åˆ†é’Ÿä¸€æ¬¡å¿«ç…§
            max_snapshots: 1440,        // ä¿ç•™24å°æ—¶æ•°æ®
            response_time_window: 1000, // æœ€è¿‘1000æ¬¡è¯·æ±‚
            slow_query_threshold_ms: 100.0,
            enable_slow_query_log: true,
            enable_alerts: true,
            hit_rate_alert_threshold: 50.0, // å‘½ä¸­ç‡ä½äº50%æŠ¥è­¦
        }
    }
}

/// ç¼“å­˜æ€§èƒ½ç›‘æ§å™¨
pub struct CacheMonitor {
    /// é…ç½®
    config: MonitorConfig,

    /// æ€§èƒ½å¿«ç…§å†å²
    snapshots: Arc<RwLock<VecDeque<PerformanceSnapshot>>>,

    /// å“åº”æ—¶é—´è®°å½•
    response_times: Arc<RwLock<VecDeque<ResponseTimeRecord>>>,

    /// æ…¢æŸ¥è¯¢è®¡æ•°
    slow_query_count: Arc<RwLock<u64>>,

    /// æœ€åå¿«ç…§æ—¶é—´
    last_snapshot: Arc<RwLock<Instant>>,
}

impl CacheMonitor {
    /// åˆ›å»ºæ–°çš„ç›‘æ§å™¨
    pub fn new(config: MonitorConfig) -> Self {
        info!("Creating cache monitor (enabled: {})", config.enabled);

        Self {
            config,
            snapshots: Arc::new(RwLock::new(VecDeque::with_capacity(1440))),
            response_times: Arc::new(RwLock::new(VecDeque::with_capacity(1000))),
            slow_query_count: Arc::new(RwLock::new(0)),
            last_snapshot: Arc::new(RwLock::new(Instant::now())),
        }
    }

    /// è®°å½•ç¼“å­˜æ“ä½œ
    pub async fn record_operation(
        &self,
        duration: Duration,
        hit: bool,
        cache_level: Option<CacheLevel>,
    ) {
        if !self.config.enabled {
            return;
        }

        let duration_ms = duration.as_secs_f64() * 1000.0;

        // æ£€æŸ¥æ˜¯å¦ä¸ºæ…¢æŸ¥è¯¢
        if duration_ms > self.config.slow_query_threshold_ms {
            let mut count = self.slow_query_count.write().await;
            *count += 1;

            if self.config.enable_slow_query_log {
                warn!(
                    "Slow cache query detected: {:.2}ms (threshold: {:.2}ms), hit: {}, level: {:?}",
                    duration_ms, self.config.slow_query_threshold_ms, hit, cache_level
                );
            }
        }

        // è®°å½•å“åº”æ—¶é—´
        let record = ResponseTimeRecord {
            timestamp: Instant::now(),
            duration_ms,
            cache_level,
            hit,
        };

        let mut times = self.response_times.write().await;
        times.push_back(record);

        // é™åˆ¶çª—å£å¤§å°
        if times.len() > self.config.response_time_window {
            times.pop_front();
        }
    }

    /// åˆ›å»ºæ€§èƒ½å¿«ç…§
    pub async fn create_snapshot(
        &self,
        l1_stats: Option<CacheStats>,
        l2_stats: Option<CacheStats>,
        combined_stats: CacheStats,
    ) -> PerformanceSnapshot {
        // è®¡ç®—å“åº”æ—¶é—´æŒ‡æ ‡
        let times = self.response_times.read().await;
        let mut durations: Vec<f64> = times.iter().map(|r| r.duration_ms).collect();
        durations.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));

        let avg_response_time_ms = if !durations.is_empty() {
            durations.iter().sum::<f64>() / durations.len() as f64
        } else {
            0.0
        };

        let p50_response_time_ms = Self::percentile(&durations, 50.0);
        let p95_response_time_ms = Self::percentile(&durations, 95.0);
        let p99_response_time_ms = Self::percentile(&durations, 99.0);

        // è®¡ç®—QPS
        let now = Instant::now();
        let last = *self.last_snapshot.read().await;
        let elapsed_secs = now.duration_since(last).as_secs_f64();
        let requests_per_second = if elapsed_secs > 0.0 {
            times.len() as f64 / elapsed_secs
        } else {
            0.0
        };

        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_secs();

        PerformanceSnapshot {
            timestamp,
            l1_stats,
            l2_stats,
            combined_stats,
            avg_response_time_ms,
            p50_response_time_ms,
            p95_response_time_ms,
            p99_response_time_ms,
            requests_per_second,
        }
    }

    /// ä¿å­˜å¿«ç…§
    pub async fn save_snapshot(&self, snapshot: PerformanceSnapshot) {
        if !self.config.enabled {
            return;
        }

        // æ£€æŸ¥å‘½ä¸­ç‡æŠ¥è­¦
        if self.config.enable_alerts {
            let hit_rate = snapshot.combined_stats.hit_rate();
            if hit_rate < self.config.hit_rate_alert_threshold {
                warn!(
                    "Cache hit rate alert: {:.2}% (threshold: {:.2}%)",
                    hit_rate, self.config.hit_rate_alert_threshold
                );
            }
        }

        let mut snapshots = self.snapshots.write().await;
        snapshots.push_back(snapshot);

        // é™åˆ¶å¿«ç…§æ•°é‡
        if snapshots.len() > self.config.max_snapshots {
            snapshots.pop_front();
        }

        // æ›´æ–°æœ€åå¿«ç…§æ—¶é—´
        *self.last_snapshot.write().await = Instant::now();

        debug!("Cache performance snapshot saved");
    }

    /// è·å–æœ€æ–°å¿«ç…§
    pub async fn latest_snapshot(&self) -> Option<PerformanceSnapshot> {
        let snapshots = self.snapshots.read().await;
        snapshots.back().cloned()
    }

    /// è·å–æ‰€æœ‰å¿«ç…§
    pub async fn all_snapshots(&self) -> Vec<PerformanceSnapshot> {
        let snapshots = self.snapshots.read().await;
        snapshots.iter().cloned().collect()
    }

    /// è·å–æ…¢æŸ¥è¯¢æ•°é‡
    pub async fn slow_query_count(&self) -> u64 {
        *self.slow_query_count.read().await
    }

    /// é‡ç½®æ…¢æŸ¥è¯¢è®¡æ•°
    pub async fn reset_slow_query_count(&self) {
        *self.slow_query_count.write().await = 0;
    }

    /// ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    pub async fn generate_report(&self) -> Option<PerformanceReport> {
        let snapshots = self.snapshots.read().await;

        if snapshots.is_empty() {
            return None;
        }

        // Safe unwrap: we already checked snapshots.is_empty() above
        let latest = snapshots.back().expect("snapshots should not be empty after is_empty() check");
        let earliest = snapshots.front().expect("snapshots should not be empty after is_empty() check");

        // è®¡ç®—è¶‹åŠ¿
        let hit_rate_trend = latest.combined_stats.hit_rate() - earliest.combined_stats.hit_rate();

        let avg_response_time_trend = latest.avg_response_time_ms - earliest.avg_response_time_ms;

        // è®¡ç®—å¹³å‡å€¼
        let avg_hit_rate = snapshots
            .iter()
            .map(|s| s.combined_stats.hit_rate())
            .sum::<f64>()
            / snapshots.len() as f64;

        let avg_qps =
            snapshots.iter().map(|s| s.requests_per_second).sum::<f64>() / snapshots.len() as f64;

        // æ‰¾åˆ°æœ€ä½³å’Œæœ€å·®æ€§èƒ½
        let mut sorted_by_hit_rate: Vec<_> = snapshots.iter().collect();
        sorted_by_hit_rate.sort_by(|a, b| {
            b.combined_stats
                .hit_rate()
                .partial_cmp(&a.combined_stats.hit_rate())
                .unwrap_or(std::cmp::Ordering::Equal)
        });

        let best_hit_rate = sorted_by_hit_rate
            .first()
            .unwrap()
            .combined_stats
            .hit_rate();
        let worst_hit_rate = sorted_by_hit_rate.last().unwrap().combined_stats.hit_rate();

        Some(PerformanceReport {
            report_period_secs: (latest.timestamp - earliest.timestamp),
            total_snapshots: snapshots.len(),
            latest_snapshot: latest.clone(),
            avg_hit_rate,
            hit_rate_trend,
            best_hit_rate,
            worst_hit_rate,
            avg_qps,
            avg_response_time_ms: latest.avg_response_time_ms,
            avg_response_time_trend,
            slow_query_count: *self.slow_query_count.read().await,
            recommendations: Self::generate_recommendations(latest, hit_rate_trend),
        })
    }

    /// è®¡ç®—ç™¾åˆ†ä½æ•°
    fn percentile(sorted_values: &[f64], percentile: f64) -> f64 {
        if sorted_values.is_empty() {
            return 0.0;
        }

        let index = ((percentile / 100.0) * (sorted_values.len() - 1) as f64).round() as usize;
        sorted_values[index.min(sorted_values.len() - 1)]
    }

    /// ç”Ÿæˆä¼˜åŒ–å»ºè®®
    fn generate_recommendations(
        snapshot: &PerformanceSnapshot,
        hit_rate_trend: f64,
    ) -> Vec<String> {
        let mut recommendations = Vec::new();

        let hit_rate = snapshot.combined_stats.hit_rate();

        // å‘½ä¸­ç‡å»ºè®®
        if hit_rate < 50.0 {
            recommendations.push(
                "âš ï¸  å‘½ä¸­ç‡è¿‡ä½ (<50%)ï¼Œå»ºè®®ï¼š1) å¢åŠ ç¼“å­˜å®¹é‡ 2) ä¼˜åŒ–ç¼“å­˜é”®è®¾è®¡ 3) å¯ç”¨ç¼“å­˜é¢„çƒ­"
                    .to_string(),
            );
        } else if hit_rate < 70.0 {
            recommendations.push(
                "ğŸ’¡ å‘½ä¸­ç‡å¯ä»¥æ”¹è¿› (<70%)ï¼Œå»ºè®®ï¼š1) åˆ†æè®¿é—®æ¨¡å¼ 2) è°ƒæ•´TTL 3) è€ƒè™‘é¢„çƒ­çƒ­é—¨æ•°æ®"
                    .to_string(),
            );
        } else if hit_rate > 85.0 {
            recommendations.push("âœ… å‘½ä¸­ç‡ä¼˜ç§€ (>85%)ï¼Œç¼“å­˜ç­–ç•¥è¿è¡Œè‰¯å¥½ï¼".to_string());
        }

        // è¶‹åŠ¿å»ºè®®
        if hit_rate_trend < -5.0 {
            recommendations.push(
                "ğŸ“‰ å‘½ä¸­ç‡ä¸‹é™è¶‹åŠ¿æ˜æ˜¾ï¼Œå»ºè®®æ£€æŸ¥ï¼š1) æŸ¥è¯¢æ¨¡å¼å˜åŒ– 2) ç¼“å­˜å¤±æ•ˆç­–ç•¥ 3) æ•°æ®çƒ­åº¦åˆ†å¸ƒ"
                    .to_string(),
            );
        } else if hit_rate_trend > 5.0 {
            recommendations.push("ğŸ“ˆ å‘½ä¸­ç‡æå‡è¶‹åŠ¿è‰¯å¥½ï¼Œå½“å‰ä¼˜åŒ–ç­–ç•¥æœ‰æ•ˆï¼".to_string());
        }

        // å“åº”æ—¶é—´å»ºè®®
        if snapshot.p99_response_time_ms > 100.0 {
            recommendations.push(
                "âš ï¸  P99å“åº”æ—¶é—´è¿‡é«˜ (>100ms)ï¼Œå»ºè®®ï¼š1) ä¼˜åŒ–ç¼“å­˜æŸ¥è¯¢ 2) æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿ 3) è€ƒè™‘å¢åŠ ç¼“å­˜å±‚çº§"
                    .to_string()
            );
        }

        // QPSå»ºè®®
        if snapshot.requests_per_second > 1000.0 {
            recommendations.push(
                "ğŸ“Š é«˜QPSåœºæ™¯ (>1000)ï¼Œå»ºè®®ï¼š1) ç¡®ä¿ç¼“å­˜å®¹é‡å……è¶³ 2) ç›‘æ§å†…å­˜ä½¿ç”¨ 3) è€ƒè™‘åˆ†å¸ƒå¼ç¼“å­˜"
                    .to_string(),
            );
        }

        if recommendations.is_empty() {
            recommendations.push("âœ… ç¼“å­˜ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼Œæ— ç‰¹æ®Šå»ºè®®".to_string());
        }

        recommendations
    }
}

/// æ€§èƒ½æŠ¥å‘Š
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceReport {
    /// æŠ¥å‘Šå‘¨æœŸï¼ˆç§’ï¼‰
    pub report_period_secs: u64,

    /// å¿«ç…§æ€»æ•°
    pub total_snapshots: usize,

    /// æœ€æ–°å¿«ç…§
    pub latest_snapshot: PerformanceSnapshot,

    /// å¹³å‡å‘½ä¸­ç‡
    pub avg_hit_rate: f64,

    /// å‘½ä¸­ç‡è¶‹åŠ¿ï¼ˆæ­£å€¼è¡¨ç¤ºä¸Šå‡ï¼‰
    pub hit_rate_trend: f64,

    /// æœ€ä½³å‘½ä¸­ç‡
    pub best_hit_rate: f64,

    /// æœ€å·®å‘½ä¸­ç‡
    pub worst_hit_rate: f64,

    /// å¹³å‡QPS
    pub avg_qps: f64,

    /// å¹³å‡å“åº”æ—¶é—´
    pub avg_response_time_ms: f64,

    /// å“åº”æ—¶é—´è¶‹åŠ¿
    pub avg_response_time_trend: f64,

    /// æ…¢æŸ¥è¯¢æ•°é‡
    pub slow_query_count: u64,

    /// ä¼˜åŒ–å»ºè®®
    pub recommendations: Vec<String>,
}

impl PerformanceReport {
    /// æ ¼å¼åŒ–ä¸ºå¯è¯»æ–‡æœ¬
    pub fn format_text(&self) -> String {
        let mut output = String::new();

        output.push_str("=== ç¼“å­˜æ€§èƒ½æŠ¥å‘Š ===\n\n");
        output.push_str(&format!(
            "æŠ¥å‘Šå‘¨æœŸ: {} ç§’ ({} åˆ†é’Ÿ)\n",
            self.report_period_secs,
            self.report_period_secs / 60
        ));
        output.push_str(&format!("å¿«ç…§æ•°é‡: {}\n\n", self.total_snapshots));

        output.push_str("--- å‘½ä¸­ç‡æŒ‡æ ‡ ---\n");
        output.push_str(&format!(
            "å½“å‰å‘½ä¸­ç‡: {:.2}%\n",
            self.latest_snapshot.combined_stats.hit_rate()
        ));
        output.push_str(&format!("å¹³å‡å‘½ä¸­ç‡: {:.2}%\n", self.avg_hit_rate));
        output.push_str(&format!("æœ€ä½³å‘½ä¸­ç‡: {:.2}%\n", self.best_hit_rate));
        output.push_str(&format!("æœ€å·®å‘½ä¸­ç‡: {:.2}%\n", self.worst_hit_rate));
        output.push_str(&format!("å‘½ä¸­ç‡è¶‹åŠ¿: {:+.2}%\n\n", self.hit_rate_trend));

        output.push_str("--- å“åº”æ—¶é—´æŒ‡æ ‡ ---\n");
        output.push_str(&format!(
            "å¹³å‡å“åº”: {:.2}ms\n",
            self.latest_snapshot.avg_response_time_ms
        ));
        output.push_str(&format!(
            "P50å“åº”: {:.2}ms\n",
            self.latest_snapshot.p50_response_time_ms
        ));
        output.push_str(&format!(
            "P95å“åº”: {:.2}ms\n",
            self.latest_snapshot.p95_response_time_ms
        ));
        output.push_str(&format!(
            "P99å“åº”: {:.2}ms\n",
            self.latest_snapshot.p99_response_time_ms
        ));
        output.push_str(&format!(
            "å“åº”æ—¶é—´è¶‹åŠ¿: {:+.2}ms\n\n",
            self.avg_response_time_trend
        ));

        output.push_str("--- ååé‡æŒ‡æ ‡ ---\n");
        output.push_str(&format!(
            "å½“å‰QPS: {:.2}\n",
            self.latest_snapshot.requests_per_second
        ));
        output.push_str(&format!("å¹³å‡QPS: {:.2}\n", self.avg_qps));
        output.push_str(&format!("æ…¢æŸ¥è¯¢æ•°: {}\n\n", self.slow_query_count));

        output.push_str("--- ä¼˜åŒ–å»ºè®® ---\n");
        for (i, rec) in self.recommendations.iter().enumerate() {
            output.push_str(&format!("{}. {}\n", i + 1, rec));
        }

        output.push_str("\n=================\n");

        output
    }

    /// æ ¼å¼åŒ–ä¸ºJSON
    pub fn format_json(&self) -> Result<String, serde_json::Error> {
        serde_json::to_string_pretty(self)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_monitor_creation() {
        let config = MonitorConfig::default();
        let monitor = CacheMonitor::new(config.clone());

        assert_eq!(monitor.config.enabled, config.enabled);
        assert_eq!(monitor.slow_query_count().await, 0);
    }

    #[tokio::test]
    async fn test_record_operation() {
        let config = MonitorConfig::default();
        let monitor = CacheMonitor::new(config);

        // è®°å½•å‡ æ¬¡æ“ä½œ
        monitor
            .record_operation(Duration::from_millis(10), true, Some(CacheLevel::L1))
            .await;

        monitor
            .record_operation(
                Duration::from_millis(150), // æ…¢æŸ¥è¯¢
                false,
                Some(CacheLevel::L2),
            )
            .await;

        // éªŒè¯æ…¢æŸ¥è¯¢è®¡æ•°
        assert_eq!(monitor.slow_query_count().await, 1);
    }

    #[tokio::test]
    async fn test_snapshot_creation() {
        let config = MonitorConfig::default();
        let monitor = CacheMonitor::new(config);

        // è®°å½•ä¸€äº›æ“ä½œ
        for _ in 0..10 {
            monitor
                .record_operation(Duration::from_millis(20), true, Some(CacheLevel::L1))
                .await;
        }

        let stats = CacheStats {
            total_gets: 10,
            hits: 8,
            misses: 2,
            total_sets: 5,
            evictions: 0,
            invalidations: 0,
            total_size_bytes: 1024,
            entry_count: 5,
        };

        let snapshot = monitor
            .create_snapshot(Some(stats.clone()), None, stats)
            .await;

        assert_eq!(snapshot.combined_stats.hit_rate(), 80.0);
        assert!(snapshot.avg_response_time_ms > 0.0);
    }
}
