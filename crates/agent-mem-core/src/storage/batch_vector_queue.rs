//! ğŸ†• Phase 1.2: æ‰¹é‡å‘é‡å­˜å‚¨é˜Ÿåˆ—
//!
//! å®ç°è‡ªåŠ¨æ‰¹é‡å¤„ç†é˜Ÿåˆ—ï¼Œå°†å‘é‡å­˜å‚¨æ“ä½œæ‰¹é‡æ‰§è¡Œ
//! é¢„æœŸæ•ˆæœ: æ‰¹é‡å­˜å‚¨ååé‡æå‡5-10x

use agent_mem_traits::{AgentMemError, Result, VectorData, VectorStore};
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::mpsc;
use tokio::sync::RwLock;
use tracing::{debug, error, info, warn};

/// å‘é‡å­˜å‚¨ä»»åŠ¡
#[derive(Debug, Clone)]
struct VectorStorageTask {
    /// å‘é‡æ•°æ®
    vector_data: VectorData,
    /// åˆ›å»ºæ—¶é—´
    created_at: Instant,
}

/// æ‰¹é‡å‘é‡å­˜å‚¨é˜Ÿåˆ—é…ç½®
#[derive(Debug, Clone)]
pub struct BatchVectorQueueConfig {
    /// æ‰¹é‡å¤§å°
    pub batch_size: usize,
    /// æ‰¹é‡å¤„ç†é—´éš”ï¼ˆæ¯«ç§’ï¼‰
    pub batch_interval_ms: u64,
    /// æœ€å¤§é˜Ÿåˆ—å¤§å°
    pub max_queue_size: usize,
    /// æ˜¯å¦å¯ç”¨é˜Ÿåˆ—
    pub enable_queue: bool,
}

impl Default for BatchVectorQueueConfig {
    fn default() -> Self {
        Self {
            batch_size: 100,
            batch_interval_ms: 100,
            max_queue_size: 10000,
            enable_queue: true,
        }
    }
}

/// æ‰¹é‡å‘é‡å­˜å‚¨é˜Ÿåˆ—ç»Ÿè®¡
#[derive(Debug, Clone, Default)]
pub struct BatchVectorQueueStats {
    /// æ€»ä»»åŠ¡æ•°
    pub total_tasks: usize,
    /// å·²å¤„ç†ä»»åŠ¡æ•°
    pub processed_tasks: usize,
    /// æ€»æ‰¹æ¬¡æ•°
    pub total_batches: usize,
    /// å¹³å‡æ‰¹å¤„ç†æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    pub avg_batch_time_ms: f64,
    /// é˜Ÿåˆ—å½“å‰å¤§å°
    pub current_queue_size: usize,
}

/// æ‰¹é‡å‘é‡å­˜å‚¨é˜Ÿåˆ—
pub struct BatchVectorStorageQueue {
    /// å‘é‡å­˜å‚¨åç«¯
    vector_store: Arc<dyn VectorStore + Send + Sync>,
    /// é…ç½®
    config: BatchVectorQueueConfig,
    /// ä»»åŠ¡å‘é€ç«¯
    task_sender: mpsc::UnboundedSender<VectorStorageTask>,
    /// ç»Ÿè®¡ä¿¡æ¯
    stats: Arc<RwLock<BatchVectorQueueStats>>,
    /// åå°ä»»åŠ¡å¥æŸ„
    _background_handle: Arc<RwLock<Option<tokio::task::JoinHandle<()>>>>,
}

impl BatchVectorStorageQueue {
    /// åˆ›å»ºæ–°çš„æ‰¹é‡å‘é‡å­˜å‚¨é˜Ÿåˆ—
    pub fn new(
        vector_store: Arc<dyn VectorStore + Send + Sync>,
        config: BatchVectorQueueConfig,
    ) -> Self {
        let (task_sender, task_receiver) = mpsc::unbounded_channel();
        let stats = Arc::new(RwLock::new(BatchVectorQueueStats::default()));

        let vector_store_clone = Arc::clone(&vector_store);
        let config_clone = config.clone();
        let stats_clone = Arc::clone(&stats);

        // å¯åŠ¨åå°æ‰¹å¤„ç†ä»»åŠ¡
        let background_handle = tokio::spawn(async move {
            Self::process_batch_loop(
                task_receiver,
                vector_store_clone,
                config_clone,
                stats_clone,
            )
            .await;
        });

        Self {
            vector_store,
            config,
            task_sender,
            stats,
            _background_handle: Arc::new(RwLock::new(Some(background_handle))),
        }
    }

    /// æ·»åŠ å‘é‡å­˜å‚¨ä»»åŠ¡ï¼ˆéé˜»å¡ï¼‰
    ///
    /// ç«‹å³è¿”å›ï¼Œå‘é‡å­˜å‚¨å°†åœ¨åå°æ‰¹é‡å¤„ç†
    pub async fn add_vector(&self, vector_data: VectorData) -> Result<()> {
        if !self.config.enable_queue {
            // å¦‚æœé˜Ÿåˆ—æœªå¯ç”¨ï¼Œç›´æ¥å­˜å‚¨
            let _ = self.vector_store.add_vectors(vec![vector_data]).await?;
            return Ok(());
        }

        // æ³¨æ„: UnboundedSenderæ²¡æœ‰len()æ–¹æ³•ï¼Œæˆ‘ä»¬ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯æ¥è·Ÿè¸ª
        // å¦‚æœé˜Ÿåˆ—æ»¡äº†ï¼Œsendä¼šå¤±è´¥ï¼Œæˆ‘ä»¬ä¼šåœ¨é‚£é‡Œå¤„ç†

        let task = VectorStorageTask {
            vector_data,
            created_at: Instant::now(),
        };

        self.task_sender.send(task).map_err(|e| {
            AgentMemError::StorageError(format!("Failed to send vector storage task: {e}"))
        })?;

        // æ›´æ–°ç»Ÿè®¡
        {
            let mut stats = self.stats.write().await;
            stats.total_tasks += 1;
            // æ³¨æ„: UnboundedSenderæ²¡æœ‰len()æ–¹æ³•ï¼Œæˆ‘ä»¬ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯è·Ÿè¸ª
            // stats.current_queue_sizeä¼šåœ¨process_batch_loopä¸­æ›´æ–°
        }

        Ok(())
    }

    /// åå°æ‰¹å¤„ç†å¾ªç¯
    async fn process_batch_loop(
        mut task_receiver: mpsc::UnboundedReceiver<VectorStorageTask>,
        vector_store: Arc<dyn VectorStore + Send + Sync>,
        config: BatchVectorQueueConfig,
        stats: Arc<RwLock<BatchVectorQueueStats>>,
    ) {
        let mut batch = Vec::new();
        let mut last_flush = Instant::now();
        let batch_interval = Duration::from_millis(config.batch_interval_ms);

        loop {
            tokio::select! {
                // æ¥æ”¶æ–°ä»»åŠ¡
                task = task_receiver.recv() => {
                    match task {
                        Some(task) => {
                            batch.push(task.vector_data);
                            
                            // å¦‚æœè¾¾åˆ°æ‰¹é‡å¤§å°ï¼Œç«‹å³åˆ·æ–°
                            if batch.len() >= config.batch_size {
                                Self::flush_batch(&vector_store, &mut batch, &stats).await;
                                last_flush = Instant::now();
                            }
                        }
                        None => {
                            // é€šé“å…³é—­ï¼Œå¤„ç†å‰©ä½™æ‰¹æ¬¡
                            if !batch.is_empty() {
                                Self::flush_batch(&vector_store, &mut batch, &stats).await;
                            }
                            break;
                        }
                    }
                }
                // å®šæ—¶åˆ·æ–°
                _ = tokio::time::sleep(batch_interval) => {
                    if !batch.is_empty() && last_flush.elapsed() >= batch_interval {
                        Self::flush_batch(&vector_store, &mut batch, &stats).await;
                        last_flush = Instant::now();
                    }
                }
            }
        }
    }

    /// åˆ·æ–°æ‰¹æ¬¡
    async fn flush_batch(
        vector_store: &Arc<dyn VectorStore + Send + Sync>,
        batch: &mut Vec<VectorData>,
        stats: &Arc<RwLock<BatchVectorQueueStats>>,
    ) {
        if batch.is_empty() {
            return;
        }

        let batch_size = batch.len();
        let start = Instant::now();
        let vectors = batch.drain(..).collect();

        match vector_store.add_vectors(vectors).await {
            Ok(_) => {
                let elapsed = start.elapsed().as_millis() as u64;
                info!(
                    "âœ… Batch vector storage completed: {} vectors in {}ms",
                    batch_size, elapsed
                );

                // æ›´æ–°ç»Ÿè®¡
                let mut stats_guard = stats.write().await;
                stats_guard.processed_tasks += batch_size;
                stats_guard.total_batches += 1;
                if stats_guard.total_batches > 0 {
                    stats_guard.avg_batch_time_ms = (stats_guard.avg_batch_time_ms
                        * (stats_guard.total_batches - 1) as f64
                        + elapsed as f64)
                        / stats_guard.total_batches as f64;
                }
            }
            Err(e) => {
                error!("Failed to batch store vectors: {}", e);
                // æ³¨æ„: è¿™é‡Œä¸æ›´æ–°processed_tasksï¼Œå› ä¸ºå¤±è´¥äº†
            }
        }
    }

    /// è·å–ç»Ÿè®¡ä¿¡æ¯
    pub async fn stats(&self) -> BatchVectorQueueStats {
        // æ³¨æ„: UnboundedSenderæ²¡æœ‰len()æ–¹æ³•
        // æˆ‘ä»¬ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯ä¸­çš„processed_tasksæ¥ä¼°ç®—é˜Ÿåˆ—å¤§å°
        self.stats.read().await.clone()
    }

    /// ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼ˆç”¨äºæµ‹è¯•æˆ–ä¼˜é›…å…³é—­ï¼‰
    pub async fn flush(&self) -> Result<()> {
        // ç­‰å¾…é˜Ÿåˆ—å¤„ç†å®Œæˆï¼ˆé€šè¿‡æ£€æŸ¥ç»Ÿè®¡ä¿¡æ¯ï¼‰
        let mut attempts = 0;
        const MAX_ATTEMPTS: usize = 100;
        let initial_tasks = {
            let stats = self.stats.read().await;
            stats.total_tasks
        };
        
        while attempts < MAX_ATTEMPTS {
            let stats = self.stats.read().await;
            if stats.processed_tasks >= initial_tasks {
                break;
            }
            tokio::time::sleep(Duration::from_millis(10)).await;
            attempts += 1;
        }

        let final_stats = self.stats.read().await;
        if final_stats.processed_tasks < initial_tasks {
            warn!(
                "Vector storage queue still processing: {}/{} tasks processed",
                final_stats.processed_tasks,
                initial_tasks
            );
        }

        Ok(())
    }
}
