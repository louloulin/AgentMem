//! Agent Orchestrator - å¯¹è¯å¾ªç¯ç¼–æ’
//!
//! è¿™æ˜¯ AgentMem çš„æ ¸å¿ƒå¯¹è¯å¾ªç¯å®ç°ï¼Œå‚è€ƒ MIRIX çš„ AgentWrapper.step() è®¾è®¡
//! é›†æˆæ‰€æœ‰ç°æœ‰æ¨¡å—ï¼šMemoryEngine, LLMClient, ToolExecutor, MessageRepository

use crate::{
    engine::MemoryEngine,
    Memory,
    storage::traits::MessageRepositoryTrait,
};

use agent_mem_llm::LLMClient;
use agent_mem_tools::ToolExecutor;
use agent_mem_traits::{
    llm::FunctionDefinition,
    AgentMemError, Message, Result,
};
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use tracing::{debug, info, warn};
use uuid::Uuid;

pub mod memory_integration;
pub mod tool_integration;
pub mod memory_extraction;

use memory_integration::MemoryIntegrator;
use memory_extraction::MemoryExtractor;
use tool_integration::{ToolIntegrator, ToolIntegratorConfig};

/// å¯¹è¯è¯·æ±‚
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatRequest {
    /// ç”¨æˆ·æ¶ˆæ¯
    pub message: String,

    /// Agent ID
    pub agent_id: String,

    /// ç”¨æˆ· ID
    pub user_id: String,

    /// ç»„ç»‡ ID (å¯é€‰ï¼Œé»˜è®¤ä¸º "default")
    #[serde(default = "default_organization_id")]
    pub organization_id: String,

    /// ä¼šè¯ ID - ç”¨äºWorking Memoryéš”ç¦»
    pub session_id: String,

    /// æ˜¯å¦æµå¼å“åº”
    pub stream: bool,

    /// æœ€å¤§è®°å¿†æ£€ç´¢æ•°é‡
    pub max_memories: usize,
}

impl ChatRequest {
    /// éªŒè¯è¯·æ±‚å‚æ•°
    pub fn validate(&self) -> Result<()> {
        // éªŒè¯æ¶ˆæ¯ä¸ä¸ºç©º
        if self.message.trim().is_empty() {
            return Err(AgentMemError::ValidationError(
                "Message cannot be empty".to_string(),
            ));
        }

        // éªŒè¯æ¶ˆæ¯é•¿åº¦ï¼ˆæœ€å¤§ 100KBï¼‰
        if self.message.len() > 100_000 {
            return Err(AgentMemError::ValidationError(
                format!("Message too long: {} bytes (max 100KB)", self.message.len()),
            ));
        }

        // éªŒè¯ agent_id ä¸ä¸ºç©º
        if self.agent_id.trim().is_empty() {
            return Err(AgentMemError::ValidationError(
                "Agent ID cannot be empty".to_string(),
            ));
        }

        // éªŒè¯ agent_id é•¿åº¦ï¼ˆæœ€å¤§ 255 å­—ç¬¦ï¼‰
        if self.agent_id.len() > 255 {
            return Err(AgentMemError::ValidationError(
                format!("Agent ID too long: {} characters (max 255)", self.agent_id.len()),
            ));
        }

        // éªŒè¯ user_id ä¸ä¸ºç©º
        if self.user_id.trim().is_empty() {
            return Err(AgentMemError::ValidationError(
                "User ID cannot be empty".to_string(),
            ));
        }

        // éªŒè¯ user_id é•¿åº¦ï¼ˆæœ€å¤§ 255 å­—ç¬¦ï¼‰
        if self.user_id.len() > 255 {
            return Err(AgentMemError::ValidationError(
                format!("User ID too long: {} characters (max 255)", self.user_id.len()),
            ));
        }

        // éªŒè¯ organization_id ä¸ä¸ºç©º
        if self.organization_id.trim().is_empty() {
            return Err(AgentMemError::ValidationError(
                "Organization ID cannot be empty".to_string(),
            ));
        }

        // éªŒè¯ organization_id é•¿åº¦ï¼ˆæœ€å¤§ 255 å­—ç¬¦ï¼‰
        if self.organization_id.len() > 255 {
            return Err(AgentMemError::ValidationError(
                format!("Organization ID too long: {} characters (max 255)", self.organization_id.len()),
            ));
        }

        // éªŒè¯ max_memories èŒƒå›´ï¼ˆ1-1000ï¼‰
        if self.max_memories == 0 {
            return Err(AgentMemError::ValidationError(
                "max_memories must be at least 1".to_string(),
            ));
        }

        if self.max_memories > 1000 {
            return Err(AgentMemError::ValidationError(
                format!("max_memories too large: {} (max 1000)", self.max_memories),
            ));
        }

        // éªŒè¯ session_id ä¸ä¸ºç©º
        if self.session_id.trim().is_empty() {
            return Err(AgentMemError::ValidationError(
                "Session ID cannot be empty".to_string(),
            ));
        }

        // éªŒè¯ session_id é•¿åº¦ï¼ˆæœ€å¤§ 255 å­—ç¬¦ï¼‰
        if self.session_id.len() > 255 {
            return Err(AgentMemError::ValidationError(
                format!("Session ID too long: {} characters (max 255)", self.session_id.len()),
            ));
        }

        Ok(())
    }
}

/// é»˜è®¤ç»„ç»‡ ID
fn default_organization_id() -> String {
    "default".to_string()
}

/// å¯¹è¯å“åº”
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatResponse {
    /// æ¶ˆæ¯ ID
    pub message_id: String,
    
    /// Agent å“åº”å†…å®¹
    pub content: String,
    
    /// æ˜¯å¦æ›´æ–°äº†è®°å¿†
    pub memories_updated: bool,
    
    /// æ›´æ–°çš„è®°å¿†æ•°é‡
    pub memories_count: usize,
    
    /// å·¥å…·è°ƒç”¨ï¼ˆå¦‚æœæœ‰ï¼‰
    pub tool_calls: Option<Vec<ToolCallInfo>>,
}

/// å·¥å…·è°ƒç”¨ä¿¡æ¯
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ToolCallInfo {
    pub tool_name: String,
    pub arguments: serde_json::Value,
    pub result: Option<String>,
}

/// Agent ç¼–æ’å™¨é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OrchestratorConfig {
    /// æœ€å¤§å·¥å…·è°ƒç”¨è½®æ•°
    pub max_tool_rounds: usize,

    /// æœ€å¤§è®°å¿†æ£€ç´¢æ•°é‡
    pub max_memories: usize,

    /// æ˜¯å¦è‡ªåŠ¨æå–è®°å¿†
    pub auto_extract_memories: bool,

    /// è®°å¿†æå–é˜ˆå€¼
    pub memory_extraction_threshold: f32,

    /// æ˜¯å¦å¯ç”¨å·¥å…·è°ƒç”¨
    pub enable_tool_calling: bool,
}

impl Default for OrchestratorConfig {
    fn default() -> Self {
        Self {
            max_tool_rounds: 5,
            max_memories: 10,
            auto_extract_memories: true,
            memory_extraction_threshold: 0.5,
            enable_tool_calling: false, // é»˜è®¤å…³é—­ï¼Œéœ€è¦æ˜¾å¼å¯ç”¨
        }
    }
}

/// Agent ç¼–æ’å™¨ - æ ¸å¿ƒå¯¹è¯å¾ªç¯
///
/// å‚è€ƒ MIRIX çš„ AgentWrapper.step() å®ç°
/// é›†æˆæ‰€æœ‰ç°æœ‰æ¨¡å—å®ç°å®Œæ•´çš„å¯¹è¯å¾ªç¯
pub struct AgentOrchestrator {
    config: OrchestratorConfig,
    memory_engine: Arc<MemoryEngine>,
    message_repo: Arc<dyn MessageRepositoryTrait>,
    llm_client: Arc<LLMClient>,
    tool_executor: Arc<ToolExecutor>,
    memory_integrator: MemoryIntegrator,
    memory_extractor: MemoryExtractor,
    tool_integrator: ToolIntegrator,
    /// Working Memory Store - ç”¨äºä¼šè¯çº§ä¸´æ—¶ä¸Šä¸‹æ–‡ï¼ˆæœ€å°æ”¹åŠ¨æ–¹æ¡ˆï¼šç›´æ¥ä½¿ç”¨Storeè€ŒéAgentï¼‰
    working_store: Option<Arc<dyn agent_mem_traits::WorkingMemoryStore>>,
}

impl AgentOrchestrator {
    /// åˆ›å»ºæ–°çš„ç¼–æ’å™¨
    pub fn new(
        config: OrchestratorConfig,
        memory_engine: Arc<MemoryEngine>,
        message_repo: Arc<dyn MessageRepositoryTrait>,
        llm_client: Arc<LLMClient>,
        tool_executor: Arc<ToolExecutor>,
        working_store: Option<Arc<dyn agent_mem_traits::WorkingMemoryStore>>,
    ) -> Self {
        // åˆ›å»ºè®°å¿†é›†æˆå™¨
        let memory_integrator = MemoryIntegrator::with_default_config(memory_engine.clone());

        // åˆ›å»ºè®°å¿†æå–å™¨
        let memory_extractor = MemoryExtractor::with_default_config(
            llm_client.clone(),
            memory_engine.clone(),
        );

        // åˆ›å»ºå·¥å…·é›†æˆå™¨
        let tool_config = ToolIntegratorConfig {
            max_tool_rounds: config.max_tool_rounds,
            tool_timeout_seconds: 30,
            allow_parallel_execution: false,
        };
        let tool_integrator = ToolIntegrator::new(tool_config, tool_executor.clone());

        Self {
            config,
            memory_engine,
            message_repo,
            llm_client,
            tool_executor,
            memory_integrator,
            memory_extractor,
            tool_integrator,
            working_store,
        }
    }

    /// ä»Working Memoryè·å–ä¼šè¯ä¸Šä¸‹æ–‡
    ///
    /// è¿™ä¸ªæ–¹æ³•ä»WorkingMemoryStoreè·å–å½“å‰ä¼šè¯çš„ä¸´æ—¶ä¸Šä¸‹æ–‡
    async fn get_working_context(&self, session_id: &str) -> Result<String> {
        if let Some(ref store) = self.working_store {
            match store.get_session_items(session_id).await {
                Ok(items) => {
                    if items.is_empty() {
                        debug!("No working memory items found for session: {}", session_id);
                        return Ok(String::new());
                    }
                    
                    // æŒ‰ä¼˜å…ˆçº§å’Œæ—¶é—´æ’åºï¼ˆå·²åœ¨storeä¸­å®Œæˆï¼‰
                    // æ ¼å¼åŒ–ä¸ºå¯¹è¯ä¸Šä¸‹æ–‡
                    let context_lines: Vec<String> = items
                        .iter()
                        .map(|item| {
                            format!(
                                "[{}] {}",
                                item.created_at.format("%H:%M:%S"),
                                item.content
                            )
                        })
                        .collect();
                    
                    let context = context_lines.join("\n");
                    debug!(
                        "Retrieved {} working memory items for session {}: {} chars",
                        items.len(),
                        session_id,
                        context.len()
                    );
                    Ok(context)
                }
                Err(e) => {
                    warn!("Failed to get working context for session {}: {}", session_id, e);
                    Ok(String::new()) // å¤±è´¥æ—¶è¿”å›ç©ºï¼Œä¸å½±å“å¯¹è¯
                }
            }
        } else {
            debug!("Working Memory store not configured, session_id: {}", session_id);
            Ok(String::new())
        }
    }

    /// æ›´æ–°Working Memory
    ///
    /// ä¿å­˜å½“å‰å¯¹è¯è½®æ¬¡åˆ°å·¥ä½œè®°å¿†
    async fn update_working_memory(
        &self,
        session_id: &str,
        user_id: &str,
        agent_id: &str,
        user_message: &str,
        assistant_response: &str,
    ) -> Result<()> {
        if let Some(ref store) = self.working_store {
            use agent_mem_traits::WorkingMemoryItem;
            use chrono::Utc;
            
            // æ ¼å¼åŒ–å¯¹è¯å¯¹
            let conversation_pair = format!(
                "User: {}\nAssistant: {}",
                user_message, assistant_response
            );
            
            // åˆ›å»ºå·¥ä½œè®°å¿†é¡¹
            let item = WorkingMemoryItem {
                id: Uuid::new_v4().to_string(),
                user_id: user_id.to_string(),
                agent_id: agent_id.to_string(),
                session_id: session_id.to_string(),
                content: conversation_pair,
                priority: 1, // é»˜è®¤ä¼˜å…ˆçº§
                expires_at: Some(Utc::now() + chrono::Duration::hours(24)), // 24å°æ—¶åè¿‡æœŸ
                metadata: serde_json::json!({}),
                created_at: Utc::now(),
            };
            
            match store.add_item(item).await {
                Ok(_) => {
                    debug!("Successfully added working memory item for session: {}", session_id);
                }
                Err(e) => {
                    warn!("Failed to add working memory item for session {}: {}", session_id, e);
                    // ä¸è¿”å›é”™è¯¯ï¼Œé¿å…å½±å“å¯¹è¯æµç¨‹
                }
            }
        } else {
            debug!("Working Memory store not configured, skipping update for session: {}", session_id);
        }
        
        Ok(())
    }

    /// æ‰§è¡Œå®Œæ•´çš„å¯¹è¯å¾ªç¯
    ///
    /// è¿™æ˜¯æ ¸å¿ƒæ–¹æ³•ï¼Œå‚è€ƒ MIRIX çš„ AgentWrapper.step() å®ç°ï¼š
    /// 0. è·å–Working Memoryä¼šè¯ä¸Šä¸‹æ–‡
    /// 1. åˆ›å»ºç”¨æˆ·æ¶ˆæ¯
    /// 2. æ£€ç´¢ç›¸å…³è®°å¿†
    /// 3. æ„å»º promptï¼ˆæ³¨å…¥ä¼šè¯ä¸Šä¸‹æ–‡å’Œé•¿æœŸè®°å¿†ï¼‰
    /// 4. è°ƒç”¨ LLM
    /// 5. å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆå¦‚æœæœ‰ï¼‰- TODO: å¾…å®ç°
    /// 6. ä¿å­˜ assistant æ¶ˆæ¯
    /// 7. æ›´æ–° Working Memory
    /// 8. æå–å’Œæ›´æ–°è®°å¿†
    /// 9. è¿”å›å“åº”
    pub async fn step(&self, request: ChatRequest) -> Result<ChatResponse> {
        // âœ… éªŒè¯è¯·æ±‚å‚æ•°
        request.validate()?;

        info!("Starting conversation step for agent_id={}, user_id={}, session_id={}",
              request.agent_id, request.user_id, request.session_id);

        // 0. è·å–Working Memoryä¼šè¯ä¸Šä¸‹æ–‡
        let working_context = self.get_working_context(&request.session_id).await?;
        if !working_context.is_empty() {
            debug!("Retrieved working context: {} chars", working_context.len());
        }

        // 1. åˆ›å»ºç”¨æˆ·æ¶ˆæ¯
        let user_message_id = self.create_user_message(&request).await?;
        debug!("Created user message: {}", user_message_id);

        // 2. æ£€ç´¢ç›¸å…³è®°å¿†
        let memories = self.retrieve_memories(&request).await?;
        let memories_retrieved_count = memories.len();
        info!("Retrieved {} memories", memories_retrieved_count);

        // 3. æ„å»º promptï¼ˆæ³¨å…¥ä¼šè¯ä¸Šä¸‹æ–‡å’Œé•¿æœŸè®°å¿†ï¼‰
        let messages = self.build_messages_with_context(&request, &working_context, &memories).await?;
        debug!("Built {} messages with working context and memories", messages.len());

        // 4. è°ƒç”¨ LLMï¼ˆå¯èƒ½éœ€è¦å¤šè½®å·¥å…·è°ƒç”¨ï¼‰
        let (final_response, tool_calls_info) = self.execute_with_tools(
            &messages,
            &request.user_id,
        ).await?;
        debug!("Got final response: {} chars, {} tool calls",
            final_response.len(), tool_calls_info.len());

        // 5. ä¿å­˜ assistant æ¶ˆæ¯
        let assistant_message_id = self.create_assistant_message(
            &request.organization_id,
            &request.agent_id,
            &request.user_id,
            &final_response,
        ).await?;
        debug!("Created assistant message: {}", assistant_message_id);

        // 6. æ›´æ–°Working Memory
        self.update_working_memory(
            &request.session_id,
            &request.user_id,
            &request.agent_id,
            &request.message,
            &final_response,
        ).await?;
        debug!("Updated working memory for session {}", request.session_id);

        // 7. æå–å’Œæ›´æ–°è®°å¿†
        let memories_extracted = if self.config.auto_extract_memories {
            self.extract_and_update_memories(&request, &messages).await?
        } else {
            0
        };
        info!("Extracted and updated {} new memories", memories_extracted);

        // 8. è¿”å›å“åº”ï¼ˆâœ… memories_count ç°åœ¨è¡¨ç¤ºæ£€ç´¢ä½¿ç”¨çš„è®°å¿†æ•°é‡ï¼‰
        Ok(ChatResponse {
            message_id: assistant_message_id,
            content: final_response,
            memories_updated: memories_extracted > 0,
            memories_count: memories_retrieved_count,  // âœ… ä½¿ç”¨æ£€ç´¢åˆ°çš„è®°å¿†æ•°é‡
            tool_calls: if tool_calls_info.is_empty() {
                None
            } else {
                Some(tool_calls_info)
            },
        })
    }

    /// æ‰§è¡Œå¸¦å·¥å…·è°ƒç”¨çš„å¯¹è¯å¾ªç¯
    ///
    /// è¿™ä¸ªæ–¹æ³•æ”¯æŒå®Œæ•´çš„å·¥å…·è°ƒç”¨æµç¨‹ï¼š
    /// 1. åˆ›å»ºç”¨æˆ·æ¶ˆæ¯
    /// 2. æ£€ç´¢ç›¸å…³è®°å¿†
    /// 3. æ„å»º promptï¼ˆæ³¨å…¥è®°å¿†ï¼‰
    /// 4. è°ƒç”¨ LLMï¼ˆå¸¦å·¥å…·å®šä¹‰ï¼‰
    /// 5. å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œæ‰§è¡Œå·¥å…·å¹¶ç»§ç»­å¾ªç¯
    /// 6. ä¿å­˜ assistant æ¶ˆæ¯
    /// 7. æå–å’Œæ›´æ–°è®°å¿†
    /// 8. è¿”å›å“åº”
    pub async fn step_with_tools(
        &self,
        request: ChatRequest,
        available_tools: &[FunctionDefinition],
    ) -> Result<ChatResponse> {
        // âœ… éªŒè¯è¯·æ±‚å‚æ•°
        request.validate()?;

        info!(
            "Starting conversation step with tools for agent_id={}, user_id={}",
            request.agent_id, request.user_id
        );

        // 1. åˆ›å»ºç”¨æˆ·æ¶ˆæ¯
        let user_message_id = self.create_user_message(&request).await?;
        debug!("Created user message: {}", user_message_id);

        // 2. æ£€ç´¢ç›¸å…³è®°å¿†
        let memories = self.retrieve_memories(&request).await?;
        info!("Retrieved {} memories", memories.len());

        // 3. æ„å»º promptï¼ˆæ³¨å…¥è®°å¿†ï¼‰
        let mut messages = self.build_messages_with_memories(&request, &memories).await?;
        debug!("Built {} messages with memories", messages.len());

        let mut tool_calls_info = Vec::new();
        let mut final_response = String::new();
        let mut round = 0;

        // å·¥å…·è°ƒç”¨å¾ªç¯
        loop {
            round += 1;
            if round > self.config.max_tool_rounds {
                warn!("Reached max tool rounds ({}), stopping", self.config.max_tool_rounds);
                break;
            }

            // 4. è°ƒç”¨ LLMï¼ˆå¸¦å·¥å…·å®šä¹‰ï¼‰
            let llm_response = self
                .llm_client
                .generate_with_functions(&messages, available_tools)
                .await?;

            // æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æœ¬å“åº”
            if let Some(text) = &llm_response.text {
                final_response = text.clone();
                debug!("Got LLM text response: {} chars", text.len());
            }

            // æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if llm_response.function_calls.is_empty() {
                debug!("No tool calls, ending loop");
                break;
            }

            info!("Got {} tool calls", llm_response.function_calls.len());

            // 5. æ‰§è¡Œå·¥å…·è°ƒç”¨
            let tool_results = self
                .tool_integrator
                .execute_tool_calls(&llm_response.function_calls, &request.user_id)
                .await?;

            // è®°å½•å·¥å…·è°ƒç”¨ä¿¡æ¯
            for result in &tool_results {
                tool_calls_info.push(ToolCallInfo {
                    tool_name: result.tool_name.clone(),
                    arguments: serde_json::from_str(&result.arguments)
                        .unwrap_or(serde_json::json!({})),
                    result: Some(result.result.clone()),
                });
            }

            // å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
            let tool_results_text = self.tool_integrator.format_tool_results(&tool_results);
            messages.push(Message {
                role: agent_mem_traits::MessageRole::Assistant,
                content: tool_results_text,
                timestamp: Some(chrono::Utc::now()),
            });

            // å¦‚æœæ‰€æœ‰å·¥å…·éƒ½å¤±è´¥äº†ï¼Œåœæ­¢å¾ªç¯
            if tool_results.iter().all(|r| !r.success) {
                warn!("All tools failed, stopping loop");
                break;
            }
        }

        // 6. ä¿å­˜ assistant æ¶ˆæ¯
        let assistant_message_id = self
            .create_assistant_message(&request.organization_id, &request.agent_id, &request.user_id, &final_response)
            .await?;
        debug!("Created assistant message: {}", assistant_message_id);

        // 7. æå–å’Œæ›´æ–°è®°å¿†
        let memories_count = if self.config.auto_extract_memories {
            self.extract_and_update_memories(&request, &messages).await?
        } else {
            0
        };
        info!("Extracted and updated {} memories", memories_count);

        // 8. è¿”å›å“åº”
        Ok(ChatResponse {
            message_id: assistant_message_id,
            content: final_response,
            memories_updated: memories_count > 0,
            memories_count,
            tool_calls: if tool_calls_info.is_empty() {
                None
            } else {
                Some(tool_calls_info)
            },
        })
    }

    /// åˆ›å»ºç”¨æˆ·æ¶ˆæ¯
    async fn create_user_message(&self, request: &ChatRequest) -> Result<String> {
        use crate::storage::models::Message as DbMessage;

        // åˆ›å»ºç”¨æˆ·æ¶ˆæ¯
        let now = chrono::Utc::now();
        let message = DbMessage {
            id: Uuid::new_v4().to_string(),
            organization_id: request.organization_id.clone(),
            user_id: request.user_id.clone(),
            agent_id: request.agent_id.clone(),
            role: "user".to_string(),
            text: Some(request.message.clone()),
            content: None,
            model: None,
            name: None,
            tool_calls: None,
            tool_call_id: None,
            step_id: None,
            otid: None,
            tool_returns: None,
            group_id: None,
            sender_id: None,
            created_at: now,
            updated_at: now,
            is_deleted: false,
            created_by_id: None,
            last_updated_by_id: None,
        };

        // ä¿å­˜åˆ°æ•°æ®åº“
        let created_message = self.message_repo
            .create(&message)
            .await?;

        debug!("Created user message: {}", created_message.id);
        Ok(created_message.id)
    }

    /// åˆ›å»º assistant æ¶ˆæ¯
    async fn create_assistant_message(
        &self,
        organization_id: &str,
        agent_id: &str,
        user_id: &str,
        content: &str,
    ) -> Result<String> {
        use crate::storage::models::Message as DbMessage;

        // åˆ›å»º assistant æ¶ˆæ¯
        let now = chrono::Utc::now();
        let message = DbMessage {
            id: Uuid::new_v4().to_string(),
            organization_id: organization_id.to_string(),
            user_id: user_id.to_string(), // âœ… ä¿®å¤: ä»å‚æ•°è·å–è€Œéç¡¬ç¼–ç 
            agent_id: agent_id.to_string(),
            role: "assistant".to_string(),
            text: Some(content.to_string()),
            content: None,
            model: None,
            name: None,
            tool_calls: None,
            tool_call_id: None,
            step_id: None,
            otid: None,
            tool_returns: None,
            group_id: None,
            sender_id: None,
            created_at: now,
            updated_at: now,
            is_deleted: false,
            created_by_id: None,
            last_updated_by_id: None,
        };

        // ä¿å­˜åˆ°æ•°æ®åº“
        let created_message = self.message_repo
            .create(&message)
            .await?;

        debug!("Created assistant message: {}", created_message.id);
        Ok(created_message.id)
    }

    /// æ£€ç´¢ç›¸å…³è®°å¿†
    async fn retrieve_memories(&self, request: &ChatRequest) -> Result<Vec<Memory>> {
        // âœ… ä½¿ç”¨ MemoryIntegrator æ£€ç´¢è®°å¿†ï¼ˆå¸¦sessionéš”ç¦»ï¼‰
        let max_count = self.config.max_memories;
        
        // ä½¿ç”¨session_idå’Œuser_idè¿›è¡Œç²¾ç¡®è¿‡æ»¤
        let memories = self.memory_integrator
            .retrieve_relevant_memories_with_session(
                &request.message, 
                &request.agent_id,
                Some(&request.user_id),
                Some(&request.session_id),
                max_count
            )
            .await?;

        info!("ğŸ“‹ Retrieved {} memories for session={}, user={}", 
              memories.len(), request.session_id, request.user_id);

        // è¿‡æ»¤å’Œæ’åº
        let memories = self.memory_integrator.filter_by_relevance(memories);
        let memories = self.memory_integrator.sort_memories(memories);

        Ok(memories)
    }

    /// æ„å»ºåŒ…å«ä¼šè¯ä¸Šä¸‹æ–‡å’Œè®°å¿†çš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆæ–°ç‰ˆæœ¬ï¼Œé›†æˆWorking Memoryï¼‰
    async fn build_messages_with_context(
        &self,
        request: &ChatRequest,
        working_context: &str,
        memories: &[Memory],
    ) -> Result<Vec<Message>> {
        let mut messages = Vec::new();

        // æ„å»ºç³»ç»Ÿæ¶ˆæ¯ï¼Œä¼˜å…ˆçº§ï¼šWorking Context > é•¿æœŸè®°å¿†
        let mut system_message_parts = Vec::new();

        // 1. æ·»åŠ ä¼šè¯ä¸Šä¸‹æ–‡ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        if !working_context.is_empty() {
            system_message_parts.push(format!(
                "## âš ï¸ CURRENT SESSION CONTEXT (HIGHEST PRIORITY)\n\n\
                **IMPORTANT**: The following is the CURRENT conversation in THIS session. \
                This information has the HIGHEST priority and should OVERRIDE any conflicting information from past memories.\n\n\
                **Current Session History:**\n{}",
                working_context
            ));
        }

        // 2. æ·»åŠ é•¿æœŸè®°å¿†ï¼ˆä»…ä¾›å‚è€ƒï¼‰
        if !memories.is_empty() {
            let memory_context = self.memory_integrator.inject_memories_to_prompt(memories);
            system_message_parts.push(format!(
                "## ğŸ“š PAST MEMORIES (For Reference Only)\n\n\
                **Note**: The following are memories from PAST conversations. \
                If there is any conflict between these past memories and the current session context above, \
                ALWAYS prioritize the current session information.\n\n\
                {}",
                memory_context
            ));
        }

        // å¦‚æœæœ‰ä»»ä½•ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
        if !system_message_parts.is_empty() {
            let system_content = system_message_parts.join("\n\n");
            messages.push(Message::system(&system_content));
        }

        // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        messages.push(Message::user(&request.message));

        Ok(messages)
    }

    /// æ„å»ºåŒ…å«è®°å¿†çš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆä¿ç•™æ—§ç‰ˆæœ¬ä»¥å…¼å®¹ï¼‰
    async fn build_messages_with_memories(
        &self,
        request: &ChatRequest,
        memories: &[Memory],
    ) -> Result<Vec<Message>> {
        let mut messages = Vec::new();

        // æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯ï¼ˆåŒ…å«è®°å¿†ï¼‰
        if !memories.is_empty() {
            let memory_context = self.memory_integrator.inject_memories_to_prompt(memories);
            messages.push(Message::system(&memory_context));
        }

        // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        messages.push(Message::user(&request.message));

        Ok(messages)
    }

    /// æ‰§è¡Œå¸¦å·¥å…·è°ƒç”¨çš„ LLM å¯¹è¯
    ///
    /// å‚è€ƒ MIRIX çš„å®ç°ï¼Œæ”¯æŒå¤šè½®å·¥å…·è°ƒç”¨
    async fn execute_with_tools(
        &self,
        messages: &[Message],
        user_id: &str,
    ) -> Result<(String, Vec<ToolCallInfo>)> {
        let mut current_messages = messages.to_vec();
        let mut all_tool_calls = Vec::new();
        let mut round = 0;
        let max_rounds = 5; // æœ€å¤§å·¥å…·è°ƒç”¨è½®æ•°

        loop {
            round += 1;
            if round > max_rounds {
                warn!("Reached maximum tool call rounds ({})", max_rounds);
                break;
            }

            debug!("Tool call round {}/{}", round, max_rounds);

            // è·å–å¯ç”¨å·¥å…·
            let available_tools = self.get_available_tools().await;

            // è°ƒç”¨ LLMï¼ˆæ”¯æŒå·¥å…·è°ƒç”¨ï¼‰
            let llm_response = self.llm_client
                .generate_with_functions(&current_messages, &available_tools)
                .await?;

            // æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if llm_response.function_calls.is_empty() {
                // æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿”å›æ–‡æœ¬å“åº”
                let text = llm_response.text.unwrap_or_default();
                info!("LLM response without tool calls, {} total tool calls made", all_tool_calls.len());
                return Ok((text, all_tool_calls));
            }

            // æ‰§è¡Œå·¥å…·è°ƒç”¨
            info!("Executing {} tool call(s) in round {}", llm_response.function_calls.len(), round);
            let tool_results = self.tool_integrator
                .execute_tool_calls(&llm_response.function_calls, user_id)
                .await?;

            // è®°å½•å·¥å…·è°ƒç”¨ä¿¡æ¯
            for result in &tool_results {
                all_tool_calls.push(ToolCallInfo {
                    tool_name: result.tool_name.clone(),
                    arguments: serde_json::from_str(&result.arguments).unwrap_or(serde_json::json!({})),
                    result: if result.success {
                        Some(result.result.clone())
                    } else {
                        result.error.clone()
                    },
                });
            }

            // å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
            if let Some(assistant_text) = llm_response.text {
                current_messages.push(Message::assistant(&assistant_text));
            }

            // æ·»åŠ å·¥å…·ç»“æœæ¶ˆæ¯
            for result in &tool_results {
                let tool_message = if result.success {
                    format!("Tool '{}' result: {}", result.tool_name, result.result)
                } else {
                    format!("Tool '{}' error: {}", result.tool_name, result.error.as_ref().unwrap_or(&"Unknown error".to_string()))
                };
                current_messages.push(Message::system(&tool_message));
            }

            // ç»§ç»­ä¸‹ä¸€è½®ï¼ˆè®© LLM å¤„ç†å·¥å…·ç»“æœï¼‰
        }

        // å¦‚æœè¾¾åˆ°æœ€å¤§è½®æ•°ï¼Œè¿”å›æœ€åçš„æ¶ˆæ¯
        let final_text = "Maximum tool call rounds reached. Please try again.".to_string();
        Ok((final_text, all_tool_calls))
    }

    /// è·å–å¯ç”¨çš„å·¥å…·å®šä¹‰
    async fn get_available_tools(&self) -> Vec<FunctionDefinition> {
        // ä» ToolIntegrator è·å–å·¥å…·å®šä¹‰
        match self.tool_integrator.get_tool_definitions().await {
            Ok(tools) => tools,
            Err(e) => {
                warn!("Failed to get tool definitions: {}", e);
                Vec::new()
            }
        }
    }

    /// æå–å’Œæ›´æ–°è®°å¿†
    async fn extract_and_update_memories(
        &self,
        request: &ChatRequest,
        messages: &[Message],
    ) -> Result<usize> {
        // ä½¿ç”¨ MemoryExtractor æå–è®°å¿†
        let memories = self.memory_extractor
            .extract_from_conversation(messages, &request.agent_id, &request.user_id)
            .await?;

        // ä¿å­˜è®°å¿†
        let count = self.memory_extractor.save_memories(memories).await?;

        Ok(count)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_chat_request_creation() {
        let request = ChatRequest {
            message: "Hello, how are you?".to_string(),
            agent_id: "agent-123".to_string(),
            user_id: "user-456".to_string(),
            organization_id: "org-789".to_string(),
            stream: false,
            max_memories: 10,
        };

        assert_eq!(request.message, "Hello, how are you?");
        assert_eq!(request.agent_id, "agent-123");
        assert_eq!(request.user_id, "user-456");
        assert_eq!(request.organization_id, "org-789");
        assert!(!request.stream);
        assert_eq!(request.max_memories, 10);
    }

    #[test]
    fn test_chat_request_serialization() {
        let request = ChatRequest {
            message: "Test message".to_string(),
            agent_id: "agent-1".to_string(),
            user_id: "user-1".to_string(),
            organization_id: "default".to_string(),
            stream: true,
            max_memories: 5,
        };

        let json = serde_json::to_string(&request).unwrap();
        let deserialized: ChatRequest = serde_json::from_str(&json).unwrap();

        assert_eq!(request.message, deserialized.message);
        assert_eq!(request.stream, deserialized.stream);
    }

    #[test]
    fn test_chat_response_creation() {
        let response = ChatResponse {
            message_id: "msg-123".to_string(),
            content: "I'm doing well, thank you!".to_string(),
            memories_updated: true,
            memories_count: 3,
            tool_calls: None,
        };

        assert_eq!(response.message_id, "msg-123");
        assert!(response.memories_updated);
        assert_eq!(response.memories_count, 3);
        assert!(response.tool_calls.is_none());
    }

    #[test]
    fn test_chat_response_with_tool_calls() {
        let tool_call = ToolCallInfo {
            tool_name: "search".to_string(),
            arguments: serde_json::json!({"query": "weather"}),
            result: Some("Sunny, 25Â°C".to_string()),
        };

        let response = ChatResponse {
            message_id: "msg-456".to_string(),
            content: "The weather is sunny".to_string(),
            memories_updated: false,
            memories_count: 0,
            tool_calls: Some(vec![tool_call]),
        };

        assert!(response.tool_calls.is_some());
        assert_eq!(response.tool_calls.as_ref().unwrap().len(), 1);
        assert_eq!(response.tool_calls.as_ref().unwrap()[0].tool_name, "search");
    }

    #[test]
    fn test_tool_call_info_creation() {
        let tool_call = ToolCallInfo {
            tool_name: "calculator".to_string(),
            arguments: serde_json::json!({"operation": "add", "a": 5, "b": 3}),
            result: Some("8".to_string()),
        };

        assert_eq!(tool_call.tool_name, "calculator");
        assert!(tool_call.result.is_some());
        assert_eq!(tool_call.arguments["operation"], "add");
    }

    #[test]
    fn test_orchestrator_config_default() {
        let config = OrchestratorConfig::default();

        assert_eq!(config.max_tool_rounds, 5);
        assert_eq!(config.max_memories, 10);
        assert!(config.auto_extract_memories);
        assert_eq!(config.memory_extraction_threshold, 0.5);
        assert!(!config.enable_tool_calling);
    }

    #[test]
    fn test_orchestrator_config_custom() {
        let config = OrchestratorConfig {
            max_tool_rounds: 3,
            max_memories: 20,
            auto_extract_memories: false,
            memory_extraction_threshold: 0.7,
            enable_tool_calling: true,
        };

        assert_eq!(config.max_tool_rounds, 3);
        assert_eq!(config.max_memories, 20);
        assert!(!config.auto_extract_memories);
        assert_eq!(config.memory_extraction_threshold, 0.7);
        assert!(config.enable_tool_calling);
    }

    #[test]
    fn test_orchestrator_config_serialization() {
        let config = OrchestratorConfig::default();
        let json = serde_json::to_string(&config).unwrap();
        let deserialized: OrchestratorConfig = serde_json::from_str(&json).unwrap();

        assert_eq!(config.max_tool_rounds, deserialized.max_tool_rounds);
        assert_eq!(config.max_memories, deserialized.max_memories);
    }

    #[test]
    fn test_chat_request_with_empty_message() {
        let request = ChatRequest {
            message: "".to_string(),
            agent_id: "agent-1".to_string(),
            user_id: "user-1".to_string(),
            organization_id: "default".to_string(),
            stream: false,
            max_memories: 5,
        };

        assert!(request.message.is_empty());
    }

    #[test]
    fn test_chat_request_with_long_message() {
        let long_message = "A".repeat(10000);
        let request = ChatRequest {
            message: long_message.clone(),
            agent_id: "agent-1".to_string(),
            user_id: "user-1".to_string(),
            organization_id: "default".to_string(),
            stream: false,
            max_memories: 5,
        };

        assert_eq!(request.message.len(), 10000);
    }

    #[test]
    fn test_chat_response_serialization() {
        let response = ChatResponse {
            message_id: "msg-1".to_string(),
            content: "Response content".to_string(),
            memories_updated: true,
            memories_count: 2,
            tool_calls: None,
        };

        let json = serde_json::to_string(&response).unwrap();
        let deserialized: ChatResponse = serde_json::from_str(&json).unwrap();

        assert_eq!(response.message_id, deserialized.message_id);
        assert_eq!(response.memories_updated, deserialized.memories_updated);
    }

    #[test]
    fn test_tool_call_info_serialization() {
        let tool_call = ToolCallInfo {
            tool_name: "test_tool".to_string(),
            arguments: serde_json::json!({"param": "value"}),
            result: Some("success".to_string()),
        };

        let json = serde_json::to_string(&tool_call).unwrap();
        let deserialized: ToolCallInfo = serde_json::from_str(&json).unwrap();

        assert_eq!(tool_call.tool_name, deserialized.tool_name);
        assert_eq!(tool_call.result, deserialized.result);
    }

    #[tokio::test]
    async fn test_orchestrator_creation() {
        // TODO: æ·»åŠ å®Œæ•´çš„é›†æˆæµ‹è¯•
        // éœ€è¦ mock LLMClient, MemoryEngine, MessageRepository, ToolExecutor
    }
}

