//! Agent Orchestrator - å¯¹è¯å¾ªç¯ç¼–æ’
//!
//! è¿™æ˜¯ AgentMem çš„æ ¸å¿ƒå¯¹è¯å¾ªç¯å®ç°ï¼Œå‚è€ƒ MIRIX çš„ AgentWrapper.step() è®¾è®¡
//! é›†æˆæ‰€æœ‰ç°æœ‰æ¨¡å—ï¼šMemoryEngine, LLMClient, ToolExecutor, MessageRepository

use crate::{engine::MemoryEngine, storage::traits::MessageRepositoryTrait, Memory};

use agent_mem_llm::LLMClient;
use agent_mem_tools::ToolExecutor;
use agent_mem_traits::{llm::FunctionDefinition, AgentMemError, Message, Result};
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use tracing::{debug, info, warn};
use uuid::Uuid;

pub mod background_tasks;
pub mod memory_extraction;
pub mod memory_integration;
pub mod tool_integration;

use background_tasks::BackgroundTaskManager;
use memory_extraction::MemoryExtractor;
use memory_integration::MemoryIntegrator;
use tool_integration::{ToolIntegrator, ToolIntegratorConfig};

/// å¯¹è¯è¯·æ±‚
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatRequest {
    /// ç”¨æˆ·æ¶ˆæ¯
    pub message: String,

    /// Agent ID
    pub agent_id: String,

    /// ç”¨æˆ· ID
    pub user_id: String,

    /// ç»„ç»‡ ID (å¯é€‰ï¼Œé»˜è®¤ä¸º "default")
    #[serde(default = "default_organization_id")]
    pub organization_id: String,

    /// ä¼šè¯ ID - ç”¨äºWorking Memoryéš”ç¦»
    pub session_id: String,

    /// æ˜¯å¦æµå¼å“åº”
    pub stream: bool,

    /// æœ€å¤§è®°å¿†æ£€ç´¢æ•°é‡
    pub max_memories: usize,
}

impl ChatRequest {
    /// éªŒè¯è¯·æ±‚å‚æ•°
    pub fn validate(&self) -> Result<()> {
        // éªŒè¯æ¶ˆæ¯ä¸ä¸ºç©º
        if self.message.trim().is_empty() {
            return Err(AgentMemError::ValidationError(
                "Message cannot be empty".to_string(),
            ));
        }

        // éªŒè¯æ¶ˆæ¯é•¿åº¦ï¼ˆæœ€å¤§ 100KBï¼‰
        if self.message.len() > 100_000 {
            return Err(AgentMemError::ValidationError(format!(
                "Message too long: {} bytes (max 100KB)",
                self.message.len()
            )));
        }

        // éªŒè¯ agent_id ä¸ä¸ºç©º
        if self.agent_id.trim().is_empty() {
            return Err(AgentMemError::ValidationError(
                "Agent ID cannot be empty".to_string(),
            ));
        }

        // éªŒè¯ agent_id é•¿åº¦ï¼ˆæœ€å¤§ 255 å­—ç¬¦ï¼‰
        if self.agent_id.len() > 255 {
            return Err(AgentMemError::ValidationError(format!(
                "Agent ID too long: {} characters (max 255)",
                self.agent_id.len()
            )));
        }

        // éªŒè¯ user_id ä¸ä¸ºç©º
        if self.user_id.trim().is_empty() {
            return Err(AgentMemError::ValidationError(
                "User ID cannot be empty".to_string(),
            ));
        }

        // éªŒè¯ user_id é•¿åº¦ï¼ˆæœ€å¤§ 255 å­—ç¬¦ï¼‰
        if self.user_id.len() > 255 {
            return Err(AgentMemError::ValidationError(format!(
                "User ID too long: {} characters (max 255)",
                self.user_id.len()
            )));
        }

        // éªŒè¯ organization_id ä¸ä¸ºç©º
        if self.organization_id.trim().is_empty() {
            return Err(AgentMemError::ValidationError(
                "Organization ID cannot be empty".to_string(),
            ));
        }

        // éªŒè¯ organization_id é•¿åº¦ï¼ˆæœ€å¤§ 255 å­—ç¬¦ï¼‰
        if self.organization_id.len() > 255 {
            return Err(AgentMemError::ValidationError(format!(
                "Organization ID too long: {} characters (max 255)",
                self.organization_id.len()
            )));
        }

        // éªŒè¯ max_memories èŒƒå›´ï¼ˆ1-1000ï¼‰
        if self.max_memories == 0 {
            return Err(AgentMemError::ValidationError(
                "max_memories must be at least 1".to_string(),
            ));
        }

        if self.max_memories > 1000 {
            return Err(AgentMemError::ValidationError(format!(
                "max_memories too large: {} (max 1000)",
                self.max_memories
            )));
        }

        // éªŒè¯ session_id ä¸ä¸ºç©º
        if self.session_id.trim().is_empty() {
            return Err(AgentMemError::ValidationError(
                "Session ID cannot be empty".to_string(),
            ));
        }

        // éªŒè¯ session_id é•¿åº¦ï¼ˆæœ€å¤§ 255 å­—ç¬¦ï¼‰
        if self.session_id.len() > 255 {
            return Err(AgentMemError::ValidationError(format!(
                "Session ID too long: {} characters (max 255)",
                self.session_id.len()
            )));
        }

        Ok(())
    }
}

/// é»˜è®¤ç»„ç»‡ ID
fn default_organization_id() -> String {
    "default".to_string()
}

/// å¯¹è¯å“åº”
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatResponse {
    /// æ¶ˆæ¯ ID
    pub message_id: String,

    /// Agent å“åº”å†…å®¹
    pub content: String,

    /// æ˜¯å¦æ›´æ–°äº†è®°å¿†
    pub memories_updated: bool,

    /// æ›´æ–°çš„è®°å¿†æ•°é‡
    pub memories_count: usize,

    /// å·¥å…·è°ƒç”¨ï¼ˆå¦‚æœæœ‰ï¼‰
    pub tool_calls: Option<Vec<ToolCallInfo>>,
}

/// å·¥å…·è°ƒç”¨ä¿¡æ¯
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ToolCallInfo {
    pub tool_name: String,
    pub arguments: serde_json::Value,
    pub result: Option<String>,
}

/// Agent ç¼–æ’å™¨é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OrchestratorConfig {
    /// æœ€å¤§å·¥å…·è°ƒç”¨è½®æ•°
    pub max_tool_rounds: usize,

    /// æœ€å¤§è®°å¿†æ£€ç´¢æ•°é‡
    pub max_memories: usize,

    /// æ˜¯å¦è‡ªåŠ¨æå–è®°å¿†
    pub auto_extract_memories: bool,

    /// è®°å¿†æå–é˜ˆå€¼
    pub memory_extraction_threshold: f32,

    /// æ˜¯å¦å¯ç”¨å·¥å…·è°ƒç”¨
    pub enable_tool_calling: bool,
    
    /// â­ Phase 4: è‡ªé€‚åº”é…ç½®
    /// æ˜¯å¦å¯ç”¨è‡ªé€‚åº”è°ƒæ•´
    pub enable_adaptive: bool,
    
    /// TTFBé˜ˆå€¼(ms) - è¶…è¿‡æ­¤å€¼è§¦å‘é™çº§
    pub ttfb_threshold_ms: u64,
    
    /// Tokené¢„ç®—ä¸Šé™
    pub token_budget: usize,
}

impl Default for OrchestratorConfig {
    fn default() -> Self {
        Self {
            max_tool_rounds: 5,
            max_memories: 3,  // Phase 2/3ä¼˜åŒ–: ä»10é™åˆ°3
            auto_extract_memories: true,
            memory_extraction_threshold: 0.5,
            enable_tool_calling: false,
            
            // Phase 4: è‡ªé€‚åº”é…ç½®é»˜è®¤å€¼
            enable_adaptive: true,
            ttfb_threshold_ms: 5000,  // 5ç§’é˜ˆå€¼
            token_budget: 850,  // HCAMæ¨èå€¼
        }
    }
}

/// â­ æ€§èƒ½ç›‘æ§ç»Ÿè®¡
#[derive(Debug, Clone, Default)]
pub struct PerformanceMetrics {
    pub total_requests: u64,
    pub avg_ttfb_ms: f64,
    pub avg_prompt_chars: f64,
    pub avg_memories: f64,
    pub last_ttfb_ms: u64,
}

/// Agent ç¼–æ’å™¨ - æ ¸å¿ƒå¯¹è¯å¾ªç¯
///
/// å‚è€ƒ MIRIX çš„ AgentWrapper.step() å®ç°
/// é›†æˆæ‰€æœ‰ç°æœ‰æ¨¡å—å®ç°å®Œæ•´çš„å¯¹è¯å¾ªç¯
pub struct AgentOrchestrator {
    config: OrchestratorConfig,
    memory_engine: Arc<MemoryEngine>,
    message_repo: Arc<dyn MessageRepositoryTrait>,
    llm_client: Arc<LLMClient>,
    tool_executor: Arc<ToolExecutor>,
    memory_integrator: MemoryIntegrator,
    memory_extractor: Arc<MemoryExtractor>,
    tool_integrator: ToolIntegrator,
    /// Working Memory Store - ç”¨äºä¼šè¯çº§ä¸´æ—¶ä¸Šä¸‹æ–‡ï¼ˆæœ€å°æ”¹åŠ¨æ–¹æ¡ˆï¼šç›´æ¥ä½¿ç”¨Storeè€ŒéAgentï¼‰
    working_store: Option<Arc<dyn agent_mem_traits::WorkingMemoryStore>>,
    /// â­ æ€§èƒ½ç›‘æ§
    metrics: Arc<std::sync::RwLock<PerformanceMetrics>>,
    /// åå°ä»»åŠ¡ç®¡ç†å™¨
    background_tasks: Arc<BackgroundTaskManager>,
}

impl AgentOrchestrator {
    /// åˆ›å»ºæ–°çš„ç¼–æ’å™¨
    pub fn new(
        config: OrchestratorConfig,
        memory_engine: Arc<MemoryEngine>,
        message_repo: Arc<dyn MessageRepositoryTrait>,
        llm_client: Arc<LLMClient>,
        tool_executor: Arc<ToolExecutor>,
        working_store: Option<Arc<dyn agent_mem_traits::WorkingMemoryStore>>,
    ) -> Self {
        // åˆ›å»ºè®°å¿†é›†æˆå™¨
        let memory_integrator = MemoryIntegrator::with_default_config(memory_engine.clone());

        // åˆ›å»ºè®°å¿†æå–å™¨
        let memory_extractor =
            MemoryExtractor::with_default_config(llm_client.clone(), memory_engine.clone());

        // åˆ›å»ºå·¥å…·é›†æˆå™¨
        let tool_config = ToolIntegratorConfig {
            max_tool_rounds: config.max_tool_rounds,
            tool_timeout_seconds: 30,
            allow_parallel_execution: false,
        };
        let tool_integrator = ToolIntegrator::new(tool_config, tool_executor.clone());

        Self {
            config,
            memory_engine,
            message_repo,
            llm_client,
            tool_executor,
            memory_integrator,
            memory_extractor,
            tool_integrator,
            working_store,
            metrics: Arc::new(std::sync::RwLock::new(PerformanceMetrics::default())),
        }
    }

    /// ä»Working Memoryè·å–ä¼šè¯ä¸Šä¸‹æ–‡
    ///
    /// è¿™ä¸ªæ–¹æ³•ä»WorkingMemoryStoreè·å–å½“å‰ä¼šè¯çš„ä¸´æ—¶ä¸Šä¸‹æ–‡
    async fn get_working_context(&self, session_id: &str) -> Result<String> {
        if let Some(ref store) = self.working_store {
            match store.get_session_items(session_id).await {
                Ok(items) => {
                    if items.is_empty() {
                        debug!("No working memory items found for session: {}", session_id);
                        return Ok(String::new());
                    }

                    // æŒ‰ä¼˜å…ˆçº§å’Œæ—¶é—´æ’åºï¼ˆå·²åœ¨storeä¸­å®Œæˆï¼‰
                    // æ ¼å¼åŒ–ä¸ºå¯¹è¯ä¸Šä¸‹æ–‡
                    let context_lines: Vec<String> = items
                        .iter()
                        .map(|item| {
                            format!("[{}] {}", item.created_at.format("%H:%M:%S"), item.content)
                        })
                        .collect();

                    let context = context_lines.join("\n");
                    debug!(
                        "Retrieved {} working memory items for session {}: {} chars",
                        items.len(),
                        session_id,
                        context.len()
                    );
                    Ok(context)
                }
                Err(e) => {
                    warn!(
                        "Failed to get working context for session {}: {}",
                        session_id, e
                    );
                    Ok(String::new()) // å¤±è´¥æ—¶è¿”å›ç©ºï¼Œä¸å½±å“å¯¹è¯
                }
            }
        } else {
            debug!(
                "Working Memory store not configured, session_id: {}",
                session_id
            );
            Ok(String::new())
        }
    }

    /// æ›´æ–°Working Memory
    ///
    /// ä¿å­˜å½“å‰å¯¹è¯è½®æ¬¡åˆ°å·¥ä½œè®°å¿†
    async fn update_working_memory(
        &self,
        session_id: &str,
        user_id: &str,
        agent_id: &str,
        user_message: &str,
        assistant_response: &str,
    ) -> Result<()> {
        if let Some(ref store) = self.working_store {
            use agent_mem_traits::WorkingMemoryItem;
            use chrono::Utc;

            // æ ¼å¼åŒ–å¯¹è¯å¯¹
            let conversation_pair =
                format!("User: {}\nAssistant: {}", user_message, assistant_response);

            // åˆ›å»ºå·¥ä½œè®°å¿†é¡¹
            let item = WorkingMemoryItem {
                id: Uuid::new_v4().to_string(),
                user_id: user_id.to_string(),
                agent_id: agent_id.to_string(),
                session_id: session_id.to_string(),
                content: conversation_pair,
                priority: 1,                                                // é»˜è®¤ä¼˜å…ˆçº§
                expires_at: Some(Utc::now() + chrono::Duration::hours(24)), // 24å°æ—¶åè¿‡æœŸ
                metadata: serde_json::json!({}),
                created_at: Utc::now(),
            };

            match store.add_item(item).await {
                Ok(_) => {
                    debug!(
                        "Successfully added working memory item for session: {}",
                        session_id
                    );
                }
                Err(e) => {
                    warn!(
                        "Failed to add working memory item for session {}: {}",
                        session_id, e
                    );
                    // ä¸è¿”å›é”™è¯¯ï¼Œé¿å…å½±å“å¯¹è¯æµç¨‹
                }
            }
        } else {
            debug!(
                "Working Memory store not configured, skipping update for session: {}",
                session_id
            );
        }

        Ok(())
    }

    /// æ‰§è¡Œå®Œæ•´çš„å¯¹è¯å¾ªç¯
    ///
    /// è¿™æ˜¯æ ¸å¿ƒæ–¹æ³•ï¼Œå‚è€ƒ MIRIX çš„ AgentWrapper.step() å®ç°ï¼š
    /// 0. è·å–Working Memoryä¼šè¯ä¸Šä¸‹æ–‡
    /// 1. åˆ›å»ºç”¨æˆ·æ¶ˆæ¯
    /// 2. æ£€ç´¢ç›¸å…³è®°å¿†
    /// 3. æ„å»º promptï¼ˆæ³¨å…¥ä¼šè¯ä¸Šä¸‹æ–‡å’Œé•¿æœŸè®°å¿†ï¼‰
    /// 4. è°ƒç”¨ LLM
    /// 5. å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆå¦‚æœæœ‰ï¼‰- TODO: å¾…å®ç°
    /// 6. ä¿å­˜ assistant æ¶ˆæ¯
    /// 7. æ›´æ–° Working Memory
    /// 8. æå–å’Œæ›´æ–°è®°å¿†
    /// 9. è¿”å›å“åº”
    pub async fn step(&self, request: ChatRequest) -> Result<ChatResponse> {
        let start_time = std::time::Instant::now();
        
        // âœ… éªŒè¯è¯·æ±‚å‚æ•°
        request.validate()?;

        info!(
            "Starting conversation step for agent_id={}, user_id={}, session_id={}",
            request.agent_id, request.user_id, request.session_id
        );

        // 0. è·å–Working Memoryä¼šè¯ä¸Šä¸‹æ–‡
        let working_context = self.get_working_context(&request.session_id).await?;
        if !working_context.is_empty() {
            debug!("Retrieved working context: {} chars", working_context.len());
        }

        // 1. åˆ›å»ºç”¨æˆ·æ¶ˆæ¯
        let user_message_id = self.create_user_message(&request).await?;
        debug!("Created user message: {}", user_message_id);

        // â­ Phase 4: è‡ªé€‚åº”è°ƒæ•´ - æ ¹æ®æ€§èƒ½åŠ¨æ€è°ƒæ•´max_memories
        let adjusted_max_memories = if self.config.enable_adaptive {
            self.adaptive_adjust_memories(&request, start_time.elapsed()).await
        } else {
            request.max_memories
        };

        // 2. æ£€ç´¢ç›¸å…³è®°å¿†ï¼ˆä½¿ç”¨è°ƒæ•´åçš„æ•°é‡ï¼‰
        let mut adjusted_request = request.clone();
        adjusted_request.max_memories = adjusted_max_memories;
        let memories = self.retrieve_memories(&adjusted_request).await?;
        let memories_retrieved_count = memories.len();
        info!("Retrieved {} memories (adjusted from {} to {})", 
            memories_retrieved_count, request.max_memories, adjusted_max_memories);

        // 3. æ„å»º promptï¼ˆæ³¨å…¥ä¼šè¯ä¸Šä¸‹æ–‡å’Œé•¿æœŸè®°å¿†ï¼‰
        let messages = self
            .build_messages_with_context(&request, &working_context, &memories)
            .await?;
        debug!(
            "Built {} messages with working context and memories",
            messages.len()
        );

        // 4. è°ƒç”¨ LLMï¼ˆå¯èƒ½éœ€è¦å¤šè½®å·¥å…·è°ƒç”¨ï¼‰
        let (final_response, tool_calls_info) =
            self.execute_with_tools(&messages, &request.user_id).await?;
        debug!(
            "Got final response: {} chars, {} tool calls",
            final_response.len(),
            tool_calls_info.len()
        );

        // 5. ä¿å­˜ assistant æ¶ˆæ¯
        let assistant_message_id = self
            .create_assistant_message(
                &request.organization_id,
                &request.agent_id,
                &request.user_id,
                &final_response,
            )
            .await?;
        debug!("Created assistant message: {}", assistant_message_id);

        // 6. æ›´æ–°Working Memory
        self.update_working_memory(
            &request.session_id,
            &request.user_id,
            &request.agent_id,
            &request.message,
            &final_response,
        )
        .await?;
        debug!("Updated working memory for session {}", request.session_id);

        // 7. æå–å’Œæ›´æ–°è®°å¿†
        let memories_extracted = if self.config.auto_extract_memories {
            self.extract_and_update_memories(&request, &messages)
                .await?
        } else {
            0
        };
        info!("Extracted and updated {} new memories", memories_extracted);

        // â­ 8. æ›´æ–°æ€§èƒ½ç»Ÿè®¡
        let ttfb_ms = start_time.elapsed().as_millis() as u64;
        let prompt_chars: usize = messages.iter()
            .map(|m| m.content.len())
            .sum();
        self.update_metrics(ttfb_ms, prompt_chars, memories_retrieved_count);
        
        info!("ğŸ“Š Performance: TTFB={}ms, Prompt={}chars, Memories={}", 
            ttfb_ms, prompt_chars, memories_retrieved_count);

        // 9. è¿”å›å“åº”ï¼ˆâœ… memories_count ç°åœ¨è¡¨ç¤ºæ£€ç´¢ä½¿ç”¨çš„è®°å¿†æ•°é‡ï¼‰
        Ok(ChatResponse {
            message_id: assistant_message_id,
            content: final_response,
            memories_updated: memories_extracted > 0,
            memories_count: memories_retrieved_count, // âœ… ä½¿ç”¨æ£€ç´¢åˆ°çš„è®°å¿†æ•°é‡
            tool_calls: if tool_calls_info.is_empty() {
                None
            } else {
                Some(tool_calls_info)
            },
        })
    }
    
    /// â­ æ›´æ–°æ€§èƒ½ç»Ÿè®¡
    fn update_metrics(&self, ttfb_ms: u64, prompt_chars: usize, memories: usize) {
        if let Ok(mut metrics) = self.metrics.write() {
            let n = metrics.total_requests as f64;
            metrics.total_requests += 1;
            metrics.last_ttfb_ms = ttfb_ms;
            
            // ç§»åŠ¨å¹³å‡
            metrics.avg_ttfb_ms = (metrics.avg_ttfb_ms * n + ttfb_ms as f64) / (n + 1.0);
            metrics.avg_prompt_chars = (metrics.avg_prompt_chars * n + prompt_chars as f64) / (n + 1.0);
            metrics.avg_memories = (metrics.avg_memories * n + memories as f64) / (n + 1.0);
        }
    }
    
    /// â­ è·å–æ€§èƒ½ç»Ÿè®¡
    pub fn get_metrics(&self) -> PerformanceMetrics {
        self.metrics.read()
            .map(|m| m.clone())
            .unwrap_or_default()
    }

    /// æ‰§è¡Œå¸¦å·¥å…·è°ƒç”¨çš„å¯¹è¯å¾ªç¯
    ///
    /// è¿™ä¸ªæ–¹æ³•æ”¯æŒå®Œæ•´çš„å·¥å…·è°ƒç”¨æµç¨‹ï¼š
    /// 1. åˆ›å»ºç”¨æˆ·æ¶ˆæ¯
    /// 2. æ£€ç´¢ç›¸å…³è®°å¿†
    /// 3. æ„å»º promptï¼ˆæ³¨å…¥è®°å¿†ï¼‰
    /// 4. è°ƒç”¨ LLMï¼ˆå¸¦å·¥å…·å®šä¹‰ï¼‰
    /// 5. å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œæ‰§è¡Œå·¥å…·å¹¶ç»§ç»­å¾ªç¯
    /// 6. ä¿å­˜ assistant æ¶ˆæ¯
    /// 7. æå–å’Œæ›´æ–°è®°å¿†
    /// 8. è¿”å›å“åº”
    pub async fn step_with_tools(
        &self,
        request: ChatRequest,
        available_tools: &[FunctionDefinition],
    ) -> Result<ChatResponse> {
        // âœ… éªŒè¯è¯·æ±‚å‚æ•°
        request.validate()?;

        info!(
            "Starting conversation step with tools for agent_id={}, user_id={}",
            request.agent_id, request.user_id
        );

        // 1. åˆ›å»ºç”¨æˆ·æ¶ˆæ¯
        let user_message_id = self.create_user_message(&request).await?;
        debug!("Created user message: {}", user_message_id);

        // 2. æ£€ç´¢ç›¸å…³è®°å¿†
        let memories = self.retrieve_memories(&request).await?;
        info!("Retrieved {} memories", memories.len());

        // 3. æ„å»º promptï¼ˆæ³¨å…¥è®°å¿†ï¼‰
        let mut messages = self
            .build_messages_with_memories(&request, &memories)
            .await?;
        debug!("Built {} messages with memories", messages.len());

        let mut tool_calls_info = Vec::new();
        let mut final_response = String::new();
        let mut round = 0;

        // å·¥å…·è°ƒç”¨å¾ªç¯
        loop {
            round += 1;
            if round > self.config.max_tool_rounds {
                warn!(
                    "Reached max tool rounds ({}), stopping",
                    self.config.max_tool_rounds
                );
                break;
            }

            // 4. è°ƒç”¨ LLMï¼ˆå¸¦å·¥å…·å®šä¹‰ï¼‰
            let llm_response = self
                .llm_client
                .generate_with_functions(&messages, available_tools)
                .await?;

            // æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æœ¬å“åº”
            if let Some(text) = &llm_response.text {
                final_response = text.clone();
                debug!("Got LLM text response: {} chars", text.len());
            }

            // æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if llm_response.function_calls.is_empty() {
                debug!("No tool calls, ending loop");
                break;
            }

            info!("Got {} tool calls", llm_response.function_calls.len());

            // 5. æ‰§è¡Œå·¥å…·è°ƒç”¨
            let tool_results = self
                .tool_integrator
                .execute_tool_calls(&llm_response.function_calls, &request.user_id)
                .await?;

            // è®°å½•å·¥å…·è°ƒç”¨ä¿¡æ¯
            for result in &tool_results {
                tool_calls_info.push(ToolCallInfo {
                    tool_name: result.tool_name.clone(),
                    arguments: serde_json::from_str(&result.arguments)
                        .unwrap_or(serde_json::json!({})),
                    result: Some(result.result.clone()),
                });
            }

            // å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
            let tool_results_text = self.tool_integrator.format_tool_results(&tool_results);
            messages.push(Message {
                role: agent_mem_traits::MessageRole::Assistant,
                content: tool_results_text,
                timestamp: Some(chrono::Utc::now()),
            });

            // å¦‚æœæ‰€æœ‰å·¥å…·éƒ½å¤±è´¥äº†ï¼Œåœæ­¢å¾ªç¯
            if tool_results.iter().all(|r| !r.success) {
                warn!("All tools failed, stopping loop");
                break;
            }
        }

        // 6. ä¿å­˜ assistant æ¶ˆæ¯
        let assistant_message_id = self
            .create_assistant_message(
                &request.organization_id,
                &request.agent_id,
                &request.user_id,
                &final_response,
            )
            .await?;
        debug!("Created assistant message: {}", assistant_message_id);

        // 7. æå–å’Œæ›´æ–°è®°å¿†
        let memories_count = if self.config.auto_extract_memories {
            self.extract_and_update_memories(&request, &messages)
                .await?
        } else {
            0
        };
        info!("Extracted and updated {} memories", memories_count);

        // 8. è¿”å›å“åº”
        Ok(ChatResponse {
            message_id: assistant_message_id,
            content: final_response,
            memories_updated: memories_count > 0,
            memories_count,
            tool_calls: if tool_calls_info.is_empty() {
                None
            } else {
                Some(tool_calls_info)
            },
        })
    }

    /// åˆ›å»ºç”¨æˆ·æ¶ˆæ¯
    async fn create_user_message(&self, request: &ChatRequest) -> Result<String> {
        use crate::storage::models::Message as DbMessage;

        // åˆ›å»ºç”¨æˆ·æ¶ˆæ¯
        let now = chrono::Utc::now();
        let message = DbMessage {
            id: Uuid::new_v4().to_string(),
            organization_id: request.organization_id.clone(),
            user_id: request.user_id.clone(),
            agent_id: request.agent_id.clone(),
            role: "user".to_string(),
            text: Some(request.message.clone()),
            content: None,
            model: None,
            name: None,
            tool_calls: None,
            tool_call_id: None,
            step_id: None,
            otid: None,
            tool_returns: None,
            group_id: None,
            sender_id: None,
            created_at: now,
            updated_at: now,
            is_deleted: false,
            created_by_id: None,
            last_updated_by_id: None,
        };

        // ä¿å­˜åˆ°æ•°æ®åº“
        let created_message = self.message_repo.create(&message).await?;

        debug!("Created user message: {}", created_message.id);
        Ok(created_message.id)
    }

    /// åˆ›å»º assistant æ¶ˆæ¯
    async fn create_assistant_message(
        &self,
        organization_id: &str,
        agent_id: &str,
        user_id: &str,
        content: &str,
    ) -> Result<String> {
        use crate::storage::models::Message as DbMessage;

        // åˆ›å»º assistant æ¶ˆæ¯
        let now = chrono::Utc::now();
        let message = DbMessage {
            id: Uuid::new_v4().to_string(),
            organization_id: organization_id.to_string(),
            user_id: user_id.to_string(), // âœ… ä¿®å¤: ä»å‚æ•°è·å–è€Œéç¡¬ç¼–ç 
            agent_id: agent_id.to_string(),
            role: "assistant".to_string(),
            text: Some(content.to_string()),
            content: None,
            model: None,
            name: None,
            tool_calls: None,
            tool_call_id: None,
            step_id: None,
            otid: None,
            tool_returns: None,
            group_id: None,
            sender_id: None,
            created_at: now,
            updated_at: now,
            is_deleted: false,
            created_by_id: None,
            last_updated_by_id: None,
        };

        // ä¿å­˜åˆ°æ•°æ®åº“
        let created_message = self.message_repo.create(&message).await?;

        debug!("Created assistant message: {}", created_message.id);
        Ok(created_message.id)
    }

    /// æ£€ç´¢ç›¸å…³è®°å¿†
    /// â­ Phase 4: è‡ªé€‚åº”è°ƒæ•´è®°å¿†æ•°é‡
    /// æ ¹æ®å†å²æ€§èƒ½åŠ¨æ€è°ƒæ•´
    async fn adaptive_adjust_memories(&self, _request: &ChatRequest, elapsed: std::time::Duration) -> usize {
        let base_max = self.config.max_memories;
        let elapsed_ms = elapsed.as_millis() as u64;
        
        // å¦‚æœå·²ç»è¶…è¿‡é˜ˆå€¼ï¼Œå‡å°‘è®°å¿†æ•°é‡
        if elapsed_ms > self.config.ttfb_threshold_ms {
            let reduced = base_max.saturating_sub(1).max(1);
            warn!("âš ï¸  Adaptive: High latency {}ms > {}ms, reducing memories {} â†’ {}", 
                elapsed_ms, self.config.ttfb_threshold_ms, base_max, reduced);
            reduced
        } else if elapsed_ms < 1000 && base_max < 5 {
            // å¦‚æœæ€§èƒ½å¾ˆå¥½ï¼Œé€‚åº¦å¢åŠ 
            let increased = (base_max + 1).min(5);
            info!("âœ… Adaptive: Low latency {}ms, increasing memories {} â†’ {}", 
                elapsed_ms, base_max, increased);
            increased
        } else {
            base_max
        }
    }
    
    async fn retrieve_memories(&self, request: &ChatRequest) -> Result<Vec<Memory>> {
        // ğŸ†• Phase 1: ä½¿ç”¨ Episodic-firstæ£€ç´¢ï¼ˆåŸºäºè®¤çŸ¥ç†è®ºï¼‰
        // ç†è®ºä¾æ®: Atkinson-Shiffrinæ¨¡å‹ + HCAMåˆ†å±‚æ£€ç´¢
        let max_count = request.max_memories;

        // ä½¿ç”¨æ–°çš„ retrieve_episodic_first æ–¹æ³•
        // Priority 1: Episodic Memory (Agent/User) - ä¸»è¦æ¥æº
        // Priority 2: Working Memory (Session) - è¡¥å……ä¸Šä¸‹æ–‡
        // Priority 3: Semantic Memory (Agent global) - å¤‡é€‰
        let memories = self
            .memory_integrator
            .retrieve_episodic_first(
                &request.message,
                &request.agent_id,
                Some(&request.user_id),
                Some(&request.session_id),
                max_count,
            )
            .await?;

        info!(
            "ğŸ“‹ Retrieved {} memories (Episodic-first) for user={}, agent={}",
            memories.len(),
            request.user_id,
            request.agent_id
        );

        // ğŸ†• è®¤çŸ¥æ¶æ„éªŒè¯: æ—¥å¿—å·²åœ¨ retrieve_episodic_first ä¸­è®°å½•
        debug!("Memory sources: Episodic (ä¸»è¦) + Working (è¡¥å……) + Semantic (å¤‡é€‰)");

        // Phase 2/3: è¿‡æ»¤å’Œæ’åº
        let memories = self.memory_integrator.filter_by_relevance(memories);
        let memories = self.memory_integrator.sort_memories(memories);
        
        // Phase 5: å»é‡å’Œå‹ç¼©
        let memories = self.memory_integrator.deduplicate_memories(memories);
        let memories = self.memory_integrator.compress_memories(memories);

        Ok(memories)
    }

    /// â­ Phase 3: HCAMåˆ†å±‚Promptæ„å»ºï¼ˆæç®€é£æ ¼ï¼‰
    /// 
    /// ä¼˜åŒ–ç›®æ ‡ï¼šä»4606å­—ç¬¦é™è‡³<500å­—ç¬¦ï¼ˆ-89%ï¼‰
    /// ç†è®ºä¾æ®ï¼šHCAMæ¨¡å‹ - ç®€æ´ä¼˜å…ˆåŸåˆ™
    async fn build_messages_with_context(
        &self,
        request: &ChatRequest,
        working_context: &str,
        memories: &[Memory],
    ) -> Result<Vec<Message>> {
        use crate::prompt::MemorySummarizer;
        
        let mut messages = Vec::new();
        
        // âœ… Task 1.1: ä½¿ç”¨æ™ºèƒ½æ‘˜è¦å‹ç¼©è®°å¿†å†…å®¹
        // åˆ›å»ºæ‘˜è¦å™¨ï¼šæ¯æ¡è®°å¿†æœ€å¤§200å­—ç¬¦
        let summarizer = MemorySummarizer::new(200);

        // âœ… é™åˆ¶è®°å¿†æ•°é‡ä¸º3æ¡ï¼ˆå‡å°‘90% Promptå¤§å°ï¼‰
        let limited_memories = memories.iter().take(3);
        
        let mut memory_text = String::new();
        for (i, mem) in limited_memories.enumerate() {
                let content = match &mem.content {
                    agent_mem_traits::Content::Text(t) => t.as_str(),
                    _ => "[data]",
                };
            
            // âœ… æ™ºèƒ½æ‘˜è¦åŒ–æ¯æ¡è®°å¿†ï¼ˆä¿ç•™å¤´å°¾ä¿¡æ¯ï¼‰
            let summary = summarizer.summarize(content);
            
            // âœ… æç®€æ ¼å¼ï¼šç§»é™¤ç±»å‹æ ‡ç­¾ï¼ŒèŠ‚çœç©ºé—´
            memory_text.push_str(&format!("{}. {}\n", i + 1, summary));
            }
        
        // âœ… æç®€Promptæ¨¡æ¿
        let system_message = if memory_text.is_empty() {
            // æ— è®°å¿†æ—¶ï¼šä»…30å­—ç¬¦
            "You are a helpful assistant.".to_string()
        } else {
            // æœ‰è®°å¿†æ—¶ï¼šçº¦600-800å­—ç¬¦
            format!(
                "Context:\n{}\n\nUse context when relevant.",
                memory_text
            )
        };
        
        // æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages.push(Message::system(&system_message));
        messages.push(Message::user(&request.message));
        
        // è®°å½•Promptå¤§å°ï¼ˆç”¨äºç›‘æ§ï¼‰
        let total_chars = system_message.len() + request.message.len();
        debug!(
            "ğŸ“ Prompt size: {} chars (system: {}, user: {}), memories: {}/{}",
            total_chars,
            system_message.len(),
            request.message.len(),
            memories.iter().take(3).count(),
            memories.len()
        );

        Ok(messages)
    }

    /// æ„å»ºåŒ…å«è®°å¿†çš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆä¿ç•™æ—§ç‰ˆæœ¬ä»¥å…¼å®¹ï¼‰
    async fn build_messages_with_memories(
        &self,
        request: &ChatRequest,
        memories: &[Memory],
    ) -> Result<Vec<Message>> {
        let mut messages = Vec::new();

        // æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯ï¼ˆåŒ…å«è®°å¿†ï¼‰
        if !memories.is_empty() {
            let memory_context = self.memory_integrator.inject_memories_to_prompt(memories);
            messages.push(Message::system(&memory_context));
        }

        // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        messages.push(Message::user(&request.message));

        Ok(messages)
    }

    /// æ‰§è¡Œå¸¦å·¥å…·è°ƒç”¨çš„ LLM å¯¹è¯
    ///
    /// å‚è€ƒ MIRIX çš„å®ç°ï¼Œæ”¯æŒå¤šè½®å·¥å…·è°ƒç”¨
    async fn execute_with_tools(
        &self,
        messages: &[Message],
        user_id: &str,
    ) -> Result<(String, Vec<ToolCallInfo>)> {
        let mut current_messages = messages.to_vec();
        let mut all_tool_calls = Vec::new();
        let mut round = 0;
        let max_rounds = 5; // æœ€å¤§å·¥å…·è°ƒç”¨è½®æ•°

        loop {
            round += 1;
            if round > max_rounds {
                warn!("Reached maximum tool call rounds ({})", max_rounds);
                break;
            }

            debug!("Tool call round {}/{}", round, max_rounds);

            // è·å–å¯ç”¨å·¥å…·
            let available_tools = self.get_available_tools().await;

            // è°ƒç”¨ LLMï¼ˆæ”¯æŒå·¥å…·è°ƒç”¨ï¼‰
            let llm_response = self
                .llm_client
                .generate_with_functions(&current_messages, &available_tools)
                .await?;

            // æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if llm_response.function_calls.is_empty() {
                // æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿”å›æ–‡æœ¬å“åº”
                let text = llm_response.text.unwrap_or_default();
                info!(
                    "LLM response without tool calls, {} total tool calls made",
                    all_tool_calls.len()
                );
                return Ok((text, all_tool_calls));
            }

            // æ‰§è¡Œå·¥å…·è°ƒç”¨
            info!(
                "Executing {} tool call(s) in round {}",
                llm_response.function_calls.len(),
                round
            );
            let tool_results = self
                .tool_integrator
                .execute_tool_calls(&llm_response.function_calls, user_id)
                .await?;

            // è®°å½•å·¥å…·è°ƒç”¨ä¿¡æ¯
            for result in &tool_results {
                all_tool_calls.push(ToolCallInfo {
                    tool_name: result.tool_name.clone(),
                    arguments: serde_json::from_str(&result.arguments)
                        .unwrap_or(serde_json::json!({})),
                    result: if result.success {
                        Some(result.result.clone())
                    } else {
                        result.error.clone()
                    },
                });
            }

            // å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
            if let Some(assistant_text) = llm_response.text {
                current_messages.push(Message::assistant(&assistant_text));
            }

            // æ·»åŠ å·¥å…·ç»“æœæ¶ˆæ¯
            for result in &tool_results {
                let tool_message = if result.success {
                    format!("Tool '{}' result: {}", result.tool_name, result.result)
                } else {
                    format!(
                        "Tool '{}' error: {}",
                        result.tool_name,
                        result
                            .error
                            .as_ref()
                            .unwrap_or(&"Unknown error".to_string())
                    )
                };
                current_messages.push(Message::system(&tool_message));
            }

            // ç»§ç»­ä¸‹ä¸€è½®ï¼ˆè®© LLM å¤„ç†å·¥å…·ç»“æœï¼‰
        }

        // å¦‚æœè¾¾åˆ°æœ€å¤§è½®æ•°ï¼Œè¿”å›æœ€åçš„æ¶ˆæ¯
        let final_text = "Maximum tool call rounds reached. Please try again.".to_string();
        Ok((final_text, all_tool_calls))
    }

    /// è·å–å¯ç”¨çš„å·¥å…·å®šä¹‰
    async fn get_available_tools(&self) -> Vec<FunctionDefinition> {
        // ä» ToolIntegrator è·å–å·¥å…·å®šä¹‰
        match self.tool_integrator.get_tool_definitions().await {
            Ok(tools) => tools,
            Err(e) => {
                warn!("Failed to get tool definitions: {}", e);
                Vec::new()
            }
        }
    }

    /// æå–å’Œæ›´æ–°è®°å¿†
    async fn extract_and_update_memories(
        &self,
        request: &ChatRequest,
        messages: &[Message],
    ) -> Result<usize> {
        // ä½¿ç”¨ MemoryExtractor æå–è®°å¿†
        let memories = self
            .memory_extractor
            .extract_from_conversation(messages, &request.agent_id, &request.user_id)
            .await?;

        // ä¿å­˜è®°å¿†
        let count = self.memory_extractor.save_memories(memories).await?;

        Ok(count)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_chat_request_creation() {
        let request = ChatRequest {
            message: "Hello, how are you?".to_string(),
            agent_id: "agent-123".to_string(),
            user_id: "user-456".to_string(),
            session_id: "session-abc".to_string(),
            organization_id: "org-789".to_string(),
            stream: false,
            max_memories: 10,
        };

        assert_eq!(request.message, "Hello, how are you?");
        assert_eq!(request.agent_id, "agent-123");
        assert_eq!(request.user_id, "user-456");
        assert_eq!(request.session_id, "session-abc");
        assert_eq!(request.organization_id, "org-789");
        assert!(!request.stream);
        assert_eq!(request.max_memories, 10);
    }

    #[test]
    fn test_chat_request_serialization() {
        let request = ChatRequest {
            message: "Test message".to_string(),
            agent_id: "agent-1".to_string(),
            user_id: "user-1".to_string(),
            session_id: "session-1".to_string(),
            organization_id: "default".to_string(),
            stream: true,
            max_memories: 5,
        };

        let json = serde_json::to_string(&request).unwrap();
        let deserialized: ChatRequest = serde_json::from_str(&json).unwrap();

        assert_eq!(request.message, deserialized.message);
        assert_eq!(request.stream, deserialized.stream);
        assert_eq!(request.session_id, deserialized.session_id);
    }

    #[test]
    fn test_chat_response_creation() {
        let response = ChatResponse {
            message_id: "msg-123".to_string(),
            content: "I'm doing well, thank you!".to_string(),
            memories_updated: true,
            memories_count: 3,
            tool_calls: None,
        };

        assert_eq!(response.message_id, "msg-123");
        assert!(response.memories_updated);
        assert_eq!(response.memories_count, 3);
        assert!(response.tool_calls.is_none());
    }

    #[test]
    fn test_chat_response_with_tool_calls() {
        let tool_call = ToolCallInfo {
            tool_name: "search".to_string(),
            arguments: serde_json::json!({"query": "weather"}),
            result: Some("Sunny, 25Â°C".to_string()),
        };

        let response = ChatResponse {
            message_id: "msg-456".to_string(),
            content: "The weather is sunny".to_string(),
            memories_updated: false,
            memories_count: 0,
            tool_calls: Some(vec![tool_call]),
        };

        assert!(response.tool_calls.is_some());
        assert_eq!(response.tool_calls.as_ref().unwrap().len(), 1);
        assert_eq!(response.tool_calls.as_ref().unwrap()[0].tool_name, "search");
    }

    #[test]
    fn test_tool_call_info_creation() {
        let tool_call = ToolCallInfo {
            tool_name: "calculator".to_string(),
            arguments: serde_json::json!({"operation": "add", "a": 5, "b": 3}),
            result: Some("8".to_string()),
        };

        assert_eq!(tool_call.tool_name, "calculator");
        assert!(tool_call.result.is_some());
        assert_eq!(tool_call.arguments["operation"], "add");
    }

    #[test]
    fn test_orchestrator_config_default() {
        let config = OrchestratorConfig::default();

        assert_eq!(config.max_tool_rounds, 5);
        assert_eq!(config.max_memories, 10);
        assert!(config.auto_extract_memories);
        assert_eq!(config.memory_extraction_threshold, 0.5);
        assert!(!config.enable_tool_calling);
    }

    #[test]
    fn test_orchestrator_config_custom() {
        let config = OrchestratorConfig {
            max_tool_rounds: 3,
            max_memories: 20,
            auto_extract_memories: false,
            memory_extraction_threshold: 0.7,
            enable_tool_calling: true,
            enable_adaptive: false,
            token_budget: 8000,
            ttfb_threshold_ms: 500,
        };

        assert_eq!(config.max_tool_rounds, 3);
        assert_eq!(config.max_memories, 20);
        assert!(!config.auto_extract_memories);
        assert_eq!(config.memory_extraction_threshold, 0.7);
        assert!(config.enable_tool_calling);
    }

    #[test]
    fn test_orchestrator_config_serialization() {
        let config = OrchestratorConfig::default();
        let json = serde_json::to_string(&config).unwrap();
        let deserialized: OrchestratorConfig = serde_json::from_str(&json).unwrap();

        assert_eq!(config.max_tool_rounds, deserialized.max_tool_rounds);
        assert_eq!(config.max_memories, deserialized.max_memories);
    }

    #[test]
    fn test_chat_request_with_empty_message() {
        let request = ChatRequest {
            message: "".to_string(),
            agent_id: "agent-1".to_string(),
            user_id: "user-1".to_string(),
            session_id: "session-empty".to_string(),
            organization_id: "default".to_string(),
            stream: false,
            max_memories: 5,
        };

        assert!(request.message.is_empty());
    }

    #[test]
    fn test_chat_request_with_long_message() {
        let long_message = "A".repeat(10000);
        let request = ChatRequest {
            message: long_message.clone(),
            agent_id: "agent-1".to_string(),
            user_id: "user-1".to_string(),
            session_id: "session-long".to_string(),
            organization_id: "default".to_string(),
            stream: false,
            max_memories: 5,
        };

        assert_eq!(request.message.len(), 10000);
    }

    #[test]
    fn test_chat_response_serialization() {
        let response = ChatResponse {
            message_id: "msg-1".to_string(),
            content: "Response content".to_string(),
            memories_updated: true,
            memories_count: 2,
            tool_calls: None,
        };

        let json = serde_json::to_string(&response).unwrap();
        let deserialized: ChatResponse = serde_json::from_str(&json).unwrap();

        assert_eq!(response.message_id, deserialized.message_id);
        assert_eq!(response.memories_updated, deserialized.memories_updated);
    }

    #[test]
    fn test_tool_call_info_serialization() {
        let tool_call = ToolCallInfo {
            tool_name: "test_tool".to_string(),
            arguments: serde_json::json!({"param": "value"}),
            result: Some("success".to_string()),
        };

        let json = serde_json::to_string(&tool_call).unwrap();
        let deserialized: ToolCallInfo = serde_json::from_str(&json).unwrap();

        assert_eq!(tool_call.tool_name, deserialized.tool_name);
        assert_eq!(tool_call.result, deserialized.result);
    }

    #[tokio::test]
    async fn test_orchestrator_creation() {
        // TODO: æ·»åŠ å®Œæ•´çš„é›†æˆæµ‹è¯•
        // éœ€è¦ mock LLMClient, MemoryEngine, MessageRepository, ToolExecutor
    }
}
