//! è®°å¿†é›†æˆæ¨¡å— - è®°å¿†æ£€ç´¢å’Œæ³¨å…¥
//!
//! å‚è€ƒ MIRIX çš„è®°å¿†æ£€ç´¢é€»è¾‘ï¼Œå®ç°æ™ºèƒ½è®°å¿†æ£€ç´¢å’Œ prompt æ³¨å…¥

use crate::{engine::MemoryEngine, Memory};
use agent_mem_traits::{MemoryType, Result};
use regex::Regex;
use std::num::NonZeroUsize;
use std::sync::{
    atomic::{AtomicU64, Ordering},
    Arc, RwLock,
};
use tracing::{debug, info};

/// è®°å¿†é›†æˆå™¨é…ç½®
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct MemoryIntegratorConfig {
    /// æœ€å¤§æ£€ç´¢è®°å¿†æ•°é‡
    pub max_memories: usize,
    /// ç›¸å…³æ€§é˜ˆå€¼
    pub relevance_threshold: f32,
    /// æ˜¯å¦åŒ…å«æ—¶é—´ä¿¡æ¯
    pub include_timestamp: bool,
    /// æ˜¯å¦æŒ‰é‡è¦æ€§æ’åº
    pub sort_by_importance: bool,
    
    // ğŸ†• Phase 1.5: è®¤çŸ¥æ¶æ„æƒé‡é…ç½®ï¼ˆåŸºäºAdaptive Memory Frameworkï¼‰
    /// Episodic Memoryæƒé‡ï¼ˆLong-term Memoryä¼˜å…ˆï¼Œç†è®ºä¾æ®: Atkinson-Shiffrinï¼‰
    pub episodic_weight: f32,
    /// Working Memoryæƒé‡ï¼ˆè¡¥å……ä¸Šä¸‹æ–‡ï¼Œç†è®ºä¾æ®: Working Memoryå®¹é‡7Â±2ï¼‰
    pub working_weight: f32,
    /// Semantic Memoryæƒé‡ï¼ˆå¤‡é€‰ï¼Œç†è®ºä¾æ®: HCAMåˆ†å±‚æ£€ç´¢ï¼‰
    pub semantic_weight: f32,
    
    // â­ Phase 5: è®°å¿†å‹ç¼©é…ç½®
    /// å¯ç”¨è®°å¿†å‹ç¼©
    pub enable_compression: bool,
    /// å‹ç¼©é˜ˆå€¼ï¼ˆè¶…è¿‡æ­¤æ•°é‡å¯åŠ¨å‹ç¼©ï¼‰
    pub compression_threshold: usize,
}

#[derive(Debug)]
struct CacheMetrics {
    hits: AtomicU64,
    misses: AtomicU64,
    evictions: AtomicU64,
    size: AtomicU64,
}

impl CacheMetrics {
    fn new() -> Self {
        Self {
            hits: AtomicU64::new(0),
            misses: AtomicU64::new(0),
            evictions: AtomicU64::new(0),
            size: AtomicU64::new(0),
        }
    }

    fn record_hit(&self) {
        self.hits.fetch_add(1, Ordering::Relaxed);
    }

    fn record_miss(&self) {
        self.misses.fetch_add(1, Ordering::Relaxed);
    }

    fn record_eviction(&self) {
        self.evictions.fetch_add(1, Ordering::Relaxed);
    }

    fn set_size(&self, size: usize) {
        self.size.store(size as u64, Ordering::Relaxed);
    }

    #[allow(dead_code)]
    fn snapshot(&self) -> (u64, u64, u64, u64) {
        (
            self.hits.load(Ordering::Relaxed),
            self.misses.load(Ordering::Relaxed),
            self.evictions.load(Ordering::Relaxed),
            self.size.load(Ordering::Relaxed),
        )
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_normalize_cache_key() {
        let engine = Arc::new(MemoryEngine::new(Default::default()));
        let integrator = MemoryIntegrator::with_default_config(engine);

        let key = integrator.normalize_cache_key(
            "  Hello World ",
            "agent-1",
            Some("user-1"),
            Some("session-1"),
        );

        assert_eq!(
            key,
            "agent-1::user-1::session-1::hello world".to_string()
        );
    }
}

impl Default for MemoryIntegratorConfig {
    fn default() -> Self {
        Self {
            max_memories: 3, // Phase 2/3ä¼˜åŒ–
            relevance_threshold: 0.1,
            include_timestamp: true,
            sort_by_importance: true,
            
            // Phase 1.5: è®¤çŸ¥æ¶æ„æƒé‡
            episodic_weight: 1.2,
            working_weight: 1.0,
            semantic_weight: 0.9,
            
            // Phase 5: è®°å¿†å‹ç¼©
            enable_compression: true,
            compression_threshold: 10, // è¶…è¿‡10æ¡å¯åŠ¨å‹ç¼©
        }
    }
}

/// â­ ç®€å•ç¼“å­˜é¡¹
#[derive(Clone)]
struct CacheEntry {
    memories: Vec<Memory>,
    timestamp: std::time::Instant,
}

/// è®°å¿†é›†æˆå™¨
pub struct MemoryIntegrator {
    memory_engine: Arc<MemoryEngine>,
    config: MemoryIntegratorConfig,
    /// â­ ç®€å•LRUç¼“å­˜ (query -> memories)
    cache: Arc<RwLock<lru::LruCache<String, CacheEntry>>>,
    cache_metrics: CacheMetrics,
}

impl MemoryIntegrator {
    /// åˆ›å»ºæ–°çš„è®°å¿†é›†æˆå™¨
    pub fn new(memory_engine: Arc<MemoryEngine>, config: MemoryIntegratorConfig) -> Self {
        Self {
            memory_engine,
            config,
            cache: Arc::new(RwLock::new(lru::LruCache::new(
                NonZeroUsize::new(100).unwrap(),
            ))),
            cache_metrics: CacheMetrics::new(),
        }
    }

    /// ä½¿ç”¨é»˜è®¤é…ç½®åˆ›å»º
    pub fn with_default_config(memory_engine: Arc<MemoryEngine>) -> Self {
        Self::new(memory_engine, MemoryIntegratorConfig::default())
    }
    
    /// â­ æ£€æŸ¥ç¼“å­˜
    fn get_cached(&self, key: &str) -> Option<Vec<Memory>> {
        if let Ok(mut cache) = self.cache.write() {
            if let Some(entry) = cache.get(key) {
                if entry.timestamp.elapsed().as_secs() < 300 {
                    debug!("ğŸ¯ Cache hit for key: {}", &key[..key.len().min(50)]);
                    self.cache_metrics.record_hit();
                    return Some(entry.memories.clone());
                }

                cache.pop(key);
            }
        }

        self.cache_metrics.record_miss();
        None
    }

    fn normalize_cache_key(
        &self,
        query: &str,
        agent_id: &str,
        user_id: Option<&str>,
        session_id: Option<&str>,
    ) -> String {
        let normalized_query = query.trim().to_lowercase();
        let user_part = user_id.unwrap_or("_global");
        let session_part = session_id.unwrap_or("_session");
        format!(
            "{}::{}::{}::{}",
            agent_id, user_part, session_part, normalized_query
        )
    }
    
    /// â­ æ›´æ–°ç¼“å­˜
    fn update_cache(&self, key: String, memories: Vec<Memory>) {
        if let Ok(mut cache) = self.cache.write() {
            let evicted = cache.put(
                key,
                CacheEntry {
                memories: memories.clone(),
                timestamp: std::time::Instant::now(),
                },
            );

            if evicted.is_some() {
                self.cache_metrics.record_eviction();
            }

            self.cache_metrics.set_size(cache.len());
        }
    }

    /// å¤±æ•ˆæŒ‡å®šAgent/Userçš„ç¼“å­˜
    pub fn invalidate_cache(&self, agent_id: &str, user_id: Option<&str>) {
        if let Ok(mut cache) = self.cache.write() {
            let prefix = match user_id {
                Some(uid) => format!("{}::{}::", agent_id, uid),
                None => format!("{}::", agent_id),
            };

            let keys: Vec<String> = cache
                .iter()
                .map(|(k, _)| k.clone())
                .filter(|k| k.starts_with(&prefix))
                .collect();

            for key in keys {
                cache.pop(&key);
            }

            self.cache_metrics.set_size(cache.len());
            info!("ğŸ—‘ï¸  Invalidated cache entries with prefix {}", prefix);
        }
    }

    /// ä»å¯¹è¯ä¸­æ£€ç´¢ç›¸å…³è®°å¿†ï¼ˆæ”¯æŒsessionéš”ç¦»ï¼‰
    ///
    /// å‚è€ƒ MIRIX çš„ _retrieve_memories æ–¹æ³•ï¼Œå¢åŠ session_idæ”¯æŒ
    pub async fn retrieve_relevant_memories(
        &self,
        query: &str,
        agent_id: &str,
        max_count: usize,
    ) -> Result<Vec<Memory>> {
        self.retrieve_relevant_memories_with_session(query, agent_id, None, None, max_count)
            .await
    }

    /// æ£€ç´¢ç›¸å…³è®°å¿†ï¼ˆæ”¯æŒsessionå’Œuserè¿‡æ»¤ï¼‰
    pub async fn retrieve_relevant_memories_with_session(
        &self,
        query: &str,
        agent_id: &str,
        user_id: Option<&str>,
        session_id: Option<&str>,
        max_count: usize,
    ) -> Result<Vec<Memory>> {
        debug!(
            "Retrieving memories for agent_id={}, user_id={:?}, session_id={:?}, query={}",
            agent_id, user_id, session_id, query
        );

        // ä½¿ç”¨ MemoryEngine çš„æœç´¢åŠŸèƒ½
        use crate::hierarchy::MemoryScope;

        // æ ¹æ®å‚æ•°åˆ›å»ºæœ€ç²¾ç¡®çš„ scope
        let scope = if let (Some(uid), Some(sid)) = (user_id, session_id) {
            // æœ€é«˜ä¼˜å…ˆçº§ï¼šSession scopeï¼ˆä¼šè¯çº§åˆ«ï¼‰
            Some(MemoryScope::Session {
                agent_id: agent_id.to_string(),
                user_id: uid.to_string(),
                session_id: sid.to_string(),
            })
        } else if let Some(uid) = user_id {
            // ä¸­ä¼˜å…ˆçº§ï¼šUser scopeï¼ˆç”¨æˆ·çº§åˆ«ï¼‰
            Some(MemoryScope::User {
                agent_id: agent_id.to_string(),
                user_id: uid.to_string(),
            })
        } else {
            // ä½ä¼˜å…ˆçº§ï¼šAgent scopeï¼ˆä»…æŒ‰agentè¿‡æ»¤ï¼‰
            Some(MemoryScope::Agent(agent_id.to_string()))
        };

        // è°ƒç”¨ MemoryEngine è¿›è¡Œæœç´¢
        let scope_str = format!("{:?}", scope); // Clone scope info for logging
        let memories = self
            .memory_engine
            .search_memories(query, scope, Some(max_count))
            .await
            .map_err(|e| agent_mem_traits::AgentMemError::storage_error(e.to_string()))?;

        // è¿‡æ»¤ä½ç›¸å…³æ€§è®°å¿†ï¼ˆåŸºäº importance scoreï¼‰
        let filtered_memories: Vec<Memory> = memories
            .into_iter()
            .filter(|m| m.score().unwrap_or(0.0) >= self.config.relevance_threshold as f64)
            .collect();

        info!(
            "Retrieved {} relevant memories (filtered from search results, scope={})",
            filtered_memories.len(),
            scope_str
        );
        Ok(filtered_memories)
    }

    /// ğŸ†• Phase 1: Episodic-firstè®°å¿†æ£€ç´¢ï¼ˆåŸºäºè®¤çŸ¥ç†è®ºï¼‰
    ///
    /// ## ç†è®ºä¾æ®
    /// - **Atkinson-Shiffrinæ¨¡å‹**: Long-term Memoryåº”è¯¥æ˜¯ä¸»è¦æ£€ç´¢æº
    /// - **HCAM**: åˆ†å±‚æ£€ç´¢ï¼ˆç²—ç•¥â†’ç²¾ç»†ï¼‰
    /// - **Adaptive Framework**: åŠ¨æ€æƒé‡è°ƒæ•´
    ///
    /// ## æ£€ç´¢ç­–ç•¥ï¼ˆç¬¦åˆè®¤çŸ¥æ¨¡å‹ï¼‰
    /// 1. **Priority 1**: Episodic Memory (Agent/User scope) - ä¸»è¦æ¥æºï¼ˆ90%ï¼‰
    /// 2. **Priority 2**: Working Memory (Session scope) - è¡¥å……ä¸Šä¸‹æ–‡ï¼ˆ10%ï¼‰
    /// 3. **Priority 3**: Semantic Memory (Agent scope) - å¤‡é€‰
    ///
    /// ## æƒé‡è°ƒæ•´ï¼ˆåŸºäºAdaptive Frameworkï¼‰
    /// - Episodic Memory: æƒé‡ 1.2ï¼ˆæå‡ä¸»è¦æ¥æºï¼‰
    /// - Working Memory: æƒé‡ 1.0ï¼ˆæ­£å¸¸ï¼Œå› ä¸ºæ–°é²œï¼‰
    /// - Semantic Memory: æƒé‡ 0.9ï¼ˆé™ä½ï¼Œå› ä¸ºèŒƒå›´æ›´å¹¿ï¼‰
    pub async fn retrieve_episodic_first(
        &self,
        query: &str,
        agent_id: &str,
        user_id: Option<&str>,
        session_id: Option<&str>,
        max_count: usize,
    ) -> Result<Vec<Memory>> {
        // â­ å…ˆæ£€æŸ¥ç¼“å­˜
        let cache_key = self.normalize_cache_key(query, agent_id, user_id, session_id);
        if let Some(cached) = self.get_cached(&cache_key) {
            info!("ğŸ¯ Cache hit, returning {} cached memories", cached.len());
            return Ok(cached.into_iter().take(max_count).collect());
        }
        
        use crate::hierarchy::MemoryScope;
        use std::collections::HashSet;
        use tracing::warn;

        let mut all_memories = Vec::new();
        let mut seen_ids = HashSet::new();

        info!(
            "ğŸ§  Episodic-firstæ£€ç´¢ (ç†è®ºæŒ‡å¯¼): agent={}, user={:?}, session={:?}, target={}",
            agent_id, user_id, session_id, max_count
        );

        // ğŸ”§ ä¿®å¤: æ”¹è¿›å•†å“IDæ£€æµ‹ - ä»æŸ¥è¯¢ä¸­æå–å•†å“IDï¼ˆå³ä½¿åŒ…å«å…¶ä»–æ–‡æœ¬ï¼‰
        let product_id_pattern = Regex::new(r"P\d{6}").unwrap(); // ä¸è¦æ±‚å®Œå…¨åŒ¹é…ï¼Œå…è®¸åŒ…å«å…¶ä»–æ–‡æœ¬
        let extracted_product_id = product_id_pattern.find(query).map(|m| m.as_str());
        
        if let Some(product_id) = extracted_product_id {
            info!(
                "ğŸ¯ æ£€æµ‹åˆ°å•†å“IDæŸ¥è¯¢ï¼Œæå–ID: {} (from query: {})",
                product_id, query
            );
            
            // ä½¿ç”¨æå–çš„å•†å“IDè¿›è¡ŒæŸ¥è¯¢ï¼ˆè€Œä¸æ˜¯å®Œæ•´æŸ¥è¯¢ï¼‰
            let global_scope = MemoryScope::Global;
            match self
                .memory_engine
                .search_memories(product_id, Some(global_scope), Some(max_count * 2))
                .await
            {
                Ok(memories) if !memories.is_empty() => {
                    info!(
                        "âœ… Global Memory (å•†å“IDæŸ¥è¯¢) æ‰¾åˆ° {} æ¡è®°å¿†",
                        memories.len()
                    );
                    
                    // ğŸ”§ ä¿®å¤: ä¼˜å…ˆè¿”å›ç²¾ç¡®åŒ¹é…çš„å•†å“è®°å¿†ï¼Œè¿‡æ»¤å·¥ä½œè®°å¿†
                    let mut exact_product_memories = Vec::new();
                    let mut other_memories = Vec::new();
                    
                    for mut memory in memories {
                        if seen_ids.insert(memory.id.clone()) {
                            // æ£€æŸ¥æ˜¯å¦æ˜¯ç²¾ç¡®åŒ¹é…çš„å•†å“è®°å¿†
                            let content_str = match &memory.content {
                                agent_mem_traits::Content::Text(t) => t.as_str(),
                                agent_mem_traits::Content::Structured(v) => "",
                                _ => "",
                            };
                            let is_exact_product = {
                                content_str.contains(&format!("å•†å“ID: {}", product_id))
                                    || memory
                                        .attributes
                                    .get(&agent_mem_traits::AttributeKey::core("product_id"))
                                    .and_then(|attr_val| attr_val.as_string())
                                    .map(|pid| pid == product_id)
                                    .unwrap_or(false)
                            };
                            
                            // æ’é™¤å·¥ä½œè®°å¿†
                            let mem_type_opt = memory.memory_type();
                            let is_working_memory = mem_type_opt
                                .as_ref()
                                .map(|t| t.to_lowercase() == "working")
                                .unwrap_or(false);
                            
                            if is_exact_product && !is_working_memory {
                                // ç²¾ç¡®åŒ¹é…çš„å•†å“è®°å¿†ï¼Œæƒé‡æå‡
                                if let Some(score) = memory.score() {
                                    memory.set_score(score * 2.0); // å¤§å¹…æå‡æƒé‡
                                }
                                exact_product_memories.push(memory);
                            } else if !is_working_memory {
                                // å…¶ä»–ç›¸å…³è®°å¿†
                            if let Some(score) = memory.score() {
                                    memory.set_score(score * 1.2); // é€‚åº¦æå‡æƒé‡
                                }
                                other_memories.push(memory);
                            }
                        }
                    }
                    
                    // åˆå¹¶ï¼šç²¾ç¡®åŒ¹é…åœ¨å‰
                    let exact_count = exact_product_memories.len();
                    all_memories.extend(exact_product_memories);
                    all_memories.extend(other_memories);
                    
                    // å¦‚æœæ‰¾åˆ°è¶³å¤Ÿçš„ç»“æœï¼Œç›´æ¥è¿”å›
                    if all_memories.len() >= max_count {
                        info!(
                            "âœ… å•†å“IDæŸ¥è¯¢å®Œæˆï¼Œè¿”å› {} æ¡ç»“æœ (ç²¾ç¡®åŒ¹é…: {})",
                            all_memories.len(), 
                            exact_count
                        );
                        all_memories.sort_by(|a, b| {
                            b.score()
                                .unwrap_or(0.0)
                                .partial_cmp(&a.score().unwrap_or(0.0))
                                .unwrap_or(std::cmp::Ordering::Equal)
                        });
                        return Ok(all_memories.into_iter().take(max_count).collect());
                    }
                }
                Ok(_) => {
                    warn!(
                        "âš ï¸  Global MemoryæŸ¥è¯¢è¿”å›0ç»“æœ: product_id='{}'",
                        product_id
                    );
                }
                Err(e) => {
                    warn!("âš ï¸  Global MemoryæŸ¥è¯¢å¤±è´¥: {}, ç»§ç»­å…¶ä»–scopeæŸ¥è¯¢", e);
                }
            }
        }

        // ========== âœ… Task 1.2: å¹¶è¡ŒæŸ¥è¯¢ Priority 1 & 2 (ä¼˜åŒ–) ==========
        let mut query_count = 0;

        // âœ… ä¼˜åŒ–1: å¹¶è¡ŒæŸ¥è¯¢æœ€é‡è¦çš„ä¸¤å±‚ï¼ˆEpisodic + Workingï¼‰
        if let Some(uid) = user_id {
            let episodic_scope = MemoryScope::User {
                agent_id: agent_id.to_string(),
                user_id: uid.to_string(),
            };

            let working_scope = session_id.map(|sid| MemoryScope::Session {
                agent_id: agent_id.to_string(),
                user_id: uid.to_string(),
                session_id: sid.to_string(),
            });

            info!("ğŸ“šğŸ”„ [1-2/4] Parallel querying Episodic + Working Memory");

            let episodic_query = self.memory_engine.search_memories(
                query,
                Some(episodic_scope),
                Some(max_count * 2),
            );

            let working_query = if let Some(ws) = working_scope {
                Some(
                    self.memory_engine
                        .search_memories(query, Some(ws), Some(max_count / 2)),
                )
            } else {
                None
            };

            // âœ… å¹¶è¡Œæ‰§è¡Œ
            let (episodic_result, working_result) = if let Some(wq) = working_query {
                let (e, w) = tokio::join!(episodic_query, wq);
                (e, Some(w))
            } else {
                (episodic_query.await, None)
            };

            // å¤„ç† Episodic ç»“æœ
            match episodic_result {
                Ok(memories) => {
                    let count = memories.len();
                    query_count += 1;
                    for mut memory in memories {
                        if seen_ids.insert(memory.id.clone()) {
                        if let Some(score) = memory.score() {
                            memory.set_score(score * self.config.episodic_weight as f64);
                            }
                            all_memories.push(memory);
                        }
                    }
                    info!("ğŸ“š Episodic Memory returned {} memories", count);
                }
                Err(e) => {
                    warn!("âš ï¸  Episodic Memory query failed: {}", e);
                }
        }

            // å¤„ç† Working ç»“æœ
            if let Some(Ok(memories)) = working_result {
                    let mut added = 0;
                query_count += 1;
                    for memory in memories {
                        if seen_ids.insert(memory.id.clone()) {
                            all_memories.push(memory);
                            added += 1;
                        }
                    }
                info!("ğŸ”„ Working Memory added {} memories", added);
                }
        }

        // âœ… ä¼˜åŒ–2: æ—©åœæ£€æŸ¥1 - Episodic + Workingå·²è¶³å¤Ÿ
        if all_memories.len() >= max_count {
            let saved_queries = 2; // èŠ‚çœäº†Semanticå’ŒGlobalæŸ¥è¯¢
            info!(
                "âœ… Early stop after Priority 1-2: {} >= target {}, saved {} queries",
                all_memories.len(),
                max_count,
                saved_queries
            );

            // è®°å½•ç»Ÿè®¡
            self.record_query_stats(query_count, saved_queries);

            // æ’åºã€å»é‡ã€é™åˆ¶æ•°é‡
            all_memories.sort_by(|a, b| {
                b.score()
                    .unwrap_or(0.0)
                    .partial_cmp(&a.score().unwrap_or(0.0))
                    .unwrap_or(std::cmp::Ordering::Equal)
            });

            let result: Vec<Memory> = all_memories.into_iter().take(max_count).collect();

            // æ›´æ–°ç¼“å­˜
            self.update_cache(cache_key.clone(), result.clone());

            return Ok(result);
        }

        // ========== Priority 3: Semantic Memory (Agent Scope) ==========
        // âœ… ä¼˜åŒ–3: ä»…åœ¨éœ€è¦æ—¶æŸ¥è¯¢
        if all_memories.len() < max_count {
            let semantic_scope = MemoryScope::Agent(agent_id.to_string());

            let remaining = max_count.saturating_sub(all_memories.len());
            info!(
                "ğŸ“– [3/4] Querying Semantic Memory - need {} more",
                remaining
            );

            match self
                .memory_engine
                .search_memories(query, Some(semantic_scope), Some(remaining * 2))
                .await
            {
                Ok(memories) => {
                    let mut added = 0;
                    query_count += 1;
                    for mut memory in memories {
                        if seen_ids.insert(memory.id.clone()) {
                            if let Some(score) = memory.score() {
                                memory.set_score(score * self.config.semantic_weight as f64);
                            }
                            all_memories.push(memory);
                            added += 1;
                            if all_memories.len() >= max_count {
                                break;
                            }
                        }
                    }
                    info!("ğŸ“– Semantic Memory added {} memories", added);
                }
                Err(e) => {
                    warn!("âš ï¸  Semantic Memory query failed: {}", e);
                }
            }

            // âœ… ä¼˜åŒ–4: æ—©åœæ£€æŸ¥2 - åŠ ä¸ŠSemanticå·²è¶³å¤Ÿ
            if all_memories.len() >= max_count {
                let saved_queries = 1; // èŠ‚çœäº†GlobalæŸ¥è¯¢
                info!(
                    "âœ… Early stop after Priority 3: {} >= target {}, saved {} queries",
                    all_memories.len(),
                    max_count,
                    saved_queries
                );

                self.record_query_stats(query_count, saved_queries);

                all_memories.sort_by(|a, b| {
                    b.score()
                        .unwrap_or(0.0)
                        .partial_cmp(&a.score().unwrap_or(0.0))
                        .unwrap_or(std::cmp::Ordering::Equal)
                });

                let result: Vec<Memory> = all_memories.into_iter().take(max_count).collect();
                self.update_cache(cache_key.clone(), result.clone());

                return Ok(result);
            }
        }

        // ========== Priority 4: Global Memory (Global Scope) ==========
        // ç†è®ºä¾æ®: å…¨å±€çŸ¥è¯†åº“ï¼ŒåŒ…å«é€šç”¨çŸ¥è¯†ã€äº§å“ä¿¡æ¯ç­‰
        // ä¿®å¤: æ”¯æŒglobal scopeçš„å•†å“è®°å¿†ç­‰å…¨å±€çŸ¥è¯†
        if all_memories.len() < max_count {
            let global_scope = MemoryScope::Global;

            let remaining = max_count.saturating_sub(all_memories.len());
            info!(
                "ğŸŒ Priority 4: Querying Global Memory (Global scope) - éœ€è¦ {} æ›´å¤š",
                remaining
            );

            match self
                .memory_engine
                .search_memories(query, Some(global_scope), Some(remaining * 2))
                .await
            {
                Ok(memories) => {
                    let mut added = 0;
                    for mut memory in memories {
                        if seen_ids.insert(memory.id.clone()) {
                            // ğŸ¯ Global Memory æƒé‡ (å¯é…ç½®ï¼Œé™ä½å› ä¸ºèŒƒå›´æœ€å¹¿)
                            if let Some(score) = memory.score() {
                                memory.set_score(score * self.config.semantic_weight as f64);
                            }
                            all_memories.push(memory);
                            added += 1;
                            if all_memories.len() >= max_count {
                                break;
                            }
                        }
                    }
                    info!("ğŸŒ Global Memory added {} memories", added);
                }
                Err(e) => {
                    warn!("âš ï¸  Global Memory query failed: {}", e);
                }
            }
        }

        // æœ€ç»ˆç»“æœç»Ÿè®¡ï¼ˆè®¤çŸ¥æ¶æ„åˆ†ç±»ï¼‰
        let final_count = all_memories.len();
        let episodic_count = all_memories
            .iter()
            .filter(|m| {
                // ç®€å•åˆ¤æ–­ï¼šåŒ…å«user_idä½†ä¸åŒ…å«sessionçš„æ˜¯Episodic
                m.user_id().is_some() && !m.id.as_str().contains("session")
            })
            .count();
        let working_count = all_memories
            .iter()
            .filter(|m| m.id.as_str().contains("session"))
            .count();
        let semantic_count = final_count - episodic_count - working_count;

        info!(
            "âœ… æ£€ç´¢å®Œæˆ (è®¤çŸ¥æ¶æ„): {} memories (Episodic: {}, Working: {}, Semantic: {})",
            final_count, episodic_count, working_count, semantic_count
        );

        // æŒ‰è°ƒæ•´åçš„scoreæ’åº
        all_memories.sort_by(|a, b| {
            b.score()
                .unwrap_or(0.0)
                .partial_cmp(&a.score().unwrap_or(0.0))
                .unwrap_or(std::cmp::Ordering::Equal)
        });

        // è¿”å› top Nï¼ˆåŸºäºHCAMçš„ä¸¤é˜¶æ®µæ£€ç´¢ç»“æœï¼‰
        let result: Vec<Memory> = all_memories.into_iter().take(max_count).collect();
        
        // â­ æ›´æ–°ç¼“å­˜
        self.update_cache(cache_key, result.clone());
        
        Ok(result)
    }

    /// â­ Phase 3: æç®€è®°å¿†æ³¨å…¥æ ¼å¼ï¼ˆtokenä¼˜åŒ–ï¼‰
    /// 
    /// ä¼˜åŒ–ï¼šå»é™¤å†—é•¿è¯´æ˜ï¼Œåªä¿ç•™æ ¸å¿ƒä¿¡æ¯
    pub fn inject_memories_to_prompt(&self, memories: &[Memory]) -> String {
        if memories.is_empty() {
            return String::new();
        }

        let mut lines = Vec::new();
        for (i, memory) in memories.iter().enumerate().take(5) {
            // æœ€å¤š5æ¡
            let content_str = match &memory.content {
                agent_mem_traits::Content::Text(t) => t.as_str(),
                _ => "[data]",
            };
            // æç®€æ ¼å¼ï¼šåºå· + å†…å®¹ï¼ˆæœ€å¤š80å­—ç¬¦ï¼‰
            let truncated = if content_str.len() > 80 {
                format!("{}...", &content_str[..80])
            } else {
                content_str.to_string()
            };
            lines.push(format!("{}. {}", i + 1, truncated));
        }
        
        lines.join("\n")
    }

    /// æ ¼å¼åŒ–è®°å¿†ç±»å‹
    fn format_memory_type(&self, memory_type: &MemoryType) -> &str {
        match memory_type {
            MemoryType::Episodic => "Episodic",
            MemoryType::Semantic => "Semantic",
            MemoryType::Procedural => "Procedural",
            MemoryType::Working => "Working",
            MemoryType::Core => "Core",
            MemoryType::Resource => "Resource",
            MemoryType::Knowledge => "Knowledge",
            MemoryType::Contextual => "Contextual",
            MemoryType::Factual => "Factual",
        }
    }

    /// â­ Phase 2: ç»¼åˆè¯„åˆ†ç³»ç»Ÿ (relevance + importance + recency)
    /// 
    /// å€Ÿé‰´mem0çš„æœ€ä½³å®è·µï¼šç›¸å…³æ€§(50%) + é‡è¦æ€§(30%) + æ—¶æ•ˆæ€§(20%)
    pub fn calculate_comprehensive_score(&self, memory: &Memory) -> f64 {
        let relevance = memory.score().unwrap_or(0.5); // ç›¸ä¼¼åº¦åˆ†æ•°
        let importance = memory.importance().unwrap_or(0.5);
        
        // æ—¶æ•ˆæ€§è¡°å‡ï¼šä½¿ç”¨æŒ‡æ•°è¡°å‡ï¼ŒåŠè¡°æœŸä¸º30å¤©
        use chrono::Utc;
        let now = Utc::now();
        let age_seconds = (now - memory.metadata.created_at).num_seconds();
        let age_days = age_seconds as f64 / 86400.0;
        let recency = if age_days >= 0.0 {
            (-age_days / 30.0).exp() // æŒ‡æ•°è¡°å‡ï¼Œ30å¤©åŠè¡°æœŸ
        } else {
            1.0 // æœªæ¥æ—¶é—´ï¼ˆæ—¶é’Ÿåå·®ï¼‰ï¼Œé»˜è®¤1.0
        };
        
        // ç»¼åˆè¯„åˆ†ï¼š0.5 * relevance + 0.3 * importance + 0.2 * recency
        0.5 * relevance + 0.3 * importance + 0.2 * recency
    }
    
    /// æŒ‰ç»¼åˆè¯„åˆ†æ’åºè®°å¿†ï¼ˆPhase 2ä¼˜åŒ–ï¼‰
    pub fn sort_memories(&self, mut memories: Vec<Memory>) -> Vec<Memory> {
        if self.config.sort_by_importance {
            // Phase 2: ä½¿ç”¨ç»¼åˆè¯„åˆ†ä»£æ›¿å•ä¸€importance
            memories.sort_by(|a, b| {
                let score_a = self.calculate_comprehensive_score(a);
                let score_b = self.calculate_comprehensive_score(b);
                score_b
                    .partial_cmp(&score_a)
                    .unwrap_or(std::cmp::Ordering::Equal)
            });
        }
        memories
    }

    /// è¿‡æ»¤ä½ç›¸å…³æ€§è®°å¿†
    pub fn filter_by_relevance(&self, memories: Vec<Memory>) -> Vec<Memory> {
        info!(
            "ğŸ” filter_by_relevance: input={} memories, threshold={}",
            memories.len(),
            self.config.relevance_threshold
        );

        let filtered: Vec<Memory> = memories
            .into_iter()
            .filter(|m| {
                let importance = m.importance().unwrap_or(0.0);
                let keep = importance >= self.config.relevance_threshold as f64;
                info!(
                    "  Memory importance={:.3}, threshold={:.3}, keep={}",
                    importance, self.config.relevance_threshold, keep
                );
                keep
            })
            .collect();

        info!("ğŸ” filter_by_relevance: output={} memories", filtered.len());
        filtered
    }
    
    /// â­ Phase 5: è®°å¿†å»é‡
    /// ç§»é™¤å†…å®¹ç›¸ä¼¼çš„é‡å¤è®°å¿†
    pub fn deduplicate_memories(&self, memories: Vec<Memory>) -> Vec<Memory> {
        use std::collections::HashSet;
        
        let mut seen_content = HashSet::new();
        let mut dedup = Vec::new();
        
        for memory in memories {
            let content_key = match &memory.content {
                agent_mem_traits::Content::Text(t) => {
                    // ä½¿ç”¨å‰100å­—ç¬¦ä½œä¸ºå»é‡keyï¼Œç¡®ä¿å­—ç¬¦è¾¹ç•Œæ­£ç¡®
                    if t.len() > 100 {
                        // ä½¿ç”¨char_indicesæ‰¾åˆ°å®‰å…¨çš„å­—ç¬¦è¾¹ç•Œ
                        let mut char_count = 0;
                        let mut byte_index = 0;
                        for (i, _) in t.char_indices() {
                            if char_count >= 100 {
                                break;
                            }
                            char_count += 1;
                            byte_index = i;
                        }
                        &t[..byte_index]
                    } else {
                        t.as_str()
                    }
                }
                _ => continue,
            };
            
            if seen_content.insert(content_key.to_string()) {
                dedup.push(memory);
            } else {
                debug!("ğŸ”„ Deduplicate: skipping duplicate memory");
            }
        }
        
        info!(
            "ğŸ”„ Deduplicate: {} â†’ {} memories",
            seen_content.len() + (dedup.len() - seen_content.len()),
            dedup.len()
        );
        dedup
    }
    
    /// â­ Phase 5: è®°å¿†å‹ç¼©ï¼ˆç®€åŒ–ç‰ˆï¼‰
    /// å½“è®°å¿†æ•°é‡è¿‡å¤šæ—¶ï¼Œåªä¿ç•™æœ€é‡è¦çš„
    pub fn compress_memories(&self, memories: Vec<Memory>) -> Vec<Memory> {
        if !self.config.enable_compression || memories.len() <= self.config.compression_threshold {
            return memories;
        }
        
        info!(
            "ğŸ“¦ Compression: {} memories exceed threshold {}, keeping top {}",
            memories.len(),
            self.config.compression_threshold,
            self.config.compression_threshold / 2
        );
        
        // ç®€å•ç­–ç•¥ï¼šåªä¿ç•™æœ€é‡è¦çš„å‰Næ¡
        let keep_count = self.config.compression_threshold / 2;
        let mut result: Vec<Memory> = memories.into_iter().take(keep_count).collect();
        
        info!(
            "ğŸ“¦ Compressed: kept {} most important memories",
            result.len()
        );
        result
    }

    /// âœ… Task 1.2: è®°å½•æŸ¥è¯¢ç»Ÿè®¡ä¿¡æ¯
    /// ç”¨äºç›‘æ§æ—©åœä¼˜åŒ–æ•ˆæœ
    fn record_query_stats(&self, actual_queries: usize, saved_queries: usize) {
        if saved_queries > 0 {
            info!(
                "ğŸ“Š Query optimization: executed {} queries, saved {} queries ({:.1}% reduction)",
                actual_queries,
                saved_queries,
                (saved_queries as f64 / (actual_queries + saved_queries) as f64) * 100.0
            );
        }
    }
}
