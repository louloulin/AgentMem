//! ç»¼åˆè‡ªé€‚åº”æœç´¢éªŒè¯æµ‹è¯•
//!
//! åŒ…å«æ›´å¤šçœŸå®åœºæ™¯å’Œè¾¹ç•Œæƒ…å†µçš„éªŒè¯

use std::sync::Arc;
use agent_mem_config::agentmem_config::AgentMemConfig;
use agent_mem_core::search::{
    AdaptiveSearchOptimizer, QueryFeatures, SearchQuery, SearchReranker, SearchResult,
    SearchWeights, WeightPredictor,
};

/// æµ‹è¯•å¤šè¯­è¨€æŸ¥è¯¢æ”¯æŒ
#[test]
fn test_multilingual_query_support() {
    let test_cases = vec![
        ("user@example.com", "è‹±æ–‡é‚®ç®±"),
        ("ç”¨æˆ·@ç¤ºä¾‹.com", "ä¸­æ–‡é‚®ç®±"),
        ("What is AI?", "è‹±æ–‡é—®å¥"),
        ("ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ", "ä¸­æ–‡é—®å¥"),
        ("æ˜¨å¤©å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ", "ä¸­æ–‡æ—¶é—´æŸ¥è¯¢"),
        ("yesterday meeting", "è‹±æ–‡æ—¶é—´æŸ¥è¯¢"),
        ("@å¼ ä¸‰ è¯´è¿‡ #é¡¹ç›® å¾ˆé‡è¦", "ä¸­æ–‡å®ä½“"),
        ("@John mentioned #project", "è‹±æ–‡å®ä½“"),
    ];

    let config = Arc::new(AgentMemConfig::default().search);
    let optimizer = AdaptiveSearchOptimizer::new(config);

    println!("\n=== å¤šè¯­è¨€æŸ¥è¯¢æ”¯æŒæµ‹è¯• ===\n");

    for (query_text, description) in test_cases {
        let query = SearchQuery {
            query: query_text.to_string(),
            ..Default::default()
        };

        let (_, weights) = optimizer.optimize_query(&query);

        println!("åœºæ™¯: {}", description);
        println!("æŸ¥è¯¢: \"{}\"", query_text);
        println!("  å‘é‡æƒé‡: {:.3}", weights.vector_weight);
        println!("  å…¨æ–‡æƒé‡: {:.3}", weights.fulltext_weight);

        // éªŒè¯æƒé‡æœ‰æ•ˆæ€§
        assert!(weights.vector_weight >= 0.0 && weights.vector_weight <= 1.0);
        assert!(weights.fulltext_weight >= 0.0 && weights.fulltext_weight <= 1.0);
        assert!((weights.vector_weight + weights.fulltext_weight - 1.0).abs() < 0.001);

        println!("  âœ… æƒé‡æœ‰æ•ˆ\n");
    }
}

/// æµ‹è¯•æç«¯é•¿åº¦æŸ¥è¯¢
#[test]
fn test_extreme_length_queries() {
    let config = Arc::new(AgentMemConfig::default().search);
    let optimizer = AdaptiveSearchOptimizer::new(config);

    // æçŸ­æŸ¥è¯¢
    let very_short = vec!["a", "x", "?", "!", "@"];

    println!("\n=== æçŸ­æŸ¥è¯¢æµ‹è¯• ===\n");
    for query_text in very_short {
        let query = SearchQuery {
            query: query_text.to_string(),
            ..Default::default()
        };

        let (_, weights) = optimizer.optimize_query(&query);
        println!(
            "æŸ¥è¯¢: \"{}\" â†’ vector={:.3}, fulltext={:.3}",
            query_text, weights.vector_weight, weights.fulltext_weight
        );

        assert!((weights.vector_weight + weights.fulltext_weight - 1.0).abs() < 0.001);
    }

    // æé•¿æŸ¥è¯¢
    let very_long =
        "This is an extremely long query that contains multiple sentences and paragraphs. "
            .repeat(20);

    println!("\n=== æé•¿æŸ¥è¯¢æµ‹è¯• ===\n");
    let query = SearchQuery {
        query: very_long.clone(),
        ..Default::default()
    };

    let (_, weights) = optimizer.optimize_query(&query);
    println!("æŸ¥è¯¢é•¿åº¦: {} å­—ç¬¦", very_long.len());
    println!("  å‘é‡æƒé‡: {:.3}", weights.vector_weight);
    println!("  å…¨æ–‡æƒé‡: {:.3}", weights.fulltext_weight);

    assert!((weights.vector_weight + weights.fulltext_weight - 1.0).abs() < 0.001);
}

/// æµ‹è¯•ç‰¹æ®Šå­—ç¬¦å’Œç¬¦å·
#[test]
fn test_special_characters() {
    let special_queries = vec![
        ("!@#$%^&*()", "ç‰¹æ®Šç¬¦å·"),
        ("user@example.com", "é‚®ç®±ç¬¦å·"),
        ("C++ programming", "ç¼–ç¨‹ç¬¦å·"),
        ("ä»·æ ¼$99.99", "è´§å¸ç¬¦å·"),
        ("50% discount", "ç™¾åˆ†å·"),
        ("file.txt", "æ–‡ä»¶æ‰©å±•å"),
        ("/path/to/file", "è·¯å¾„"),
        ("https://example.com", "URL"),
        ("(parentheses) [brackets] {braces}", "æ‹¬å·"),
        ("emoji ğŸ˜€ ğŸ‘ ğŸ‰", "è¡¨æƒ…ç¬¦å·"),
    ];

    let config = Arc::new(AgentMemConfig::default().search);
    let optimizer = AdaptiveSearchOptimizer::new(config);

    println!("\n=== ç‰¹æ®Šå­—ç¬¦æµ‹è¯• ===\n");

    for (query_text, description) in special_queries {
        let query = SearchQuery {
            query: query_text.to_string(),
            ..Default::default()
        };

        let (_, weights) = optimizer.optimize_query(&query);

        println!("{}: \"{}\"", description, query_text);
        println!(
            "  vector={:.3}, fulltext={:.3}",
            weights.vector_weight, weights.fulltext_weight
        );

        assert!((weights.vector_weight + weights.fulltext_weight - 1.0).abs() < 0.001);
    }
}

/// æµ‹è¯•æƒé‡ä¸€è‡´æ€§
#[test]
fn test_weight_consistency() {
    let config = Arc::new(AgentMemConfig::default().search);
    let optimizer = AdaptiveSearchOptimizer::new(config);

    // ç›¸åŒæŸ¥è¯¢åº”è¯¥å¾—åˆ°ç›¸åŒçš„æƒé‡
    let query_text = "How does machine learning work?";

    let mut weights_list = Vec::new();

    for _ in 0..10 {
        let query = SearchQuery {
            query: query_text.to_string(),
            ..Default::default()
        };

        let (_, weights) = optimizer.optimize_query(&query);
        weights_list.push((weights.vector_weight, weights.fulltext_weight));
    }

    // éªŒè¯æ‰€æœ‰æƒé‡ç›¸åŒ
    let first = weights_list[0];
    for weights in &weights_list[1..] {
        assert_eq!(weights.0, first.0, "å‘é‡æƒé‡åº”è¯¥ä¸€è‡´");
        assert_eq!(weights.1, first.1, "å…¨æ–‡æƒé‡åº”è¯¥ä¸€è‡´");
    }

    println!("âœ… æƒé‡ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡ï¼š10æ¬¡æŸ¥è¯¢å¾—åˆ°ç›¸åŒæƒé‡");
}

/// æµ‹è¯•é‡æ’åºçš„ç¨³å®šæ€§
#[test]
fn test_reranker_stability() {
    let reranker = SearchReranker::new();

    // åˆ›å»ºæµ‹è¯•ç»“æœé›†
    let results = vec![
        SearchResult {
            id: "1".to_string(),
            content: "First result".to_string(),
            score: 0.9,
            vector_score: Some(0.9),
            fulltext_score: None,
            metadata: None,
        },
        SearchResult {
            id: "2".to_string(),
            content: "Second result".to_string(),
            score: 0.85,
            vector_score: Some(0.85),
            fulltext_score: None,
            metadata: None,
        },
        SearchResult {
            id: "3".to_string(),
            content: "Third result".to_string(),
            score: 0.8,
            vector_score: Some(0.8),
            fulltext_score: None,
            metadata: None,
        },
    ];

    let query = SearchQuery {
        query: "test".to_string(),
        ..Default::default()
    };

    // å¤šæ¬¡é‡æ’åºåº”è¯¥å¾—åˆ°ç›¸åŒç»“æœ
    let reranked1 = reranker.rerank(results.clone(), &query);
    let reranked2 = reranker.rerank(results.clone(), &query);
    let reranked3 = reranker.rerank(results, &query);

    assert_eq!(reranked1.len(), reranked2.len());
    assert_eq!(reranked2.len(), reranked3.len());

    for i in 0..reranked1.len() {
        assert_eq!(reranked1[i].id, reranked2[i].id);
        assert_eq!(reranked2[i].id, reranked3[i].id);
        assert!((reranked1[i].score - reranked2[i].score).abs() < 0.0001);
    }

    println!("âœ… é‡æ’åºç¨³å®šæ€§æµ‹è¯•é€šè¿‡");
}

/// æµ‹è¯•å¹¶å‘å®‰å…¨æ€§
#[tokio::test]
async fn test_concurrent_optimization() {
    use std::sync::Arc;
    use tokio::sync::RwLock;

    let config = Arc::new(AgentMemConfig::default().search);
    let optimizer = Arc::new(RwLock::new(AdaptiveSearchOptimizer::new(config)));

    let queries = vec![
        "user@example.com",
        "How does AI work?",
        "yesterday",
        "simple query",
        "complex technical question about distributed systems",
    ];

    let mut handles = vec![];

    for query_text in queries {
        let optimizer = optimizer.clone();
        let query_text = query_text.to_string();

        let handle = tokio::spawn(async move {
            let optimizer = optimizer.read().await;
            let query = SearchQuery {
                query: query_text.clone(),
                ..Default::default()
            };

            let (_, weights) = optimizer.optimize_query(&query);

            // éªŒè¯æƒé‡æœ‰æ•ˆæ€§
            assert!(weights.vector_weight >= 0.0 && weights.vector_weight <= 1.0);
            assert!(weights.fulltext_weight >= 0.0 && weights.fulltext_weight <= 1.0);
            assert!((weights.vector_weight + weights.fulltext_weight - 1.0).abs() < 0.001);

            query_text
        });

        handles.push(handle);
    }

    let results = futures::future::join_all(handles).await;

    for result in results {
        assert!(result.is_ok(), "å¹¶å‘æŸ¥è¯¢ä¸åº”è¯¥å¤±è´¥");
    }

    println!("âœ… å¹¶å‘å®‰å…¨æ€§æµ‹è¯•é€šè¿‡");
}

/// æµ‹è¯•æ€§èƒ½é€€åŒ–æ£€æµ‹
#[test]
fn test_performance_degradation() {
    let config = Arc::new(AgentMemConfig::default().search);
    let optimizer = AdaptiveSearchOptimizer::new(config);

    use std::time::Instant;

    let queries: Vec<String> = (0..1000)
        .map(|i| format!("test query number {}", i))
        .collect();

    let start = Instant::now();

    for query_text in &queries {
        let query = SearchQuery {
            query: query_text.clone(),
            ..Default::default()
        };

        let (_, _weights) = optimizer.optimize_query(&query);
    }

    let elapsed = start.elapsed();
    let avg_time = elapsed.as_micros() as f64 / queries.len() as f64;

    println!("\n=== æ€§èƒ½æµ‹è¯• ===");
    println!("æŸ¥è¯¢æ•°é‡: {}", queries.len());
    println!("æ€»è€—æ—¶: {:?}", elapsed);
    println!("å¹³å‡è€—æ—¶: {:.2} Î¼s/æŸ¥è¯¢", avg_time);

    // å¹³å‡æ¯ä¸ªæŸ¥è¯¢åº”è¯¥åœ¨100Î¼sä»¥å†…
    assert!(
        avg_time < 100.0,
        "æ€§èƒ½é€€åŒ–ï¼šå¹³å‡æŸ¥è¯¢æ—¶é—´ {:.2} Î¼s è¶…è¿‡100 Î¼s",
        avg_time
    );

    println!("âœ… æ€§èƒ½æµ‹è¯•é€šè¿‡");
}

/// æµ‹è¯•æŸ¥è¯¢ç‰¹å¾æå–çš„å‡†ç¡®æ€§
#[test]
fn test_feature_extraction_accuracy() {
    println!("\n=== ç‰¹å¾æå–å‡†ç¡®æ€§æµ‹è¯• ===\n");

    // æµ‹è¯•1: ç²¾ç¡®åŒ¹é…æ£€æµ‹
    let exact_match_queries = vec!["user@example.com", "#tag", "\"exact phrase\"", "@mention"];
    for query in exact_match_queries {
        let features = QueryFeatures::extract_from_query(query);
        assert!(features.has_exact_terms, "åº”è¯¥æ£€æµ‹åˆ°ç²¾ç¡®åŒ¹é…: {}", query);
    }
    println!("âœ… ç²¾ç¡®åŒ¹é…æ£€æµ‹å‡†ç¡®");

    // æµ‹è¯•2: æ—¶é—´æŒ‡ç¤ºè¯æ£€æµ‹
    let temporal_queries = vec!["yesterday", "today", "last week", "æ˜¨å¤©", "æœ€è¿‘"];
    for query in temporal_queries {
        let features = QueryFeatures::extract_from_query(query);
        assert!(
            features.has_temporal_indicator,
            "åº”è¯¥æ£€æµ‹åˆ°æ—¶é—´æŒ‡ç¤º: {}",
            query
        );
    }
    println!("âœ… æ—¶é—´æŒ‡ç¤ºè¯æ£€æµ‹å‡†ç¡®");

    // æµ‹è¯•3: é—®å¥æ£€æµ‹
    let question_queries = vec![
        "What is AI?",
        "How does it work?",
        "Why?",
        "ä»€ä¹ˆæ˜¯AIï¼Ÿ",
        "æ€ä¹ˆåšï¼Ÿ",
    ];
    for query in question_queries {
        let features = QueryFeatures::extract_from_query(query);
        assert!(features.is_question, "åº”è¯¥æ£€æµ‹åˆ°é—®å¥: {}", query);
    }
    println!("âœ… é—®å¥æ£€æµ‹å‡†ç¡®");

    // æµ‹è¯•4: è¯­ä¹‰å¤æ‚åº¦è®¡ç®—
    let simple = QueryFeatures::extract_from_query("pizza");
    let complex = QueryFeatures::extract_from_query(
        "Explain the architectural considerations for implementing distributed vector databases",
    );
    assert!(
        simple.semantic_complexity < complex.semantic_complexity,
        "å¤æ‚æŸ¥è¯¢çš„è¯­ä¹‰å¤æ‚åº¦åº”è¯¥æ›´é«˜"
    );
    println!("âœ… è¯­ä¹‰å¤æ‚åº¦è®¡ç®—åˆç†");
}

/// æµ‹è¯•æƒé‡é¢„æµ‹çš„åˆç†æ€§
#[test]
fn test_weight_prediction_rationality() {
    let config = Arc::new(AgentMemConfig::default().search);
    let predictor = WeightPredictor::new(config);

    println!("\n=== æƒé‡é¢„æµ‹åˆç†æ€§æµ‹è¯• ===\n");

    // æµ‹è¯•1: ç²¾ç¡®åŒ¹é…åº”è¯¥æé«˜å…¨æ–‡æƒé‡
    let exact_features = QueryFeatures {
        has_exact_terms: true,
        semantic_complexity: 0.3,
        has_temporal_indicator: false,
        entity_count: 0,
        query_length: 20,
        is_question: false,
    };
    let weights = predictor.predict(&exact_features);
    assert!(
        weights.fulltext_weight > 0.5,
        "ç²¾ç¡®åŒ¹é…æŸ¥è¯¢åº”è¯¥åå‘å…¨æ–‡æœç´¢ï¼Œå®é™…: {:.2}",
        weights.fulltext_weight
    );
    println!("âœ… ç²¾ç¡®åŒ¹é…æƒé‡åˆç†");

    // æµ‹è¯•2: é«˜è¯­ä¹‰å¤æ‚åº¦åº”è¯¥æé«˜å‘é‡æƒé‡
    let semantic_features = QueryFeatures {
        has_exact_terms: false,
        semantic_complexity: 0.9,
        has_temporal_indicator: false,
        entity_count: 0,
        query_length: 100,
        is_question: true,
    };
    let weights = predictor.predict(&semantic_features);
    assert!(
        weights.vector_weight > 0.6,
        "é«˜è¯­ä¹‰å¤æ‚åº¦åº”è¯¥åå‘å‘é‡æœç´¢ï¼Œå®é™…: {:.2}",
        weights.vector_weight
    );
    println!("âœ… è¯­ä¹‰æŸ¥è¯¢æƒé‡åˆç†");

    // æµ‹è¯•3: å¹³è¡¡æŸ¥è¯¢åº”è¯¥æƒé‡æ¥è¿‘
    let balanced_features = QueryFeatures {
        has_exact_terms: false,
        semantic_complexity: 0.5,
        has_temporal_indicator: false,
        entity_count: 0,
        query_length: 30,
        is_question: false,
    };
    let weights = predictor.predict(&balanced_features);
    let diff = (weights.vector_weight - weights.fulltext_weight).abs();
    assert!(
        diff < 0.3,
        "å¹³è¡¡æŸ¥è¯¢æƒé‡å·®å¼‚åº”è¯¥è¾ƒå°ï¼Œå®é™…å·®å¼‚: {:.2}",
        diff
    );
    println!("âœ… å¹³è¡¡æŸ¥è¯¢æƒé‡åˆç†");
}

/// æµ‹è¯•å­¦ä¹ æœºåˆ¶
#[test]
fn test_learning_mechanism() {
    let config = Arc::new(AgentMemConfig::default().search);
    let mut optimizer = AdaptiveSearchOptimizer::new(config);

    let query = "test query";
    let good_weights = SearchWeights {
        vector_weight: 0.7,
        fulltext_weight: 0.3,
        confidence: 0.8,
    };

    let bad_weights = SearchWeights {
        vector_weight: 0.5,
        fulltext_weight: 0.5,
        confidence: 0.6,
    };

    // è®°å½•å¥½çš„é…ç½®ï¼ˆé«˜æ•ˆæœï¼‰
    optimizer.record_feedback(query, good_weights.clone(), 0.95);

    // è®°å½•åçš„é…ç½®ï¼ˆä½æ•ˆæœï¼‰- ä¸åº”è¯¥è¢«è®°å½•
    optimizer.record_feedback(query, bad_weights, 0.3);

    // è®°å½•ä¸­ç­‰é…ç½® - ä¸åº”è¯¥è¢«è®°å½•
    optimizer.record_feedback(query, good_weights, 0.6);

    println!("âœ… å­¦ä¹ æœºåˆ¶æµ‹è¯•é€šè¿‡ï¼ˆåªè®°å½•é«˜æ•ˆåé¦ˆï¼‰");
}
