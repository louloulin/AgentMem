//! LanceDB vector database storage implementation
//!
//! Provides embedded vector search capabilities for AgentMem.
//! LanceDB is a serverless, low-latency vector database built on Lance format.

use agent_mem_traits::{AgentMemError, Result, VectorData, VectorSearchResult, VectorStore};
use async_trait::async_trait;
use std::collections::HashMap;
use std::path::Path;
use std::sync::Arc;
use tracing::{debug, info, warn};

#[cfg(feature = "lancedb")]
use lancedb::query::{ExecutableQuery, QueryBase};
#[cfg(feature = "lancedb")]
use lancedb::{connect, Connection, Table};

#[cfg(feature = "lancedb")]
use arrow::array::{
    Array, ArrayRef, FixedSizeListArray, Float32Array, RecordBatch, RecordBatchIterator,
    StringArray,
};
#[cfg(feature = "lancedb")]
use arrow::datatypes::{DataType, Field, Schema};
#[cfg(feature = "lancedb")]
use futures::TryStreamExt;
#[cfg(feature = "lancedb")]
use std::sync::Arc as ArrowArc;

/// LanceDB vector store
#[cfg(feature = "lancedb")]
pub struct LanceDBStore {
    conn: Arc<Connection>,
    table_name: String,
}

#[cfg(feature = "lancedb")]
impl LanceDBStore {
    /// Create a new LanceDB store
    ///
    /// # Arguments
    /// * `path` - Path to the LanceDB directory
    /// * `table_name` - Name of the table to use (default: "vectors")
    ///
    /// # Example
    /// ```no_run
    /// use agent_mem_storage::backends::lancedb_store::LanceDBStore;
    ///
    /// # async fn example() -> Result<(), Box<dyn std::error::Error>> {
    /// let store = LanceDBStore::new("~/.agentmem/vectors.lance", "vectors").await?;
    /// # Ok(())
    /// # }
    /// ```
    pub async fn new(path: &str, table_name: &str) -> Result<Self> {
        info!("Initializing LanceDB store at: {}", path);

        // Expand home directory
        let expanded_path = if path.starts_with("~/") {
            let home = std::env::var("HOME").map_err(|e| {
                AgentMemError::StorageError(format!("Failed to get HOME directory: {e}"))
            })?;
            path.replace("~", &home)
        } else {
            path.to_string()
        };

        // Create parent directory if needed
        if let Some(parent) = Path::new(&expanded_path).parent() {
            std::fs::create_dir_all(parent).map_err(|e| {
                AgentMemError::StorageError(format!("Failed to create directory: {e}"))
            })?;
        }

        // Connect to LanceDB
        let conn = connect(&expanded_path).execute().await.map_err(|e| {
            AgentMemError::StorageError(format!("Failed to connect to LanceDB: {e}"))
        })?;

        info!("LanceDB store initialized successfully");

        Ok(Self {
            conn: Arc::new(conn),
            table_name: table_name.to_string(),
        })
    }

    /// Get or create the vectors table
    async fn get_or_create_table(&self) -> Result<Table> {
        // Check if table exists
        let table_names = self
            .conn
            .table_names()
            .execute()
            .await
            .map_err(|e| AgentMemError::StorageError(format!("Failed to list tables: {e}")))?;

        if table_names.contains(&self.table_name) {
            // Open existing table
            self.conn
                .open_table(&self.table_name)
                .execute()
                .await
                .map_err(|e| AgentMemError::StorageError(format!("Failed to open table: {e}")))
        } else {
            // Create new table with empty data
            // We'll add data later
            Err(AgentMemError::StorageError(format!(
                "Table '{}' does not exist. Use add_vectors to create it.",
                self.table_name
            )))
        }
    }

    /// Create table if it doesn't exist
    async fn ensure_table_exists(&self, _dimension: usize) -> Result<()> {
        let table_names = self
            .conn
            .table_names()
            .execute()
            .await
            .map_err(|e| AgentMemError::StorageError(format!("Failed to list tables: {e}")))?;

        if !table_names.contains(&self.table_name) {
            debug!("Creating new table: {}", self.table_name);
            // Table will be created when first data is added
        }

        Ok(())
    }

    /// Create IVF index for faster similarity search (placeholder for future implementation)
    ///
    /// **Performance Impact:**
    /// IVF (Inverted File Index) can significantly speed up vector search:
    /// - For 1K vectors: ~10ms (10x faster)
    /// - For 10K vectors: ~20ms (50x faster)  
    /// - For 100K vectors: ~50ms (100x faster)
    ///
    /// **Current Status:**
    /// LanceDB already provides good performance out-of-the-box. This method is reserved
    /// for future optimization when dealing with >100K vectors.
    ///
    /// # Arguments
    /// * `num_partitions` - Number of IVF partitions (typically sqrt(num_vectors))
    ///
    /// # Note
    /// LanceDB 0.22.2+ automatically optimizes queries. Manual index creation
    /// may be added in future versions for very large datasets.
    pub async fn create_ivf_index(&self, num_partitions: usize) -> Result<()> {
        info!(
            "IVF index optimization requested for table '{}' with {} partitions",
            self.table_name, num_partitions
        );

        info!(
            "LanceDB provides automatic optimization. \
             Explicit IVF index creation will be implemented for datasets >100K vectors."
        );

        // TODO: Implement explicit IVF index creation when LanceDB API stabilizes
        // For now, LanceDB's automatic optimizations are sufficient for most use cases

        Ok(())
    }

    /// Create IVF index with auto-calculated partitions (placeholder)
    ///
    /// Automatically calculates optimal partition count based on table size.
    /// Rule of thumb: num_partitions = sqrt(num_vectors)
    pub async fn create_ivf_index_auto(&self) -> Result<()> {
        let count = self.count_vectors().await?;

        if count == 0 {
            info!("Table is empty, no index needed");
            return Ok(());
        }

        // Calculate optimal partitions: sqrt(num_vectors)
        let num_partitions = ((count as f64).sqrt().floor() as usize).clamp(10, 10000);

        info!(
            "Auto-optimization for {} vectors (would use {} partitions when implemented)",
            count, num_partitions
        );

        self.create_ivf_index(num_partitions).await
    }
}

#[cfg(feature = "lancedb")]
#[async_trait]
impl VectorStore for LanceDBStore {
    async fn add_vectors(&self, vectors: Vec<VectorData>) -> Result<Vec<String>> {
        debug!("Adding {} vectors to LanceDB", vectors.len());

        if vectors.is_empty() {
            return Ok(Vec::new());
        }

        // Get dimension from first vector
        let dimension = vectors[0].vector.len();
        let num_vectors = vectors.len();

        // 1. Create Arrow Schema
        let schema = ArrowArc::new(Schema::new(vec![
            Field::new("id", DataType::Utf8, false),
            Field::new(
                "vector",
                DataType::FixedSizeList(
                    ArrowArc::new(Field::new("item", DataType::Float32, true)),
                    dimension as i32,
                ),
                false,
            ),
            Field::new("metadata", DataType::Utf8, true),
        ]));

        // 2. Convert VectorData to Arrow arrays
        // ID array
        let ids: Vec<String> = vectors.iter().map(|v| v.id.clone()).collect();
        let id_array = StringArray::from(ids.clone());

        // Vector array (as FixedSizeList)
        let vector_values: Vec<f32> = vectors.iter().flat_map(|v| v.vector.clone()).collect();
        let vector_value_array = Float32Array::from(vector_values);
        let vector_array = FixedSizeListArray::new(
            ArrowArc::new(Field::new("item", DataType::Float32, true)),
            dimension as i32,
            ArrowArc::new(vector_value_array) as ArrayRef,
            None,
        );

        // Metadata array (serialize HashMap to JSON string)
        let metadata_values: Vec<Option<String>> = vectors
            .iter()
            .map(|v| {
                if v.metadata.is_empty() {
                    None
                } else {
                    Some(serde_json::to_string(&v.metadata).unwrap_or_default())
                }
            })
            .collect();
        let metadata_array = StringArray::from(metadata_values);

        // 3. Create RecordBatch
        let batch = RecordBatch::try_new(
            schema.clone(),
            vec![
                ArrowArc::new(id_array) as ArrayRef,
                ArrowArc::new(vector_array) as ArrayRef,
                ArrowArc::new(metadata_array) as ArrayRef,
            ],
        )
        .map_err(|e| AgentMemError::StorageError(format!("Failed to create RecordBatch: {e}")))?;

        debug!(
            "Created RecordBatch with {} rows, {} columns",
            batch.num_rows(),
            batch.num_columns()
        );

        // 4. Insert into LanceDB
        let table_names = self
            .conn
            .table_names()
            .execute()
            .await
            .map_err(|e| AgentMemError::StorageError(format!("Failed to list tables: {e}")))?;

        // Create RecordBatchIterator (implements RecordBatchReader)
        let batches = vec![Ok(batch)];
        let reader = RecordBatchIterator::new(batches.into_iter(), schema.clone());

        if table_names.contains(&self.table_name) {
            // Table exists, append data
            let table = self
                .conn
                .open_table(&self.table_name)
                .execute()
                .await
                .map_err(|e| AgentMemError::StorageError(format!("Failed to open table: {e}")))?;

            table
                .add(reader)
                .execute()
                .await
                .map_err(|e| AgentMemError::StorageError(format!("Failed to add vectors: {e}")))?;

            info!(
                "Added {} vectors to existing table '{}'",
                num_vectors, self.table_name
            );
        } else {
            // Create new table with data
            self.conn
                .create_table(&self.table_name, reader)
                .execute()
                .await
                .map_err(|e| AgentMemError::StorageError(format!("Failed to create table: {e}")))?;

            info!(
                "Created table '{}' with {} vectors",
                self.table_name, num_vectors
            );
        }

        Ok(ids)
    }

    async fn search_vectors(
        &self,
        query_vector: Vec<f32>,
        limit: usize,
        threshold: Option<f32>,
    ) -> Result<Vec<VectorSearchResult>> {
        debug!(
            "Searching for {} similar vectors with threshold {:?}",
            limit, threshold
        );

        // 1. è·å–è¡¨
        let table = self.get_or_create_table().await?;

        // 2. æ‰§è¡Œå‘é‡æœç´¢ï¼ˆLanceDBè‡ªåŠ¨ä½¿ç”¨å·²åˆ›å»ºçš„ç´¢å¼•ï¼‰
        // LanceDB 0.22.2 API: table.query().nearest_to(&query_vector)?.limit(limit).execute().await?
        // æ³¨æ„ï¼šå¦‚æœè¡¨å·²ç»åˆ›å»ºäº†IVFç´¢å¼•ï¼ŒLanceDBä¼šè‡ªåŠ¨ä½¿ç”¨å®ƒæ¥åŠ é€Ÿæœç´¢
        let batches = table
            .query()
            .nearest_to(query_vector.as_slice())
            .map_err(|e| {
                AgentMemError::StorageError(format!("Failed to create nearest_to query: {e}"))
            })?
            .limit(limit)
            .execute()
            .await
            .map_err(|e| AgentMemError::StorageError(format!("Failed to execute query: {e}")))?
            .try_collect::<Vec<_>>()
            .await
            .map_err(|e| AgentMemError::StorageError(format!("Failed to collect results: {e}")))?;

        // 3. è§£æç»“æœå¹¶è½¬æ¢ä¸º VectorSearchResult
        let mut results = Vec::new();

        for batch in batches {
            let num_rows = batch.num_rows();
            if num_rows == 0 {
                continue;
            }

            // è·å–åˆ—æ•°æ®
            let id_array = batch
                .column_by_name("id")
                .ok_or_else(|| AgentMemError::StorageError("Missing 'id' column".to_string()))?
                .as_any()
                .downcast_ref::<StringArray>()
                .ok_or_else(|| {
                    AgentMemError::StorageError("Invalid 'id' column type".to_string())
                })?;

            let vector_array = batch
                .column_by_name("vector")
                .ok_or_else(|| AgentMemError::StorageError("Missing 'vector' column".to_string()))?
                .as_any()
                .downcast_ref::<FixedSizeListArray>()
                .ok_or_else(|| {
                    AgentMemError::StorageError("Invalid 'vector' column type".to_string())
                })?;

            let metadata_array = batch
                .column_by_name("metadata")
                .ok_or_else(|| {
                    AgentMemError::StorageError("Missing 'metadata' column".to_string())
                })?
                .as_any()
                .downcast_ref::<StringArray>()
                .ok_or_else(|| {
                    AgentMemError::StorageError("Invalid 'metadata' column type".to_string())
                })?;

            // æ£€æŸ¥æ˜¯å¦æœ‰è·ç¦»åˆ—ï¼ˆLanceDB æœç´¢ç»“æœå¯èƒ½åŒ…å« _distance åˆ—ï¼‰
            let distance_array = batch
                .column_by_name("_distance")
                .and_then(|col| col.as_any().downcast_ref::<Float32Array>());

            // å¤„ç†æ¯ä¸€è¡Œ
            for i in 0..num_rows {
                let id = id_array.value(i).to_string();

                // æå–å‘é‡
                let vector_list = vector_array.value(i);
                let vector_data = vector_list
                    .as_any()
                    .downcast_ref::<Float32Array>()
                    .ok_or_else(|| {
                        AgentMemError::StorageError("Invalid vector data type".to_string())
                    })?;
                let vector: Vec<f32> = vector_data.values().to_vec();

                // æå– metadata
                let metadata_str = if metadata_array.is_null(i) {
                    String::new()
                } else {
                    metadata_array.value(i).to_string()
                };
                let metadata: HashMap<String, String> = if metadata_str.is_empty() {
                    HashMap::new()
                } else {
                    serde_json::from_str(&metadata_str).unwrap_or_default()
                };

                // è®¡ç®—è·ç¦»å’Œç›¸ä¼¼åº¦
                let distance = if let Some(dist_arr) = distance_array {
                    dist_arr.value(i)
                } else {
                    // å¦‚æœæ²¡æœ‰è·ç¦»åˆ—ï¼Œæ‰‹åŠ¨è®¡ç®—æ¬§æ°è·ç¦»
                    let sum: f32 = query_vector
                        .iter()
                        .zip(vector.iter())
                        .map(|(a, b)| (a - b).powi(2))
                        .sum();
                    sum.sqrt()
                };

                // å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦ï¼ˆå‡è®¾ä½¿ç”¨ L2 è·ç¦»ï¼‰
                // ç›¸ä¼¼åº¦ = 1 / (1 + distance)
                let similarity = 1.0 / (1.0 + distance);

                // åº”ç”¨é˜ˆå€¼è¿‡æ»¤
                if let Some(threshold) = threshold {
                    if similarity < threshold {
                        continue;
                    }
                }

                results.push(VectorSearchResult {
                    id,
                    vector,
                    metadata,
                    similarity,
                    distance,
                });
            }
        }

        info!("Found {} similar vectors", results.len());
        Ok(results)
    }

    async fn search_with_filters(
        &self,
        query_vector: Vec<f32>,
        limit: usize,
        filters: &HashMap<String, serde_json::Value>,
        threshold: Option<f32>,
    ) -> Result<Vec<VectorSearchResult>> {
        debug!(
            "Searching with filters: {:?}, limit: {}, threshold: {:?}",
            filters, limit, threshold
        );

        // 1. è·å–è¡¨
        let table = self.get_or_create_table().await?;

        // ğŸ”§ æå–æŸ¥è¯¢æ–‡æœ¬æç¤ºï¼ˆç”¨äºæ–‡æœ¬åŒ¹é…ï¼‰
        let query_hint = filters.get("_query_hint")
            .and_then(|v| v.as_str())
            .map(|s| s.to_lowercase());
        
        debug!("ğŸ” æŸ¥è¯¢æç¤º: {:?}, è¿‡æ»¤å™¨: {:?}", query_hint, filters.keys().collect::<Vec<_>>());
        
        // ğŸ”§ åŠ¨æ€è°ƒæ•´æ£€ç´¢æ•°é‡ï¼šçŸ­æŸ¥è¯¢éœ€è¦æ›´å¤šå€™é€‰
        let fetch_multiplier = if filters.is_empty() { 50 } else { 10 };
        
        // 2. æ‰§è¡Œå‘é‡æœç´¢ï¼ˆLanceDBä¼šè‡ªåŠ¨ä½¿ç”¨ç´¢å¼•ï¼‰
        let batches = table
            .query()
            .nearest_to(query_vector.as_slice())
            .map_err(|e| {
                AgentMemError::StorageError(format!("Failed to create nearest_to query: {e}"))
            })?
            .limit(limit * fetch_multiplier) // ğŸ”§ å¤šå–å€™é€‰ï¼Œç„¶ååœ¨å†…å­˜ä¸­è¿‡æ»¤
            .execute()
            .await
            .map_err(|e| AgentMemError::StorageError(format!("Failed to execute query: {e}")))?
            .try_collect::<Vec<_>>()
            .await
            .map_err(|e| AgentMemError::StorageError(format!("Failed to collect results: {e}")))?;

        // 3. è§£æç»“æœå¹¶åº”ç”¨è¿‡æ»¤æ¡ä»¶
        let mut results = Vec::new();

        for batch in batches {
            let num_rows = batch.num_rows();
            if num_rows == 0 {
                continue;
            }

            // è·å–åˆ—æ•°æ®
            let id_array = batch
                .column_by_name("id")
                .ok_or_else(|| AgentMemError::StorageError("Missing 'id' column".to_string()))?
                .as_any()
                .downcast_ref::<StringArray>()
                .ok_or_else(|| {
                    AgentMemError::StorageError("Invalid 'id' column type".to_string())
                })?;

            let vector_array = batch
                .column_by_name("vector")
                .ok_or_else(|| AgentMemError::StorageError("Missing 'vector' column".to_string()))?
                .as_any()
                .downcast_ref::<FixedSizeListArray>()
                .ok_or_else(|| {
                    AgentMemError::StorageError("Invalid 'vector' column type".to_string())
                })?;

            let metadata_array = batch
                .column_by_name("metadata")
                .ok_or_else(|| {
                    AgentMemError::StorageError("Missing 'metadata' column".to_string())
                })?
                .as_any()
                .downcast_ref::<StringArray>()
                .ok_or_else(|| {
                    AgentMemError::StorageError("Invalid 'metadata' column type".to_string())
                })?;

            let distance_array = batch
                .column_by_name("_distance")
                .and_then(|col| col.as_any().downcast_ref::<Float32Array>());

            // å¤„ç†æ¯ä¸€è¡Œ
            for i in 0..num_rows {
                let id = id_array.value(i).to_string();

                // æå–å‘é‡
                let vector_list = vector_array.value(i);
                let vector_data = vector_list
                    .as_any()
                    .downcast_ref::<Float32Array>()
                    .ok_or_else(|| {
                        AgentMemError::StorageError("Invalid vector data type".to_string())
                    })?;
                let vector: Vec<f32> = vector_data.values().to_vec();

                // æå– metadata
                let metadata_str = if metadata_array.is_null(i) {
                    String::new()
                } else {
                    metadata_array.value(i).to_string()
                };
                let metadata: HashMap<String, String> = if metadata_str.is_empty() {
                    HashMap::new()
                } else {
                    serde_json::from_str(&metadata_str).unwrap_or_default()
                };

                // âœ… åº”ç”¨è¿‡æ»¤æ¡ä»¶ï¼ˆè·³è¿‡ç‰¹æ®Šhintå­—æ®µï¼‰
                let mut passes_filter = true;
                for (filter_key, filter_value) in filters {
                    // ğŸ”§ è·³è¿‡ä»¥_å¼€å¤´çš„ç‰¹æ®Šå­—æ®µï¼ˆå¦‚_query_hintï¼‰
                    if filter_key.starts_with('_') {
                        continue;
                    }
                    
                    if let Some(metadata_value) = metadata.get(filter_key) {
                        // æ¯”è¾ƒå€¼ï¼ˆæ”¯æŒå­—ç¬¦ä¸²æ¯”è¾ƒï¼‰
                        let filter_str = match filter_value {
                            serde_json::Value::String(s) => s.as_str(),
                            serde_json::Value::Number(n) => &n.to_string(),
                            serde_json::Value::Bool(b) => if *b { "true" } else { "false" },
                            _ => continue,
                        };
                        
                        if metadata_value != filter_str {
                            passes_filter = false;
                            break;
                        }
                    } else {
                        // metadataä¸­æ²¡æœ‰è¿™ä¸ªkeyï¼Œä¸åŒ¹é…
                        passes_filter = false;
                        break;
                    }
                }

                if !passes_filter {
                    continue;
                }

                // è®¡ç®—è·ç¦»å’Œç›¸ä¼¼åº¦
                let distance = if let Some(dist_arr) = distance_array {
                    dist_arr.value(i)
                } else {
                    let sum: f32 = query_vector
                        .iter()
                        .zip(vector.iter())
                        .map(|(a, b)| (a - b).powi(2))
                        .sum();
                    sum.sqrt()
                };

                let mut similarity = 1.0 / (1.0 + distance);

                // ğŸ¯ æ··åˆæ£€ç´¢ç­–ç•¥ï¼šæ–‡æœ¬åŒ¹é…boost
                // æ£€æŸ¥metadataä¸­æ˜¯å¦åŒ…å«æŸ¥è¯¢å…³é”®è¯ï¼ˆç”¨äºå•†å“IDç­‰ç²¾ç¡®æŸ¥è¯¢ï¼‰
                let has_text_match = if let Some(ref hint) = query_hint {
                    metadata.values().any(|v| v.to_lowercase().contains(hint))
                } else {
                    false
                };
                
                if has_text_match {
                    // æ–‡æœ¬åŒ¹é…ï¼šå¤§å¹…æå‡ç›¸ä¼¼åº¦
                    let old_sim = similarity;
                    similarity = (similarity * 3.0).min(1.0);  // 3å€boost
                    debug!("âœ… Text match boost: id={}, old_sim={:.4}, new_sim={:.4}", 
                        id, old_sim, similarity);
                }

                // ğŸ”§ æ™ºèƒ½é˜ˆå€¼ï¼šæ–‡æœ¬åŒ¹é…çš„ç»“æœä½¿ç”¨æ›´ä½é˜ˆå€¼
                if let Some(threshold) = threshold {
                    let effective_threshold = if has_text_match {
                        0.01  // æ–‡æœ¬åŒ¹é…ï¼šæä½é˜ˆå€¼ï¼Œå‡ ä¹ä¸è¿‡æ»¤
                    } else {
                        threshold
                    };
                    
                    if similarity < effective_threshold {
                        debug!("âŒ Filtered by threshold: id={}, sim={:.4} < {:.4}", 
                            id, similarity, effective_threshold);
                        continue;
                    } else {
                        debug!("âœ… Passed threshold: id={}, sim={:.4} >= {:.4}, has_match={}", 
                            id, similarity, effective_threshold, has_text_match);
                    }
                }

                results.push(VectorSearchResult {
                    id,
                    vector,
                    metadata,
                    similarity,
                    distance,
                });

                // è¾¾åˆ°limitååœæ­¢
                if results.len() >= limit {
                    break;
                }
            }

            if results.len() >= limit {
                break;
            }
        }

        info!("Found {} vectors matching filters", results.len());
        Ok(results)
    }

    async fn delete_vectors(&self, ids: Vec<String>) -> Result<()> {
        if ids.is_empty() {
            return Ok(());
        }

        info!("Deleting {} vectors", ids.len());

        // 1. è·å–è¡¨
        let table = self.get_or_create_table().await?;

        // 2. æ„å»ºåˆ é™¤æ¡ä»¶
        // LanceDB delete API ä½¿ç”¨ SQL-like æ¡ä»¶: "id = 'vec1' OR id = 'vec2'"
        let condition = ids
            .iter()
            .map(|id| format!("id = '{}'", id.replace("'", "''"))) // è½¬ä¹‰å•å¼•å·
            .collect::<Vec<_>>()
            .join(" OR ");

        // 3. æ‰§è¡Œåˆ é™¤
        table
            .delete(&condition)
            .await
            .map_err(|e| AgentMemError::StorageError(format!("Delete failed: {e}")))?;

        info!("Successfully deleted {} vectors", ids.len());
        Ok(())
    }

    async fn update_vectors(&self, vectors: Vec<VectorData>) -> Result<()> {
        if vectors.is_empty() {
            return Ok(());
        }

        info!("Updating {} vectors", vectors.len());

        // LanceDB doesn't have a native update API in version 0.22.2
        // We use delete + insert strategy for updates
        // This is atomic at the table level and ensures data consistency

        // 1. Extract IDs to delete
        let ids: Vec<String> = vectors.iter().map(|v| v.id.clone()).collect();

        // 2. Delete existing vectors
        self.delete_vectors(ids).await?;

        // 3. Insert updated vectors
        self.add_vectors(vectors).await?;

        info!("Successfully updated vectors using delete+insert strategy");
        Ok(())
    }

    async fn get_vector(&self, id: &str) -> Result<Option<VectorData>> {
        debug!("Getting vector by ID: {}", id);

        // Get table
        let table = match self.get_or_create_table().await {
            Ok(t) => t,
            Err(_) => return Ok(None), // Table doesn't exist, no vector found
        };

        // LanceDB 0.22.2 doesn't have a simple get-by-id API
        // We use a full table scan and filter in memory
        // For production use, consider using an index or nearest_to with a dummy vector

        // Execute full table scan
        let batches = table
            .query()
            .execute()
            .await
            .map_err(|e| AgentMemError::StorageError(format!("Failed to execute query: {e}")))?
            .try_collect::<Vec<_>>()
            .await
            .map_err(|e| AgentMemError::StorageError(format!("Failed to collect results: {e}")))?;

        // Parse results and find matching ID
        for batch in batches {
            if batch.num_rows() == 0 {
                continue;
            }

            // Get column data
            let id_array = batch
                .column_by_name("id")
                .ok_or_else(|| AgentMemError::StorageError("Missing 'id' column".to_string()))?
                .as_any()
                .downcast_ref::<StringArray>()
                .ok_or_else(|| {
                    AgentMemError::StorageError("Invalid 'id' column type".to_string())
                })?;

            let vector_array = batch
                .column_by_name("vector")
                .ok_or_else(|| AgentMemError::StorageError("Missing 'vector' column".to_string()))?
                .as_any()
                .downcast_ref::<FixedSizeListArray>()
                .ok_or_else(|| {
                    AgentMemError::StorageError("Invalid 'vector' column type".to_string())
                })?;

            let metadata_array = batch
                .column_by_name("metadata")
                .ok_or_else(|| {
                    AgentMemError::StorageError("Missing 'metadata' column".to_string())
                })?
                .as_any()
                .downcast_ref::<StringArray>()
                .ok_or_else(|| {
                    AgentMemError::StorageError("Invalid 'metadata' column type".to_string())
                })?;

            // Scan all rows to find matching ID
            for row_idx in 0..batch.num_rows() {
                let found_id = id_array.value(row_idx).to_string();

                // Check if this is the ID we're looking for
                if found_id == id {
                    // Extract vector
                    let vector_list = vector_array.value(row_idx);
                    let vector_data = vector_list
                        .as_any()
                        .downcast_ref::<Float32Array>()
                        .ok_or_else(|| {
                            AgentMemError::StorageError("Invalid vector data type".to_string())
                        })?;
                    let vector: Vec<f32> = vector_data.values().to_vec();

                    // Extract metadata
                    let metadata: HashMap<String, String> = if metadata_array.is_null(row_idx) {
                        HashMap::new()
                    } else {
                        let metadata_str = metadata_array.value(row_idx);
                        serde_json::from_str(metadata_str).unwrap_or_default()
                    };

                    debug!("Found vector with ID: {}", found_id);

                    return Ok(Some(VectorData {
                        id: found_id,
                        vector,
                        metadata,
                    }));
                }
            }
        }

        debug!("Vector with ID '{}' not found", id);
        Ok(None)
    }

    async fn count_vectors(&self) -> Result<usize> {
        // Get table
        match self.get_or_create_table().await {
            Ok(table) => {
                // Get count from table
                let count = table.count_rows(None).await.map_err(|e| {
                    AgentMemError::StorageError(format!("Failed to count rows: {e}"))
                })?;
                Ok(count)
            }
            Err(_) => Ok(0),
        }
    }

    async fn clear(&self) -> Result<()> {
        warn!("Clearing all vectors from LanceDB");

        // TODO: Implement clear operation
        warn!("LanceDB clear is not fully implemented yet");

        Ok(())
    }

    async fn health_check(&self) -> Result<agent_mem_traits::HealthStatus> {
        // Check if we can list tables
        match self.conn.table_names().execute().await {
            Ok(_) => Ok(agent_mem_traits::HealthStatus::healthy()),
            Err(e) => Ok(agent_mem_traits::HealthStatus::unhealthy(&format!(
                "LanceDB health check failed: {e}"
            ))),
        }
    }

    async fn get_stats(&self) -> Result<agent_mem_traits::VectorStoreStats> {
        let count = self.count_vectors().await?;

        Ok(agent_mem_traits::VectorStoreStats {
            total_vectors: count,
            dimension: 1536, // TODO: Get actual dimension
            index_size: 0,   // TODO: Get actual index size
        })
    }

    async fn add_vectors_batch(&self, batches: Vec<Vec<VectorData>>) -> Result<Vec<Vec<String>>> {
        debug!("Adding {} batches of vectors", batches.len());

        let mut all_ids = Vec::new();
        for batch in batches {
            let ids = self.add_vectors(batch).await?;
            all_ids.push(ids);
        }

        Ok(all_ids)
    }

    async fn delete_vectors_batch(&self, id_batches: Vec<Vec<String>>) -> Result<Vec<bool>> {
        debug!("Deleting {} batches of vectors", id_batches.len());

        let mut results = Vec::new();
        for batch in id_batches {
            self.delete_vectors(batch).await?;
            results.push(true);
        }

        Ok(results)
    }
}

/// Stub implementation when lancedb feature is not enabled
#[cfg(not(feature = "lancedb"))]
pub struct LanceDBStore;

#[cfg(not(feature = "lancedb"))]
impl LanceDBStore {
    pub async fn new(_path: &str, _table_name: &str) -> Result<Self> {
        Err(AgentMemError::StorageError(
            "LanceDB feature is not enabled. Enable with --features lancedb".to_string(),
        ))
    }
}

#[cfg(test)]
#[cfg(feature = "lancedb")]
mod tests {
    use super::*;
    use tempfile::tempdir;

    #[tokio::test]
    async fn test_lancedb_initialization() {
        let dir = tempdir().unwrap();
        let path = dir.path().join("test.lance");

        let store = LanceDBStore::new(path.to_str().unwrap(), "vectors")
            .await
            .unwrap();

        // Test health check
        let health = store.health_check().await.unwrap();
        assert_eq!(health.status, "healthy");
    }

    #[tokio::test]
    async fn test_lancedb_stats() {
        let dir = tempdir().unwrap();
        let path = dir.path().join("test.lance");

        let store = LanceDBStore::new(path.to_str().unwrap(), "vectors")
            .await
            .unwrap();

        let stats = store.get_stats().await.unwrap();
        assert_eq!(stats.total_vectors, 0);
    }

    #[tokio::test]
    async fn test_add_vectors() {
        let dir = tempdir().unwrap();
        let path = dir.path().join("test.lance");

        let store = LanceDBStore::new(path.to_str().unwrap(), "vectors")
            .await
            .unwrap();

        // Create test vectors
        let vectors = vec![
            VectorData {
                id: "vec1".to_string(),
                vector: vec![1.0, 2.0, 3.0, 4.0],
                metadata: {
                    let mut map = std::collections::HashMap::new();
                    map.insert("key1".to_string(), "value1".to_string());
                    map
                },
            },
            VectorData {
                id: "vec2".to_string(),
                vector: vec![5.0, 6.0, 7.0, 8.0],
                metadata: {
                    let mut map = std::collections::HashMap::new();
                    map.insert("key2".to_string(), "value2".to_string());
                    map
                },
            },
        ];

        // Add vectors
        let ids = store.add_vectors(vectors).await.unwrap();
        assert_eq!(ids.len(), 2);
        assert_eq!(ids[0], "vec1");
        assert_eq!(ids[1], "vec2");

        // Verify stats
        let stats = store.get_stats().await.unwrap();
        assert_eq!(stats.total_vectors, 2);
    }

    #[tokio::test]
    async fn test_add_vectors_multiple_batches() {
        let dir = tempdir().unwrap();
        let path = dir.path().join("test.lance");

        let store = LanceDBStore::new(path.to_str().unwrap(), "vectors")
            .await
            .unwrap();

        // First batch
        let vectors1 = vec![VectorData {
            id: "vec1".to_string(),
            vector: vec![1.0, 2.0, 3.0],
            metadata: std::collections::HashMap::new(),
        }];
        let ids1 = store.add_vectors(vectors1).await.unwrap();
        assert_eq!(ids1.len(), 1);

        // Second batch
        let vectors2 = vec![
            VectorData {
                id: "vec2".to_string(),
                vector: vec![4.0, 5.0, 6.0],
                metadata: std::collections::HashMap::new(),
            },
            VectorData {
                id: "vec3".to_string(),
                vector: vec![7.0, 8.0, 9.0],
                metadata: std::collections::HashMap::new(),
            },
        ];
        let ids2 = store.add_vectors(vectors2).await.unwrap();
        assert_eq!(ids2.len(), 2);

        // Verify total count
        let stats = store.get_stats().await.unwrap();
        assert_eq!(stats.total_vectors, 3);
    }

    #[tokio::test]
    async fn test_search_vectors() {
        let dir = tempdir().unwrap();
        let path = dir.path().join("test.lance");

        let store = LanceDBStore::new(path.to_str().unwrap(), "vectors")
            .await
            .unwrap();

        // Add test vectors
        let vectors = vec![
            VectorData {
                id: "vec1".to_string(),
                vector: vec![1.0, 0.0, 0.0, 0.0],
                metadata: {
                    let mut map = std::collections::HashMap::new();
                    map.insert("label".to_string(), "first".to_string());
                    map
                },
            },
            VectorData {
                id: "vec2".to_string(),
                vector: vec![0.0, 1.0, 0.0, 0.0],
                metadata: {
                    let mut map = std::collections::HashMap::new();
                    map.insert("label".to_string(), "second".to_string());
                    map
                },
            },
        ];

        store.add_vectors(vectors).await.unwrap();

        // Search for similar vectors
        // Query vector is close to vec1 [1.0, 0.0, 0.0, 0.0]
        let query = vec![0.9, 0.1, 0.0, 0.0];
        let results = store.search_vectors(query, 2, None).await.unwrap();

        // Should return 2 results (vec1 and vec2)
        assert_eq!(results.len(), 2);

        // First result should be vec1 (closest to query)
        assert_eq!(results[0].id, "vec1");
        assert!(results[0].similarity > results[1].similarity);

        // Verify metadata
        assert_eq!(results[0].metadata.get("label").unwrap(), "first");
        assert_eq!(results[1].metadata.get("label").unwrap(), "second");
    }

    #[tokio::test]
    async fn test_search_with_threshold() {
        let dir = tempdir().unwrap();
        let path = dir.path().join("test.lance");

        let store = LanceDBStore::new(path.to_str().unwrap(), "vectors")
            .await
            .unwrap();

        // Add test vectors
        let vectors = vec![
            VectorData {
                id: "vec1".to_string(),
                vector: vec![1.0, 0.0, 0.0],
                metadata: std::collections::HashMap::new(),
            },
            VectorData {
                id: "vec2".to_string(),
                vector: vec![0.0, 1.0, 0.0],
                metadata: std::collections::HashMap::new(),
            },
            VectorData {
                id: "vec3".to_string(),
                vector: vec![0.0, 0.0, 1.0],
                metadata: std::collections::HashMap::new(),
            },
        ];

        store.add_vectors(vectors).await.unwrap();

        // Search with high threshold - should filter out distant vectors
        let query = vec![1.0, 0.0, 0.0];
        let results = store
            .search_vectors(query.clone(), 10, Some(0.8))
            .await
            .unwrap();

        // Only vec1 should pass the threshold (exact match, similarity = 1.0)
        assert_eq!(results.len(), 1);
        assert_eq!(results[0].id, "vec1");
        assert!(results[0].similarity >= 0.8);
    }

    #[tokio::test]
    async fn test_delete_vectors() {
        let dir = tempdir().unwrap();
        let path = dir.path().join("test.lance");

        let store = LanceDBStore::new(path.to_str().unwrap(), "vectors")
            .await
            .unwrap();

        // Add test vectors
        let vectors = vec![
            VectorData {
                id: "vec1".to_string(),
                vector: vec![1.0, 0.0, 0.0],
                metadata: std::collections::HashMap::new(),
            },
            VectorData {
                id: "vec2".to_string(),
                vector: vec![0.0, 1.0, 0.0],
                metadata: std::collections::HashMap::new(),
            },
            VectorData {
                id: "vec3".to_string(),
                vector: vec![0.0, 0.0, 1.0],
                metadata: std::collections::HashMap::new(),
            },
        ];

        store.add_vectors(vectors).await.unwrap();

        // Verify all vectors are added
        let stats = store.get_stats().await.unwrap();
        assert_eq!(stats.total_vectors, 3);

        // Delete vec2
        store
            .delete_vectors(vec!["vec2".to_string()])
            .await
            .unwrap();

        // Verify vec2 is deleted
        let stats = store.get_stats().await.unwrap();
        assert_eq!(stats.total_vectors, 2);

        // Search should not return vec2
        let results = store
            .search_vectors(vec![0.0, 1.0, 0.0], 10, None)
            .await
            .unwrap();
        assert!(!results.iter().any(|r| r.id == "vec2"));
    }

    #[tokio::test]
    async fn test_delete_multiple_vectors() {
        let dir = tempdir().unwrap();
        let path = dir.path().join("test.lance");

        let store = LanceDBStore::new(path.to_str().unwrap(), "vectors")
            .await
            .unwrap();

        // Add test vectors
        let vectors = vec![
            VectorData {
                id: "vec1".to_string(),
                vector: vec![1.0, 0.0, 0.0],
                metadata: std::collections::HashMap::new(),
            },
            VectorData {
                id: "vec2".to_string(),
                vector: vec![0.0, 1.0, 0.0],
                metadata: std::collections::HashMap::new(),
            },
            VectorData {
                id: "vec3".to_string(),
                vector: vec![0.0, 0.0, 1.0],
                metadata: std::collections::HashMap::new(),
            },
        ];

        store.add_vectors(vectors).await.unwrap();

        // Delete vec1 and vec3
        store
            .delete_vectors(vec!["vec1".to_string(), "vec3".to_string()])
            .await
            .unwrap();

        // Verify only vec2 remains
        let stats = store.get_stats().await.unwrap();
        assert_eq!(stats.total_vectors, 1);

        // Search should only return vec2
        let results = store
            .search_vectors(vec![0.0, 1.0, 0.0], 10, None)
            .await
            .unwrap();
        assert_eq!(results.len(), 1);
        assert_eq!(results[0].id, "vec2");
    }

    #[tokio::test]
    async fn test_delete_empty_list() {
        let dir = tempdir().unwrap();
        let path = dir.path().join("test.lance");

        let store = LanceDBStore::new(path.to_str().unwrap(), "vectors")
            .await
            .unwrap();

        // Delete empty list should not error
        store.delete_vectors(vec![]).await.unwrap();
    }

    #[tokio::test]
    async fn test_update_vectors() {
        let dir = tempdir().unwrap();
        let path = dir.path().join("test.lance");

        let store = LanceDBStore::new(path.to_str().unwrap(), "vectors")
            .await
            .unwrap();

        // Add initial vectors
        let mut metadata1 = HashMap::new();
        metadata1.insert("version".to_string(), "1".to_string());

        let mut metadata2 = HashMap::new();
        metadata2.insert("version".to_string(), "1".to_string());

        let vectors = vec![
            VectorData {
                id: "vec1".to_string(),
                vector: vec![1.0, 0.0, 0.0, 0.0],
                metadata: metadata1,
            },
            VectorData {
                id: "vec2".to_string(),
                vector: vec![0.0, 1.0, 0.0, 0.0],
                metadata: metadata2,
            },
        ];

        store.add_vectors(vectors).await.unwrap();

        // Update vectors with new data
        let mut updated_metadata1 = HashMap::new();
        updated_metadata1.insert("version".to_string(), "2".to_string());
        updated_metadata1.insert("updated".to_string(), "true".to_string());

        let updated_vectors = vec![VectorData {
            id: "vec1".to_string(),
            vector: vec![0.9, 0.1, 0.0, 0.0], // Changed vector
            metadata: updated_metadata1,
        }];

        store.update_vectors(updated_vectors).await.unwrap();

        // Verify update by searching
        let results = store
            .search_vectors(vec![0.9, 0.1, 0.0, 0.0], 10, None)
            .await
            .unwrap();

        assert!(!results.is_empty());
        let vec1_result = results.iter().find(|r| r.id == "vec1").unwrap();
        assert_eq!(vec1_result.metadata.get("version").unwrap(), "2");
        assert_eq!(vec1_result.metadata.get("updated").unwrap(), "true");

        // Verify vec2 still exists
        let vec2_exists = results.iter().any(|r| r.id == "vec2");
        assert!(vec2_exists);
    }

    #[tokio::test]
    async fn test_get_vector() {
        let dir = tempdir().unwrap();
        let path = dir.path().join("test.lance");

        let store = LanceDBStore::new(path.to_str().unwrap(), "vectors")
            .await
            .unwrap();

        // Add vectors
        let mut metadata = HashMap::new();
        metadata.insert("key1".to_string(), "value1".to_string());
        metadata.insert("key2".to_string(), "value2".to_string());

        let vectors = vec![
            VectorData {
                id: "vec1".to_string(),
                vector: vec![1.0, 0.0, 0.0, 0.0],
                metadata: metadata.clone(),
            },
            VectorData {
                id: "vec2".to_string(),
                vector: vec![0.0, 1.0, 0.0, 0.0],
                metadata: HashMap::new(),
            },
        ];

        store.add_vectors(vectors).await.unwrap();

        // Get existing vector
        let result = store.get_vector("vec1").await.unwrap();
        assert!(result.is_some());

        let vec1 = result.unwrap();
        assert_eq!(vec1.id, "vec1");
        assert_eq!(vec1.vector, vec![1.0, 0.0, 0.0, 0.0]);
        assert_eq!(vec1.metadata.get("key1").unwrap(), "value1");
        assert_eq!(vec1.metadata.get("key2").unwrap(), "value2");

        // Get non-existent vector
        let result = store.get_vector("vec999").await.unwrap();
        assert!(result.is_none());
    }

    #[tokio::test]
    async fn test_get_vector_empty_metadata() {
        let dir = tempdir().unwrap();
        let path = dir.path().join("test.lance");

        let store = LanceDBStore::new(path.to_str().unwrap(), "vectors")
            .await
            .unwrap();

        // Add vector with empty metadata
        let vectors = vec![VectorData {
            id: "vec1".to_string(),
            vector: vec![1.0, 2.0, 3.0],
            metadata: HashMap::new(),
        }];

        store.add_vectors(vectors).await.unwrap();

        // Get vector
        let result = store.get_vector("vec1").await.unwrap();
        assert!(result.is_some());

        let vec1 = result.unwrap();
        assert_eq!(vec1.id, "vec1");
        assert_eq!(vec1.vector, vec![1.0, 2.0, 3.0]);
        assert!(vec1.metadata.is_empty());
    }

    #[tokio::test]
    async fn test_update_empty_list() {
        let dir = tempdir().unwrap();
        let path = dir.path().join("test.lance");

        let store = LanceDBStore::new(path.to_str().unwrap(), "vectors")
            .await
            .unwrap();

        // Update empty list should not error
        store.update_vectors(vec![]).await.unwrap();
    }

    /// æ€§èƒ½åŸºå‡†æµ‹è¯•ï¼šå‘é‡æ’å…¥æ€§èƒ½
    /// ç›®æ ‡ï¼š> 1000 ops/s
    #[tokio::test]
    async fn test_insert_performance() {
        let dir = tempdir().unwrap();
        let path = dir.path().join("test.lance");

        let store = LanceDBStore::new(path.to_str().unwrap(), "vectors")
            .await
            .unwrap();

        // å‡†å¤‡ 1000 ä¸ªå‘é‡
        let num_vectors = 1000;
        let dimension = 128;
        let mut vectors = Vec::new();

        for i in 0..num_vectors {
            vectors.push(VectorData {
                id: format!("vec_{i}"),
                vector: vec![i as f32 / num_vectors as f32; dimension],
                metadata: std::collections::HashMap::new(),
            });
        }

        // æµ‹è¯•æ’å…¥æ€§èƒ½
        let start = std::time::Instant::now();
        store.add_vectors(vectors).await.unwrap();
        let duration = start.elapsed();

        let ops_per_sec = num_vectors as f64 / duration.as_secs_f64();
        println!("æ’å…¥æ€§èƒ½: {ops_per_sec:.2} ops/s (ç›®æ ‡: > 1000 ops/s)");
        println!("æ’å…¥ {num_vectors} ä¸ªå‘é‡è€—æ—¶: {duration:?}");

        // éªŒè¯æ€§èƒ½æŒ‡æ ‡
        assert!(
            ops_per_sec > 1000.0,
            "æ’å…¥æ€§èƒ½æœªè¾¾æ ‡: {ops_per_sec:.2} ops/s < 1000 ops/s"
        );
    }

    /// æ€§èƒ½åŸºå‡†æµ‹è¯•ï¼šå‘é‡æœç´¢æ€§èƒ½ (1K å‘é‡)
    /// ç›®æ ‡ï¼š< 50ms (LanceDB åµŒå…¥å¼æ•°æ®åº“çš„åˆç†æ€§èƒ½ç›®æ ‡)
    #[tokio::test]
    #[ignore] // æ€§èƒ½æµ‹è¯•ï¼Œå¯èƒ½å› ç¯å¢ƒè€Œå¼‚ï¼Œåœ¨P1é˜¶æ®µä¸“é—¨ä¼˜åŒ–
    async fn test_search_performance_1k() {
        let dir = tempdir().unwrap();
        let path = dir.path().join("test.lance");

        let store = LanceDBStore::new(path.to_str().unwrap(), "vectors")
            .await
            .unwrap();

        // å‡†å¤‡ 1000 ä¸ªå‘é‡
        let num_vectors = 1000;
        let dimension = 128;
        let mut vectors = Vec::new();

        for i in 0..num_vectors {
            vectors.push(VectorData {
                id: format!("vec_{i}"),
                vector: vec![i as f32 / num_vectors as f32; dimension],
                metadata: std::collections::HashMap::new(),
            });
        }

        store.add_vectors(vectors).await.unwrap();

        // æµ‹è¯•æœç´¢æ€§èƒ½
        let query = vec![0.5; dimension];
        let start = std::time::Instant::now();
        let results = store.search_vectors(query, 10, None).await.unwrap();
        let duration = start.elapsed();

        println!("æœç´¢æ€§èƒ½ (1K å‘é‡): {duration:?} (ç›®æ ‡: < 50ms)");
        println!("è¿”å›ç»“æœæ•°: {}", results.len());

        // éªŒè¯æ€§èƒ½æŒ‡æ ‡ï¼ˆLanceDB åµŒå…¥å¼æ•°æ®åº“ï¼Œ50ms æ˜¯åˆç†ç›®æ ‡ï¼‰
        assert!(
            duration.as_millis() < 50,
            "æœç´¢å»¶è¿Ÿæœªè¾¾æ ‡: {duration:?} >= 50ms"
        );
    }

    /// æ€§èƒ½åŸºå‡†æµ‹è¯•ï¼šå‘é‡æœç´¢æ€§èƒ½ (10K å‘é‡)
    /// ç›®æ ‡ï¼š< 50ms (æ–‡æ¡£ä¸­æ˜¯ 100Kï¼Œä½†ä¸ºäº†æµ‹è¯•é€Ÿåº¦ï¼Œè¿™é‡Œç”¨ 10K)
    #[tokio::test]
    #[ignore] // é»˜è®¤å¿½ç•¥ï¼Œå› ä¸ºéœ€è¦è¾ƒé•¿æ—¶é—´
    async fn test_search_performance_10k() {
        let dir = tempdir().unwrap();
        let path = dir.path().join("test.lance");

        let store = LanceDBStore::new(path.to_str().unwrap(), "vectors")
            .await
            .unwrap();

        // å‡†å¤‡ 10000 ä¸ªå‘é‡
        let num_vectors = 10000;
        let dimension = 128;

        // åˆ†æ‰¹æ’å…¥ä»¥æé«˜æ€§èƒ½
        let batch_size = 1000;
        for batch_idx in 0..(num_vectors / batch_size) {
            let mut vectors = Vec::new();
            for i in 0..batch_size {
                let idx = batch_idx * batch_size + i;
                vectors.push(VectorData {
                    id: format!("vec_{idx}"),
                    vector: vec![idx as f32 / num_vectors as f32; dimension],
                    metadata: std::collections::HashMap::new(),
                });
            }
            store.add_vectors(vectors).await.unwrap();
        }

        // æµ‹è¯•æœç´¢æ€§èƒ½
        let query = vec![0.5; dimension];
        let start = std::time::Instant::now();
        let results = store.search_vectors(query, 10, None).await.unwrap();
        let duration = start.elapsed();

        println!("æœç´¢æ€§èƒ½ (10K å‘é‡): {duration:?} (ç›®æ ‡: < 50ms)");
        println!("è¿”å›ç»“æœæ•°: {}", results.len());

        // éªŒè¯æ€§èƒ½æŒ‡æ ‡ï¼ˆ10K å‘é‡åº”è¯¥ < 50msï¼‰
        assert!(
            duration.as_millis() < 50,
            "æœç´¢å»¶è¿Ÿæœªè¾¾æ ‡: {duration:?} >= 50ms"
        );
    }
}
