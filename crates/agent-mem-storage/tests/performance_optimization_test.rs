//! Performance optimization tests for AgentMem storage layer
//!
//! Tests the following optimizations:
//! 1. Batch vector insertion (3-5x throughput improvement)
//! 2. LanceDB automatic optimizations
//! 3. Caching effectiveness

use agent_mem_storage::backends::lancedb_store::LanceDBStore;
use agent_mem_traits::{VectorData, VectorStore};
use std::collections::HashMap;
use std::time::Instant;

#[tokio::test]
#[cfg(feature = "lancedb")]
async fn test_batch_insertion_performance() {
    let dir = tempfile::tempdir().unwrap();

    // Prepare test data (reduced size for stability)
    let dimension = 64;
    let num_vectors = 100;

    // Test 1: Sequential insertion (baseline)
    let seq_path = dir.path().join("seq_test.lance");
    let seq_store = LanceDBStore::new(seq_path.to_str().unwrap(), "vectors")
        .await
        .unwrap();

    let start = Instant::now();
    for i in 0..num_vectors {
        let vector = vec![VectorData {
            id: format!("seq_{i}"),
            vector: vec![i as f32 / num_vectors as f32; dimension],
            metadata: HashMap::new(),
        }];
        seq_store.add_vectors(vector).await.unwrap();
    }
    let sequential_duration = start.elapsed();

    println!(
        "Sequential insertion: {sequential_duration:?} for {num_vectors} vectors"
    );

    // Test 2: Batch insertion (optimized)
    let batch_path = dir.path().join("batch_test.lance");
    let batch_store = LanceDBStore::new(batch_path.to_str().unwrap(), "vectors")
        .await
        .unwrap();

    let mut batch_vectors = Vec::new();
    for i in 0..num_vectors {
        batch_vectors.push(VectorData {
            id: format!("batch_{i}"),
            vector: vec![i as f32 / num_vectors as f32; dimension],
            metadata: HashMap::new(),
        });
    }

    let start = Instant::now();
    batch_store.add_vectors(batch_vectors).await.unwrap();
    let batch_duration = start.elapsed();

    println!(
        "Batch insertion: {batch_duration:?} for {num_vectors} vectors"
    );

    // Calculate speedup
    let speedup = sequential_duration.as_secs_f64() / batch_duration.as_secs_f64();
    println!("Batch insertion speedup: {speedup:.2}x");

    // Batch should be at least 1.5x faster (conservative estimate)
    assert!(
        speedup >= 1.5,
        "Batch insertion should be at least 1.5x faster, got {speedup:.2}x"
    );
}

#[tokio::test]
#[cfg(feature = "lancedb")]
async fn test_search_performance_scaling() {
    let dir = tempfile::tempdir().unwrap();
    let path = dir.path().join("search_perf.lance");

    let store = LanceDBStore::new(path.to_str().unwrap(), "search_perf_vectors")
        .await
        .unwrap();

    let dimension = 128;

    // Test search performance at different scales (reduced for stability)
    let scales = vec![100, 500, 1000];
    let mut search_times = Vec::new();

    for &num_vectors in &scales {
        // Use unique table per scale to avoid conflicts
        let scale_path = dir.path().join(format!("scale_{num_vectors}.lance"));
        let scale_store = LanceDBStore::new(
            scale_path.to_str().unwrap(),
            &format!("vectors_{num_vectors}"),
        )
        .await
        .unwrap();

        // Insert vectors in batches
        let batch_size = 100;
        for batch_start in (0..num_vectors).step_by(batch_size) {
            let batch_end = (batch_start + batch_size).min(num_vectors);
            let mut batch_vectors = Vec::new();
            for i in batch_start..batch_end {
                batch_vectors.push(VectorData {
                    id: format!("vec_{i}"),
                    vector: vec![i as f32 / num_vectors as f32; dimension],
                    metadata: HashMap::new(),
                });
            }
            scale_store.add_vectors(batch_vectors).await.unwrap();
        }

        // Benchmark search
        let query = vec![0.5; dimension];
        let start = Instant::now();
        let results = scale_store.search_vectors(query, 10, None).await.unwrap();
        let search_time = start.elapsed();

        search_times.push((num_vectors, search_time));

        println!(
            "Search with {} vectors: {:?} ({} results)",
            num_vectors,
            search_time,
            results.len()
        );
    }

    // Verify search time scaling
    // Search should not grow linearly with vector count
    let time_100 = search_times.iter().find(|(n, _)| *n == 100).unwrap().1;
    let time_1k = search_times.iter().find(|(n, _)| *n == 1000).unwrap().1;

    let growth_ratio = time_1k.as_secs_f64() / time_100.as_secs_f64();
    println!("Search time growth (100â†’1K): {growth_ratio:.2}x");

    // Growth should be sub-linear (< 10x for 10x data)
    assert!(
        growth_ratio < 10.0,
        "Search should scale sub-linearly, got {growth_ratio:.2}x growth for 10x data"
    );
}

#[tokio::test]
#[cfg(feature = "lancedb")]
async fn test_threshold_filtering_performance() {
    let dir = tempfile::tempdir().unwrap();
    let path = dir.path().join("threshold_test.lance");

    let store = LanceDBStore::new(path.to_str().unwrap(), "vectors")
        .await
        .unwrap();

    // Add diverse vectors
    let dimension = 128;
    let num_vectors = 1000;
    let mut vectors = Vec::new();

    for i in 0..num_vectors {
        vectors.push(VectorData {
            id: format!("vec_{i}"),
            vector: {
                let mut v = vec![0.0; dimension];
                // Create diverse vectors with varying similarity
                v[0] = (i as f32 / num_vectors as f32).sin();
                v[1] = (i as f32 / num_vectors as f32).cos();
                v
            },
            metadata: HashMap::new(),
        });
    }

    store.add_vectors(vectors).await.unwrap();

    // Test different thresholds
    let query = vec![0.5; dimension];
    let thresholds = vec![None, Some(0.9), Some(0.7), Some(0.5)];

    for threshold in thresholds {
        let start = Instant::now();
        let results = store
            .search_vectors(query.clone(), 100, threshold)
            .await
            .unwrap();
        let duration = start.elapsed();

        println!(
            "Threshold {:?}: {} results in {:?}",
            threshold,
            results.len(),
            duration
        );

        // Verify filtering works
        if let Some(t) = threshold {
            for result in &results {
                assert!(
                    result.similarity >= t,
                    "Result similarity {} should be >= threshold {}",
                    result.similarity,
                    t
                );
            }
        }
    }
}

#[tokio::test]
#[cfg(feature = "lancedb")]
async fn test_ivf_index_placeholder() {
    let dir = tempfile::tempdir().unwrap();
    let path = dir.path().join("index_test.lance");

    let store = LanceDBStore::new(path.to_str().unwrap(), "vectors")
        .await
        .unwrap();

    // Add some vectors
    let vectors = vec![VectorData {
        id: "test1".to_string(),
        vector: vec![1.0, 0.0, 0.0],
        metadata: HashMap::new(),
    }];

    store.add_vectors(vectors).await.unwrap();

    // Test index creation (should not error)
    let result = store.create_ivf_index(10).await;
    assert!(result.is_ok(), "Index creation should not error");

    let result = store.create_ivf_index_auto().await;
    assert!(result.is_ok(), "Auto index creation should not error");
}

#[tokio::test]
#[cfg(feature = "lancedb")]
async fn test_concurrent_operations() {
    let dir = tempfile::tempdir().unwrap();
    let path = dir.path().join("concurrent_test.lance");

    // Use unique table name to avoid conflicts
    let store = std::sync::Arc::new(
        LanceDBStore::new(path.to_str().unwrap(), "concurrent_vectors")
            .await
            .unwrap(),
    );

    // Concurrent insertions
    let mut handles = Vec::new();

    for batch_id in 0..5 {
        let store_clone = store.clone();
        let handle = tokio::spawn(async move {
            let mut vectors = Vec::new();
            for i in 0..100 {
                vectors.push(VectorData {
                    id: format!("batch{batch_id}_{i}"),
                    vector: vec![i as f32 / 100.0; 128],
                    metadata: HashMap::new(),
                });
            }
            store_clone.add_vectors(vectors).await.unwrap();
        });
        handles.push(handle);
    }

    // Wait for all insertions
    for handle in handles {
        handle.await.unwrap();
    }

    // Verify total count
    let count = store.count_vectors().await.unwrap();
    assert_eq!(
        count, 500,
        "Should have 500 vectors from concurrent inserts"
    );

    // Concurrent searches
    let mut search_handles = Vec::new();

    for i in 0..10 {
        let store_clone = store.clone();
        let handle = tokio::spawn(async move {
            let query = vec![i as f32 / 10.0; 128];
            store_clone.search_vectors(query, 10, None).await.unwrap()
        });
        search_handles.push(handle);
    }

    // All searches should complete successfully
    for handle in search_handles {
        let results = handle.await.unwrap();
        assert!(!results.is_empty(), "Should find results");
    }
}

/// Integration test: Real-world workflow (simplified for stability)
#[tokio::test]
#[cfg(feature = "lancedb")]
async fn test_real_world_workflow() {
    let dir = tempfile::tempdir().unwrap();
    let path = dir.path().join("workflow_test.lance");

    let store = LanceDBStore::new(path.to_str().unwrap(), "workflow_vectors")
        .await
        .unwrap();

    // Phase 1: Initial data load (batch) - reduced size
    println!("Phase 1: Initial data load");
    let initial_vectors: Vec<VectorData> = (0..100)
        .map(|i| VectorData {
            id: format!("init_{i}"),
            vector: vec![i as f32 / 100.0; 64],
            metadata: {
                let mut m = HashMap::new();
                m.insert("type".to_string(), "initial".to_string());
                m
            },
        })
        .collect();

    let start = Instant::now();
    store.add_vectors(initial_vectors).await.unwrap();
    println!("Initial load: {:?} for 100 vectors", start.elapsed());

    // Phase 2: Create index (placeholder, but tests API)
    println!("Phase 2: Optimize with index");
    store.create_ivf_index_auto().await.unwrap();

    // Phase 3: Incremental updates
    println!("Phase 3: Incremental updates");
    for batch in 0..5 {
        let updates: Vec<VectorData> = (0..10)
            .map(|i| VectorData {
                id: format!("update_{batch}_{i}"),
                vector: vec![(batch * 10 + i) as f32 / 50.0; 64],
                metadata: {
                    let mut m = HashMap::new();
                    m.insert("type".to_string(), "update".to_string());
                    m.insert("batch".to_string(), batch.to_string());
                    m
                },
            })
            .collect();

        store.add_vectors(updates).await.unwrap();
    }

    // Phase 4: Search workload
    println!("Phase 4: Search workload");
    let search_queries = [vec![0.1; 64], vec![0.5; 64], vec![0.9; 64]];

    for (i, query) in search_queries.iter().enumerate() {
        let start = Instant::now();
        let results = store
            .search_vectors(query.clone(), 10, Some(0.3))
            .await
            .unwrap();
        println!(
            "Query {}: {} results in {:?}",
            i + 1,
            results.len(),
            start.elapsed()
        );
    }

    // Phase 5: Cleanup old data
    println!("Phase 5: Cleanup");
    let delete_ids: Vec<String> = (0..10).map(|i| format!("init_{i}")).collect();
    store.delete_vectors(delete_ids).await.unwrap();

    // Verify final state
    let final_count = store.count_vectors().await.unwrap();
    println!("Final vector count: {final_count}");
    assert_eq!(final_count, 140, "Should have 90 initial + 50 updates");
}
