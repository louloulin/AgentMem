//! é«˜çº§äº‹å®æå–æ¨¡å—
//!
//! æä¾›æ™ºèƒ½äº‹å®æå–åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
//! - å®ä½“è¯†åˆ«å’Œåˆ†ç±»
//! - å…³ç³»æå–å’Œå»ºæ¨¡
//! - äº‹å®ç»“æ„åŒ–å’ŒéªŒè¯
//! - è¯­ä¹‰ç†è§£å’Œæ¨ç†
//! - å¤šæ¨¡æ€å†…å®¹å¤„ç†

use agent_mem_llm::LLMProvider;
use agent_mem_traits::Result;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use tracing::{debug, info, warn};

// P0 ä¼˜åŒ–: è¶…æ—¶æ§åˆ¶
use crate::timeout::{with_timeout, TimeoutConfig};

// P1 ä¼˜åŒ–: ç¼“å­˜
use crate::caching::{CacheConfig, LruCacheWrapper};

/// æå–çš„äº‹å®ä¿¡æ¯
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExtractedFact {
    pub content: String,
    pub confidence: f32,
    pub category: FactCategory,
    pub entities: Vec<Entity>,
    pub temporal_info: Option<TemporalInfo>,
    pub source_message_id: Option<String>,
    pub metadata: HashMap<String, serde_json::Value>,
}

/// äº‹å®ç±»åˆ«ï¼ˆæ‰©å±•ç‰ˆæœ¬ï¼‰
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum FactCategory {
    Personal,     // ä¸ªäººä¿¡æ¯ï¼ˆå§“åã€å¹´é¾„ã€èŒä¸šç­‰ï¼‰
    Preference,   // åå¥½è®¾ç½®ï¼ˆå–œå¥½ã€åŒæ¶ç­‰ï¼‰
    Relationship, // å…³ç³»ä¿¡æ¯ï¼ˆå®¶åº­ã€æœ‹å‹ã€åŒäº‹ç­‰ï¼‰
    Event,        // äº‹ä»¶è®°å½•ï¼ˆå‘ç”Ÿçš„äº‹æƒ…ï¼‰
    Knowledge,    // çŸ¥è¯†äº‹å®ï¼ˆå®¢è§‚ä¿¡æ¯ï¼‰
    Procedural,   // ç¨‹åºæ€§çŸ¥è¯†ï¼ˆå¦‚ä½•åšæŸäº‹ï¼‰
    Emotional,    // æƒ…æ„ŸçŠ¶æ€ï¼ˆå¿ƒæƒ…ã€æ„Ÿå—ç­‰ï¼‰
    Goal,         // ç›®æ ‡å’Œè®¡åˆ’
    Skill,        // æŠ€èƒ½å’Œèƒ½åŠ›
    Location,     // åœ°ç†ä½ç½®ä¿¡æ¯
    Temporal,     // æ—¶é—´ç›¸å…³ä¿¡æ¯
    Financial,    // è´¢åŠ¡ä¿¡æ¯
    Health,       // å¥åº·ç›¸å…³ä¿¡æ¯
    Educational,  // æ•™è‚²èƒŒæ™¯
    Professional, // èŒä¸šç›¸å…³
}

/// å®ä½“ä¿¡æ¯
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Entity {
    pub name: String,
    pub entity_type: EntityType,
    pub confidence: f32,
    pub attributes: HashMap<String, serde_json::Value>,
    pub id: String,
}

/// å…³ç³»ç±»å‹
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum RelationType {
    FamilyOf,       // å®¶åº­å…³ç³»
    WorksAt,        // å·¥ä½œå…³ç³»
    Likes,          // å–œæ¬¢
    Dislikes,       // ä¸å–œæ¬¢
    FriendOf,       // æœ‹å‹å…³ç³»
    HasProperty,    // æ‹¥æœ‰å±æ€§
    LocatedAt,      // ä½äº
    ParticipatesIn, // å‚ä¸
    OccursAt,       // å‘ç”Ÿäº
    Causes,         // å¯¼è‡´
    Other(String),  // å…¶ä»–å…³ç³»
}

/// å…³ç³»
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Relation {
    pub subject: String,             // ä¸»ä½“
    pub predicate: String,           // è°“è¯
    pub object: String,              // å®¢ä½“
    pub relation_type: RelationType, // å…³ç³»ç±»å‹
    pub confidence: f32,             // ç½®ä¿¡åº¦
    pub subject_id: String,          // ä¸»ä½“ID
    pub object_id: String,           // å®¢ä½“ID
}

/// ç»“æ„åŒ–äº‹å®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StructuredFact {
    pub id: String,                        // äº‹å®ID
    pub fact_type: String,                 // äº‹å®ç±»å‹
    pub description: String,               // äº‹å®æè¿°
    pub entities: Vec<Entity>,             // ç›¸å…³å®ä½“
    pub relations: Vec<Relation>,          // ç›¸å…³å…³ç³»
    pub confidence: f32,                   // ç½®ä¿¡åº¦
    pub importance: f32,                   // é‡è¦æ€§
    pub source_messages: Vec<String>,      // æ¥æºæ¶ˆæ¯ID
    pub metadata: HashMap<String, String>, // å…ƒæ•°æ®
}

/// å®ä½“ç±»å‹
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum EntityType {
    Person,        // äººç‰©
    Organization,  // ç»„ç»‡æœºæ„
    Location,      // åœ°ç‚¹
    Product,       // äº§å“
    Concept,       // æ¦‚å¿µ
    Date,          // æ—¥æœŸ
    Time,          // æ—¶é—´
    Number,        // æ•°å­—
    Money,         // é‡‘é¢
    Percentage,    // ç™¾åˆ†æ¯”
    Email,         // é‚®ç®±
    Phone,         // ç”µè¯
    Url,           // ç½‘å€
    Event,         // äº‹ä»¶
    Skill,         // æŠ€èƒ½
    Language,      // è¯­è¨€
    Technology,    // æŠ€æœ¯
    Object,        // ç‰©ä½“
    Other(String), // å…¶ä»–ç±»å‹
}

/// æ—¶é—´ä¿¡æ¯
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TemporalInfo {
    pub timestamp: Option<String>,     // ISO 8601 æ ¼å¼æ—¶é—´æˆ³
    pub duration: Option<String>,      // æŒç»­æ—¶é—´æè¿°
    pub frequency: Option<String>,     // é¢‘ç‡æè¿°
    pub relative_time: Option<String>, // ç›¸å¯¹æ—¶é—´ï¼ˆå¦‚"æ˜¨å¤©"ã€"ä¸‹å‘¨"ï¼‰
    pub time_range: Option<TimeRange>, // æ—¶é—´èŒƒå›´
}

/// æ—¶é—´èŒƒå›´
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TimeRange {
    pub start: Option<String>,
    pub end: Option<String>,
}

// ä½¿ç”¨ agent_mem_traits ä¸­çš„ Message ç±»å‹
pub use agent_mem_traits::Message;

/// äº‹å®æå–å“åº”
#[derive(Debug, Deserialize)]
pub struct FactExtractionResponse {
    pub facts: Vec<ExtractedFact>,
    pub confidence: f32,
    pub reasoning: String,
}

/// äº‹å®æå–å™¨
pub struct FactExtractor {
    llm: Arc<dyn LLMProvider + Send + Sync>,
    // P0 ä¼˜åŒ–: è¶…æ—¶é…ç½®
    timeout_config: TimeoutConfig,
    // P1 ä¼˜åŒ– #1: LRUç¼“å­˜
    cache: Option<Arc<LruCacheWrapper<Vec<ExtractedFact>>>>,
}

impl FactExtractor {
    /// åˆ›å»ºæ–°çš„äº‹å®æå–å™¨
    pub fn new(llm: Arc<dyn LLMProvider + Send + Sync>) -> Self {
        Self {
            llm,
            timeout_config: TimeoutConfig::default(),
            cache: None,
        }
    }

    /// åˆ›å»ºå¸¦è‡ªå®šä¹‰è¶…æ—¶é…ç½®çš„äº‹å®æå–å™¨
    pub fn with_timeout_config(
        llm: Arc<dyn LLMProvider + Send + Sync>,
        timeout_config: TimeoutConfig,
    ) -> Self {
        Self {
            llm,
            timeout_config,
            cache: None,
        }
    }

    /// åˆ›å»ºå¸¦ç¼“å­˜çš„äº‹å®æå–å™¨ (P1 ä¼˜åŒ– #1)
    pub fn with_cache(llm: Arc<dyn LLMProvider + Send + Sync>, cache_config: CacheConfig) -> Self {
        Self {
            llm,
            timeout_config: TimeoutConfig::default(),
            cache: Some(Arc::new(LruCacheWrapper::new(cache_config))),
        }
    }

    /// åˆ›å»ºå¸¦è¶…æ—¶å’Œç¼“å­˜çš„äº‹å®æå–å™¨
    pub fn with_timeout_and_cache(
        llm: Arc<dyn LLMProvider + Send + Sync>,
        timeout_config: TimeoutConfig,
        cache_config: CacheConfig,
    ) -> Self {
        Self {
            llm,
            timeout_config,
            cache: Some(Arc::new(LruCacheWrapper::new(cache_config))),
        }
    }

    /// ä»æ¶ˆæ¯ä¸­æå–äº‹å®ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼‰- å†…éƒ¨å®ç°
    pub async fn extract_facts_internal(&self, messages: &[Message]) -> Result<Vec<ExtractedFact>> {
        info!("ğŸ”µ å¼€å§‹æå–äº‹å®ï¼Œæ¶ˆæ¯æ•°é‡: {}", messages.len());

        if messages.is_empty() {
            info!("âš ï¸  æ¶ˆæ¯ä¸ºç©ºï¼Œè·³è¿‡æå–");
            return Ok(vec![]);
        }

        let conversation = self.format_conversation(messages);
        info!("   å¯¹è¯é•¿åº¦: {} å­—ç¬¦", conversation.len());

        // P1 ä¼˜åŒ– #1: æ£€æŸ¥ç¼“å­˜
        if let Some(cache) = &self.cache {
            let cache_key = LruCacheWrapper::<Vec<ExtractedFact>>::compute_key(&conversation);
            if let Some(cached_facts) = cache.get(&cache_key) {
                info!("âœ… ç¼“å­˜å‘½ä¸­ï¼Œç›´æ¥è¿”å› {} ä¸ªäº‹å®", cached_facts.len());
                return Ok(cached_facts);
            }
            info!("   ç¼“å­˜æœªå‘½ä¸­");
        }

        let prompt = self.build_enhanced_extraction_prompt(&conversation);
        info!("   Prompt é•¿åº¦: {} å­—ç¬¦", prompt.len());
        debug!("   Prompt å†…å®¹: {}", prompt);

        // P0 ä¼˜åŒ– #2: æ·»åŠ è¶…æ—¶æ§åˆ¶
        info!(
            "ğŸ”µ è°ƒç”¨ LLM æå–äº‹å®ï¼ˆè¶…æ—¶: {}ç§’ï¼‰...",
            self.timeout_config.fact_extraction_timeout_secs
        );
        let llm_start = std::time::Instant::now();

        let llm = self.llm.clone();
        let response_text = with_timeout(
            async move {
                info!("   LLM è°ƒç”¨å¼€å§‹...");
                let result = llm.generate(&[Message::user(&prompt)]).await;
                info!("   LLM è°ƒç”¨å®Œæˆ");
                result
            },
            self.timeout_config.fact_extraction_timeout_secs,
            "fact_extraction",
        )
        .await?;

        let llm_duration = llm_start.elapsed();
        info!("âœ… LLM è°ƒç”¨å®Œæˆï¼Œè€—æ—¶: {:?}", llm_duration);
        info!("   å“åº”é•¿åº¦: {} å­—ç¬¦", response_text.len());

        // å°è¯•æå– JSON éƒ¨åˆ†
        info!("ğŸ”µ æå– JSON å“åº”...");
        let json_text = self.extract_json_from_response(&response_text)?;
        info!("   JSON é•¿åº¦: {} å­—ç¬¦", json_text.len());

        // è°ƒè¯•ï¼šæ‰“å° JSON æ–‡æœ¬
        debug!("Extracted JSON: {}", json_text);

        // P1 ä¼˜åŒ– #3: è§£æå¤±è´¥æ—¶ä½¿ç”¨è§„åˆ™æå–é™çº§
        info!("ğŸ”µ è§£æäº‹å®...");
        let mut facts = match serde_json::from_str::<FactExtractionResponse>(&json_text) {
            Ok(response) => {
                info!(
                    "âœ… LLM äº‹å®æå–æˆåŠŸï¼Œæå–åˆ° {} ä¸ªäº‹å®",
                    response.facts.len()
                );
                response.facts
            }
            Err(e) => {
                warn!("âŒ LLM äº‹å®æå– JSON è§£æå¤±è´¥: {}, é™çº§åˆ°è§„åˆ™æå–", e);
                warn!("   JSON text: {}", json_text);

                // P1 ä¼˜åŒ– #3: é™çº§åˆ°åŸºäºè§„åˆ™çš„æå–
                info!("ğŸ”µ ä½¿ç”¨è§„åˆ™æå–...");
                let rule_facts = self.rule_based_fact_extraction(messages)?;
                info!("âœ… è§„åˆ™æå–å®Œæˆï¼Œæå–åˆ° {} ä¸ªäº‹å®", rule_facts.len());
                rule_facts
            }
        };

        // åå¤„ç†ï¼šå®ä½“è¯†åˆ«å’Œæ—¶é—´ä¿¡æ¯æå–
        info!("ğŸ”µ å¢å¼ºäº‹å®ï¼ˆå®ä½“è¯†åˆ« + æ—¶é—´ä¿¡æ¯ï¼‰...");
        self.enhance_facts_with_entities(&mut facts).await?;
        self.enhance_facts_with_temporal_info(&mut facts).await?;
        info!("âœ… äº‹å®å¢å¼ºå®Œæˆ");

        // éªŒè¯å’Œè¿‡æ»¤
        info!("ğŸ”µ éªŒè¯å’Œè¿‡æ»¤äº‹å®...");
        let before_filter = facts.len();
        facts = self.validate_and_filter_facts(facts);
        info!("âœ… è¿‡æ»¤å®Œæˆï¼Œä¿ç•™ {}/{} ä¸ªäº‹å®", facts.len(), before_filter);

        // åˆå¹¶ç›¸ä¼¼äº‹å®
        info!("ğŸ”µ åˆå¹¶ç›¸ä¼¼äº‹å®...");
        let before_merge = facts.len();
        facts = self.merge_similar_facts(facts);
        info!("âœ… åˆå¹¶å®Œæˆï¼Œæœ€ç»ˆ {}/{} ä¸ªäº‹å®", facts.len(), before_merge);

        // P1 ä¼˜åŒ– #1: å†™å…¥ç¼“å­˜
        if let Some(cache) = &self.cache {
            let conversation = self.format_conversation(messages);
            let cache_key = LruCacheWrapper::<Vec<ExtractedFact>>::compute_key(&conversation);
            cache.put(cache_key, facts.clone());
            info!("âœ… äº‹å®å·²ç¼“å­˜");
        }

        info!("âœ… äº‹å®æå–å®Œæˆï¼Œå…± {} ä¸ªäº‹å®", facts.len());
        Ok(facts)
    }

    /// è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
    pub fn cache_stats(&self) -> Option<crate::caching::CacheStats> {
        self.cache.as_ref().map(|c| c.stats())
    }

    /// ä»å“åº”ä¸­æå– JSON éƒ¨åˆ†
    fn extract_json_from_response(&self, response: &str) -> Result<String> {
        // å°è¯•ç›´æ¥è§£æ
        if response.trim().starts_with('{') {
            let cleaned = self.clean_json_response(response);
            return Ok(cleaned);
        }

        // æŸ¥æ‰¾ JSON å—
        if let Some(start) = response.find('{') {
            if let Some(end) = response.rfind('}') {
                if end > start {
                    let json_part = &response[start..=end];
                    let cleaned = self.clean_json_response(json_part);
                    return Ok(cleaned);
                }
            }
        }

        // å¦‚æœæ‰¾ä¸åˆ° JSONï¼Œè¿”å›é”™è¯¯
        Err(agent_mem_traits::AgentMemError::internal_error(
            "No valid JSON found in response".to_string(),
        ))
    }

    /// æ¸…ç† JSON å“åº”ï¼Œå¤„ç†å¤šå€¼å­—æ®µ
    fn clean_json_response(&self, json_str: &str) -> String {
        let mut cleaned = json_str.to_string();

        // å¤„ç† category å­—æ®µä¸­çš„å¤šå€¼æƒ…å†µï¼Œå¦‚ "Personal|Professional" -> "Personal"
        let category_re = regex::Regex::new(r#""category":\s*"([^"|]+)\|[^"]*""#).unwrap();
        cleaned = category_re
            .replace_all(&cleaned, r#""category": "$1""#)
            .to_string();

        // å¤„ç† entity_type å­—æ®µä¸­çš„å¤šå€¼æƒ…å†µï¼Œå¦‚ "Language|Technology" -> "Language"
        let entity_type_re = regex::Regex::new(r#""entity_type":\s*"([^"|]+)\|[^"]*""#).unwrap();
        cleaned = entity_type_re
            .replace_all(&cleaned, r#""entity_type": "$1""#)
            .to_string();

        // å¤„ç†æœªçŸ¥çš„å®ä½“ç±»å‹ï¼Œæ˜ å°„åˆ°å·²çŸ¥ç±»å‹
        let entity_type_mappings = [
            ("Profession", "Concept"),
            ("Job", "Concept"),
            ("Career", "Concept"),
            ("Work", "Concept"),
            ("Industry", "Concept"),
            ("Field", "Concept"),
            ("Hobby", "Concept"),
            ("Interest", "Concept"),
            ("Activity", "Event"),
            ("Action", "Event"),
            ("Place", "Location"),
            ("Country", "Location"),
            ("City", "Location"),
            ("Company", "Organization"),
            ("Business", "Organization"),
            ("Institution", "Organization"),
            ("School", "Organization"),
            ("University", "Organization"),
            ("Role", "Concept"),
            ("Position", "Concept"),
            ("Title", "Concept"),
            ("Age", "Number"),
            ("Years", "Number"),
            ("Name", "Person"),
            ("PersonName", "Person"),
            ("FullName", "Person"),
            ("FirstName", "Person"),
            ("LastName", "Person"),
            ("Department", "Organization"),
            ("Team", "Organization"),
            ("Group", "Organization"),
            ("Responsibility", "Concept"),
            ("Duty", "Concept"),
            ("Task", "Concept"),
            ("Function", "Concept"),
            ("Skill", "Skill"),
            ("Ability", "Skill"),
            ("Expertise", "Skill"),
            ("Knowledge", "Concept"),
            ("Experience", "Concept"),
            ("Background", "Concept"),
            ("Education", "Concept"),
            ("Qualification", "Concept"),
            ("Achievement", "Event"),
            ("Accomplishment", "Event"),
            ("Project", "Event"),
            ("Initiative", "Event"),
            ("Program", "Event"),
        ];

        for (unknown_type, known_type) in entity_type_mappings.iter() {
            let pattern = format!(r#""entity_type":\s*"{unknown_type}""#);
            let replacement = format!(r#""entity_type": "{known_type}""#);
            let re = regex::Regex::new(&pattern).unwrap();
            cleaned = re.replace_all(&cleaned, replacement.as_str()).to_string();
        }

        // å¤„ç†æ•°å­—å­—æ®µè¢«é”™è¯¯åœ°ä½œä¸ºæ•°å­—è€Œä¸æ˜¯å­—ç¬¦ä¸²çš„æƒ…å†µ
        // å°† "name": 30 è½¬æ¢ä¸º "name": "30"
        let number_to_string_re = regex::Regex::new(r#""name":\s*(\d+)"#).unwrap();
        cleaned = number_to_string_re
            .replace_all(&cleaned, r#""name": "$1""#)
            .to_string();

        // å¤„ç†å…¶ä»–å¯èƒ½çš„æ•°å­—å­—æ®µ
        let id_number_re = regex::Regex::new(r#""id":\s*(\d+)"#).unwrap();
        cleaned = id_number_re
            .replace_all(&cleaned, r#""id": "$1""#)
            .to_string();

        cleaned
    }

    /// æ ¼å¼åŒ–å¯¹è¯å†…å®¹
    fn format_conversation(&self, messages: &[Message]) -> String {
        messages
            .iter()
            .map(|msg| format!("{:?}: {}", msg.role, msg.content))
            .collect::<Vec<_>>()
            .join("\n")
    }

    /// æ„å»ºäº‹å®æå–æç¤º
    fn build_fact_extraction_prompt(&self, conversation: &str) -> String {
        format!(
            r#"Extract key facts from this conversation. Return JSON only.

Conversation:
{conversation}

JSON format:
{{
    "facts": [
        {{
            "content": "fact description",
            "confidence": 0.9,
            "category": "Personal|Preference|Relationship|Event|Knowledge|Procedural",
            "entities": ["entity1", "entity2"],
            "temporal_info": null,
            "source_message_id": null
        }}
    ],
    "confidence": 0.8,
    "reasoning": "brief explanation"
}}

Rules:
- Extract 1-5 most important facts only
- Use confidence 0.3-1.0
- Categories: Personal (name, age), Preference (likes/dislikes), Relationship (connections), Event (actions), Knowledge (facts), Procedural (how-to)
- Include key entities mentioned
- Keep content concise (max 50 words per fact)"#
        )
    }

    /// æ„å»ºå¢å¼ºçš„äº‹å®æå–æç¤º
    fn build_enhanced_extraction_prompt(&self, conversation: &str) -> String {
        format!(
            r#"Extract structured facts from this conversation. You are a professional information extraction expert.

Conversation:
{conversation}

Extract facts in these categories:
1. Personal - personal info (name, age, job, contact)
2. Preference - preferences (likes, dislikes, habits)
3. Relationship - relationships (family, friends, colleagues)
4. Event - events (activities, experiences)
5. Knowledge - knowledge facts (objective information)
6. Procedural - procedural knowledge (how-to, methods)
7. Emotional - emotional states (mood, feelings)
8. Goal - goals and plans (objectives, planning)
9. Skill - skills and abilities (professional skills, languages)
10. Location - location info (residence, workplace, travel)
11. Temporal - time-related info (schedule, timing)
12. Financial - financial info (income, expenses)
13. Health - health info (medical records, conditions)
14. Educational - education background (degree, school)
15. Professional - professional info (career, work experience)

JSON format:
{{
    "facts": [
        {{
            "content": "clear, complete fact description",
            "confidence": 0.9,
            "category": "Personal|Preference|Relationship|Event|Knowledge|Procedural|Emotional|Goal|Skill|Location|Temporal|Financial|Health|Educational|Professional",
            "entities": [
                {{
                    "id": "unique_entity_id",
                    "name": "entity_name",
                    "entity_type": "Person|Organization|Location|Product|Concept|Date|Time|Number|Money|Percentage|Email|Phone|Url|Event|Skill|Language|Technology",
                    "confidence": 0.9,
                    "attributes": {{}}
                }}
            ],
            "temporal_info": {{
                "timestamp": "ISO 8601 format if specific time",
                "duration": "duration description",
                "frequency": "frequency description",
                "relative_time": "relative time like 'yesterday', 'next week'",
                "time_range": {{
                    "start": "start time",
                    "end": "end time"
                }}
            }},
            "source_message_id": null,
            "metadata": {{}}
        }}
    ],
    "confidence": 0.8,
    "reasoning": "brief explanation"
}}

Requirements:
- Ensure accuracy and completeness
- Avoid duplicate or redundant information
- Lower confidence for ambiguous information
- Extract specific entities and temporal info
- Preserve original semantic meaning"#
        )
    }

    /// å¢å¼ºäº‹å®çš„å®ä½“ä¿¡æ¯
    async fn enhance_facts_with_entities(&self, facts: &mut Vec<ExtractedFact>) -> Result<()> {
        for fact in facts.iter_mut() {
            if fact.entities.is_empty() {
                // å¦‚æœæ²¡æœ‰å®ä½“ä¿¡æ¯ï¼Œå°è¯•ä»å†…å®¹ä¸­æå–
                let entities = self.extract_entities_from_content(&fact.content).await?;
                fact.entities = entities;
            }
        }
        Ok(())
    }

    /// å¢å¼ºäº‹å®çš„æ—¶é—´ä¿¡æ¯
    async fn enhance_facts_with_temporal_info(&self, facts: &mut Vec<ExtractedFact>) -> Result<()> {
        for fact in facts.iter_mut() {
            if fact.temporal_info.is_none() {
                // å¦‚æœæ²¡æœ‰æ—¶é—´ä¿¡æ¯ï¼Œå°è¯•ä»å†…å®¹ä¸­æå–
                let temporal_info = self
                    .extract_temporal_info_from_content(&fact.content)
                    .await?;
                fact.temporal_info = temporal_info;
            }
        }
        Ok(())
    }

    /// ä»å†…å®¹ä¸­æå–å®ä½“
    async fn extract_entities_from_content(&self, content: &str) -> Result<Vec<Entity>> {
        // ç®€åŒ–çš„å®ä½“æå–é€»è¾‘ï¼Œå®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„NERæ¨¡å‹
        let mut entities = Vec::new();

        // åŸºäºè§„åˆ™çš„ç®€å•å®ä½“è¯†åˆ«
        if let Some(entity) = self.extract_person_entities(content) {
            entities.push(entity);
        }

        if let Some(entity) = self.extract_location_entities(content) {
            entities.push(entity);
        }

        if let Some(entity) = self.extract_organization_entities(content) {
            entities.push(entity);
        }

        Ok(entities)
    }

    /// ä»å†…å®¹ä¸­æå–æ—¶é—´ä¿¡æ¯
    async fn extract_temporal_info_from_content(
        &self,
        content: &str,
    ) -> Result<Option<TemporalInfo>> {
        // ç®€åŒ–çš„æ—¶é—´ä¿¡æ¯æå–é€»è¾‘
        let mut temporal_info = TemporalInfo {
            timestamp: None,
            duration: None,
            frequency: None,
            relative_time: None,
            time_range: None,
        };

        // æ£€æµ‹ç›¸å¯¹æ—¶é—´è¡¨è¾¾
        if content.contains("æ˜¨å¤©") || content.contains("yesterday") {
            temporal_info.relative_time = Some("yesterday".to_string());
        } else if content.contains("ä»Šå¤©") || content.contains("today") {
            temporal_info.relative_time = Some("today".to_string());
        } else if content.contains("æ˜å¤©") || content.contains("tomorrow") {
            temporal_info.relative_time = Some("tomorrow".to_string());
        }

        // æ£€æµ‹é¢‘ç‡è¡¨è¾¾
        if content.contains("æ¯å¤©") || content.contains("daily") {
            temporal_info.frequency = Some("daily".to_string());
        } else if content.contains("æ¯å‘¨") || content.contains("weekly") {
            temporal_info.frequency = Some("weekly".to_string());
        }

        // å¦‚æœæœ‰ä»»ä½•æ—¶é—´ä¿¡æ¯ï¼Œè¿”å›ç»“æ„
        if temporal_info.timestamp.is_some()
            || temporal_info.duration.is_some()
            || temporal_info.frequency.is_some()
            || temporal_info.relative_time.is_some()
        {
            Ok(Some(temporal_info))
        } else {
            Ok(None)
        }
    }

    /// éªŒè¯å’Œè¿‡æ»¤äº‹å®ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼‰
    fn validate_and_filter_facts(&self, facts: Vec<ExtractedFact>) -> Vec<ExtractedFact> {
        facts
            .into_iter()
            .filter(|fact| {
                // è¿‡æ»¤æ‰ç½®ä¿¡åº¦è¿‡ä½çš„äº‹å®
                fact.confidence >= 0.3 &&
                // è¿‡æ»¤æ‰å†…å®¹è¿‡çŸ­çš„äº‹å®
                fact.content.len() >= 10 &&
                // è¿‡æ»¤æ‰ç©ºå†…å®¹
                !fact.content.trim().is_empty()
            })
            .collect()
    }

    /// éªŒè¯å’Œè¿‡æ»¤äº‹å®ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
    pub fn validate_facts(&self, facts: Vec<ExtractedFact>) -> Vec<ExtractedFact> {
        self.validate_and_filter_facts(facts)
    }

    /// åˆå¹¶ç›¸ä¼¼äº‹å®
    pub fn merge_similar_facts(&self, facts: Vec<ExtractedFact>) -> Vec<ExtractedFact> {
        // ç®€å•çš„å»é‡é€»è¾‘ï¼ŒåŸºäºå†…å®¹ç›¸ä¼¼æ€§
        let mut merged_facts = Vec::new();

        for fact in facts {
            let is_similar = merged_facts.iter().any(|existing: &ExtractedFact| {
                self.calculate_similarity(&fact.content, &existing.content) > 0.8
            });

            if !is_similar {
                merged_facts.push(fact);
            }
        }

        merged_facts
    }

    /// è®¡ç®—æ–‡æœ¬ç›¸ä¼¼æ€§ï¼ˆç®€å•å®ç°ï¼‰
    fn calculate_similarity(&self, text1: &str, text2: &str) -> f32 {
        let words1: std::collections::HashSet<&str> = text1.split_whitespace().collect();
        let words2: std::collections::HashSet<&str> = text2.split_whitespace().collect();

        let intersection = words1.intersection(&words2).count();
        let union = words1.union(&words2).count();

        if union == 0 {
            0.0
        } else {
            intersection as f32 / union as f32
        }
    }

    /// P1 ä¼˜åŒ– #3: åŸºäºè§„åˆ™çš„äº‹å®æå–ï¼ˆé™çº§æ–¹æ¡ˆï¼‰
    ///
    /// å½“ LLM è§£æå¤±è´¥æ—¶ä½¿ç”¨æ­¤æ–¹æ³•ä½œä¸ºåå¤‡æ–¹æ¡ˆ
    fn rule_based_fact_extraction(&self, messages: &[Message]) -> Result<Vec<ExtractedFact>> {
        info!("ä½¿ç”¨åŸºäºè§„åˆ™çš„äº‹å®æå–ï¼ˆé™çº§æ–¹æ¡ˆï¼‰");

        let mut facts = Vec::new();

        for message in messages {
            let content = &message.content;

            // è§„åˆ™1: æå–åŒ…å«å…³é”®è¯çš„å¥å­ä½œä¸ºäº‹å®
            let sentences: Vec<&str> = content.split('ã€‚').collect();

            for (idx, sentence) in sentences.iter().enumerate() {
                let sentence = sentence.trim();
                if sentence.is_empty() {
                    continue;
                }

                // åˆ¤æ–­äº‹å®ç±»åˆ«
                let category = self.classify_by_keywords(sentence);

                // æ„å»ºäº‹å®
                let fact = ExtractedFact {
                    content: sentence.to_string(),
                    confidence: 0.6, // è§„åˆ™æå–ç½®ä¿¡åº¦è¾ƒä½
                    category,
                    entities: vec![],
                    temporal_info: None,
                    source_message_id: Some(format!("rule_extract_{idx}")),
                    metadata: {
                        let mut map = HashMap::new();
                        map.insert(
                            "extraction_method".to_string(),
                            serde_json::json!("rule_based"),
                        );
                        map
                    },
                };

                facts.push(fact);
            }
        }

        if facts.is_empty() {
            // å¦‚æœæ²¡æœ‰æå–åˆ°ä»»ä½•äº‹å®ï¼Œè‡³å°‘è¿”å›åŸå§‹å†…å®¹
            for message in messages {
                facts.push(ExtractedFact {
                    content: message.content.clone(),
                    confidence: 0.5,
                    category: FactCategory::Knowledge,
                    entities: vec![],
                    temporal_info: None,
                    source_message_id: None,
                    metadata: {
                        let mut map = HashMap::new();
                        map.insert(
                            "extraction_method".to_string(),
                            serde_json::json!("fallback_raw"),
                        );
                        map
                    },
                });
            }
        }

        info!("è§„åˆ™æå–å®Œæˆ: {} ä¸ªäº‹å®", facts.len());
        Ok(facts)
    }

    /// åŸºäºå…³é”®è¯åˆ†ç±»äº‹å®ç±»åˆ«
    fn classify_by_keywords(&self, text: &str) -> FactCategory {
        let text_lower = text.to_lowercase();

        // ä¸ªäººä¿¡æ¯å…³é”®è¯
        if text_lower.contains("æˆ‘") && (text_lower.contains("å«") || text_lower.contains("æ˜¯"))
        {
            return FactCategory::Personal;
        }

        // åå¥½å…³é”®è¯
        if text_lower.contains("å–œæ¬¢") || text_lower.contains("è®¨åŒ") || text_lower.contains("çˆ±")
        {
            return FactCategory::Preference;
        }

        // å…³ç³»å…³é”®è¯
        if text_lower.contains("æœ‹å‹") || text_lower.contains("å®¶äºº") || text_lower.contains("åŒäº‹")
        {
            return FactCategory::Relationship;
        }

        // äº‹ä»¶å…³é”®è¯
        if text_lower.contains("å‘ç”Ÿ") || text_lower.contains("ç»å†") || text_lower.contains("åšäº†")
        {
            return FactCategory::Event;
        }

        // æŠ€èƒ½å…³é”®è¯
        if text_lower.contains("ä¼š") || text_lower.contains("èƒ½") || text_lower.contains("æ“…é•¿")
        {
            return FactCategory::Skill;
        }

        // ç›®æ ‡å…³é”®è¯
        if text_lower.contains("æƒ³") || text_lower.contains("æ‰“ç®—") || text_lower.contains("è®¡åˆ’")
        {
            return FactCategory::Goal;
        }

        // é»˜è®¤ä¸ºçŸ¥è¯†ç±»
        FactCategory::Knowledge
    }

    /// æå–äººç‰©å®ä½“
    fn extract_person_entities(&self, content: &str) -> Option<Entity> {
        // ç®€åŒ–çš„äººç‰©å®ä½“è¯†åˆ«
        let person_patterns = vec![
            r"æˆ‘å«(\w+)",
            r"æˆ‘æ˜¯(\w+)",
            r"åå­—æ˜¯(\w+)",
            r"My name is (\w+)",
            r"I am (\w+)",
            r"called (\w+)",
        ];

        for pattern in person_patterns {
            if let Ok(re) = regex::Regex::new(pattern) {
                if let Some(captures) = re.captures(content) {
                    if let Some(name) = captures.get(1) {
                        return Some(Entity {
                            id: format!("person_{}", name.as_str()),
                            name: name.as_str().to_string(),
                            entity_type: EntityType::Person,
                            confidence: 0.8,
                            attributes: HashMap::new(),
                        });
                    }
                }
            }
        }
        None
    }

    /// æå–åœ°ç‚¹å®ä½“
    fn extract_location_entities(&self, content: &str) -> Option<Entity> {
        // ç®€åŒ–çš„åœ°ç‚¹å®ä½“è¯†åˆ«
        let location_keywords = vec![
            "åŒ—äº¬",
            "ä¸Šæµ·",
            "å¹¿å·",
            "æ·±åœ³",
            "æ­å·",
            "å—äº¬",
            "æˆéƒ½",
            "æ­¦æ±‰",
            "Beijing",
            "Shanghai",
            "Guangzhou",
            "Shenzhen",
            "Hangzhou",
            "New York",
            "London",
            "Tokyo",
            "Paris",
            "Berlin",
        ];

        for keyword in location_keywords {
            if content.contains(keyword) {
                return Some(Entity {
                    id: format!("location_{keyword}"),
                    name: keyword.to_string(),
                    entity_type: EntityType::Location,
                    confidence: 0.7,
                    attributes: HashMap::new(),
                });
            }
        }
        None
    }

    /// æå–ç»„ç»‡å®ä½“
    fn extract_organization_entities(&self, content: &str) -> Option<Entity> {
        // ç®€åŒ–çš„ç»„ç»‡å®ä½“è¯†åˆ«
        let org_keywords = vec![
            "å…¬å¸",
            "ä¼ä¸š",
            "ç»„ç»‡",
            "æœºæ„",
            "å­¦æ ¡",
            "å¤§å­¦",
            "åŒ»é™¢",
            "Company",
            "Corporation",
            "Organization",
            "University",
            "School",
            "Hospital",
            "Google",
            "Microsoft",
            "Apple",
            "Amazon",
            "Facebook",
            "Tesla",
        ];

        for keyword in org_keywords {
            if content.contains(keyword) {
                return Some(Entity {
                    id: format!("org_{keyword}"),
                    name: keyword.to_string(),
                    entity_type: EntityType::Organization,
                    confidence: 0.7,
                    attributes: HashMap::new(),
                });
            }
        }
        None
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_fact_category_serialization() {
        let category = FactCategory::Personal;
        let serialized = serde_json::to_string(&category).unwrap();
        assert!(serialized.contains("Personal"));
    }

    #[test]
    fn test_extracted_fact_creation() {
        let fact = ExtractedFact {
            content: "User likes coffee".to_string(),
            confidence: 0.9,
            category: FactCategory::Preference,
            entities: vec![Entity {
                id: uuid::Uuid::new_v4().to_string(),
                name: "coffee".to_string(),
                entity_type: EntityType::Product,
                confidence: 0.9,
                attributes: HashMap::new(),
            }],
            temporal_info: None,
            source_message_id: None,
            metadata: HashMap::new(),
        };

        assert_eq!(fact.content, "User likes coffee");
        assert_eq!(fact.confidence, 0.9);
        assert!(matches!(fact.category, FactCategory::Preference));
        assert_eq!(fact.entities.len(), 1);
        assert_eq!(fact.entities[0].name, "coffee");
    }

    #[test]
    fn test_message_formatting() {
        let messages = vec![
            Message {
                role: agent_mem_traits::MessageRole::User,
                content: "I love coffee".to_string(),
                timestamp: None,
            },
            Message {
                role: agent_mem_traits::MessageRole::Assistant,
                content: "That's great! What's your favorite type?".to_string(),
                timestamp: None,
            },
        ];

        // è¿™é‡Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ª FactExtractor å®ä¾‹æ¥æµ‹è¯•ï¼Œä½†ç”±äºéœ€è¦ API keyï¼Œæˆ‘ä»¬è·³è¿‡è¿™ä¸ªæµ‹è¯•
        // åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œformat_conversation æ–¹æ³•ä¼šè¢«æ­£ç¡®è°ƒç”¨
    }

    #[test]
    fn test_similarity_calculation() {
        // ç”±äº calculate_similarity æ˜¯ç§æœ‰æ–¹æ³•ï¼Œæˆ‘ä»¬æ— æ³•ç›´æ¥æµ‹è¯•
        // ä½†å¯ä»¥é€šè¿‡å…¬å…±æ–¹æ³•é—´æ¥æµ‹è¯•å…¶è¡Œä¸º
        let fact1 = ExtractedFact {
            content: "User likes coffee and tea".to_string(),
            confidence: 0.9,
            category: FactCategory::Preference,
            entities: vec![],
            temporal_info: None,
            source_message_id: None,
            metadata: HashMap::new(),
        };

        let fact2 = ExtractedFact {
            content: "User enjoys coffee and tea".to_string(),
            confidence: 0.8,
            category: FactCategory::Preference,
            entities: vec![],
            temporal_info: None,
            source_message_id: None,
            metadata: HashMap::new(),
        };

        let facts = vec![fact1, fact2];
        // merge_similar_facts ä¼šä½¿ç”¨ calculate_similarity
        // åœ¨å®é™…æµ‹è¯•ä¸­éœ€è¦åˆ›å»º FactExtractor å®ä¾‹
    }

    #[test]
    fn test_fact_validation() {
        let facts = vec![
            ExtractedFact {
                content: "Valid fact with good length".to_string(),
                confidence: 0.8,
                category: FactCategory::Knowledge,
                entities: vec![],
                temporal_info: None,
                source_message_id: None,
                metadata: HashMap::new(),
            },
            ExtractedFact {
                content: "Short".to_string(), // åº”è¯¥è¢«è¿‡æ»¤æ‰
                confidence: 0.9,
                category: FactCategory::Knowledge,
                entities: vec![],
                temporal_info: None,
                source_message_id: None,
                metadata: HashMap::new(),
            },
            ExtractedFact {
                content: "Low confidence fact".to_string(),
                confidence: 0.2, // åº”è¯¥è¢«è¿‡æ»¤æ‰
                category: FactCategory::Knowledge,
                entities: vec![],
                temporal_info: None,
                source_message_id: None,
                metadata: HashMap::new(),
            },
        ];

        // éœ€è¦åˆ›å»º FactExtractor å®ä¾‹æ¥æµ‹è¯• validate_facts
        // åœ¨å®é™…ä½¿ç”¨ä¸­ä¼šæ­£ç¡®è¿‡æ»¤
    }
}

/// é«˜çº§äº‹å®æå–å™¨ (Mem5 å¢å¼ºç‰ˆ)
///
/// æŒ‰ç…§ Mem5 è®¡åˆ’å®ç°çš„é«˜çº§äº‹å®æå–å™¨ï¼Œæ”¯æŒï¼š
/// - å®ä½“è¯†åˆ«å’Œåˆ†ç±»
/// - å…³ç³»æå–å’Œå»ºæ¨¡
/// - äº‹å®ç»“æ„åŒ–å’ŒéªŒè¯
/// - è¯­ä¹‰ç†è§£å’Œæ¨ç†
pub struct AdvancedFactExtractor {
    llm: Arc<dyn LLMProvider + Send + Sync>,
    // P0 ä¼˜åŒ–: è¶…æ—¶é…ç½®
    timeout_config: TimeoutConfig,
}

impl AdvancedFactExtractor {
    /// åˆ›å»ºæ–°çš„é«˜çº§äº‹å®æå–å™¨
    pub fn new(llm: Arc<dyn LLMProvider + Send + Sync>) -> Self {
        Self {
            llm,
            timeout_config: TimeoutConfig::default(),
        }
    }

    /// åˆ›å»ºå¸¦è¶…æ—¶é…ç½®çš„é«˜çº§äº‹å®æå–å™¨
    pub fn with_timeout_config(
        llm: Arc<dyn LLMProvider + Send + Sync>,
        timeout_config: TimeoutConfig,
    ) -> Self {
        Self {
            llm,
            timeout_config,
        }
    }

    /// æå–ç»“æ„åŒ–äº‹å® (Mem5 æ ¸å¿ƒåŠŸèƒ½)
    pub async fn extract_structured_facts(
        &self,
        messages: &[Message],
    ) -> Result<Vec<StructuredFact>> {
        info!("å¼€å§‹æå–ç»“æ„åŒ–äº‹å®ï¼Œæ¶ˆæ¯æ•°é‡: {}", messages.len());

        // 1. å®ä½“è¯†åˆ« (ç®€åŒ–å®ç°)
        let entities = self.extract_entities_simple(messages).await?;
        debug!("è¯†åˆ«åˆ° {} ä¸ªå®ä½“", entities.len());

        // 2. å…³ç³»æå– (ç®€åŒ–å®ç°)
        let relations = self.extract_relations_simple(&entities, messages).await?;
        debug!("æå–åˆ° {} ä¸ªå…³ç³»", relations.len());

        // 3. äº‹å®ç»“æ„åŒ–
        let facts = self.structure_facts(entities, relations, messages).await?;
        info!("ç”Ÿæˆäº† {} ä¸ªç»“æ„åŒ–äº‹å®", facts.len());

        Ok(facts)
    }

    /// ç»“æ„åŒ–äº‹å®ç”Ÿæˆ
    async fn structure_facts(
        &self,
        entities: Vec<Entity>,
        relations: Vec<Relation>,
        messages: &[Message],
    ) -> Result<Vec<StructuredFact>> {
        let mut facts = Vec::new();

        // åŸºäºå®ä½“å’Œå…³ç³»ç”Ÿæˆäº‹å®
        for relation in &relations {
            let subject = entities.iter().find(|e| e.id == relation.subject_id);
            let object = entities.iter().find(|e| e.id == relation.object_id);

            if let (Some(subject), Some(object)) = (subject, object) {
                let fact = StructuredFact {
                    id: format!("fact_{}", facts.len()),
                    fact_type: format!("{:?}", relation.relation_type),
                    entities: vec![subject.clone(), object.clone()],
                    relations: vec![relation.clone()],
                    description: format!(
                        "{} {} {}",
                        subject.name,
                        self.relation_to_description(&relation.relation_type),
                        object.name
                    ),
                    confidence: (relation.confidence + subject.confidence + object.confidence)
                        / 3.0,
                    importance: self.calculate_importance(&relation.relation_type, subject, object),
                    source_messages: messages
                        .iter()
                        .enumerate()
                        .map(|(i, _)| format!("msg_{i}"))
                        .collect(),
                    metadata: HashMap::new(),
                };
                facts.push(fact);
            }
        }

        // åŸºäºå•ä¸ªå®ä½“ç”Ÿæˆäº‹å®
        for entity in &entities {
            if entity.confidence > 0.8 {
                let fact = StructuredFact {
                    id: format!("fact_{}", facts.len()),
                    fact_type: format!("{:?}_entity", entity.entity_type),
                    entities: vec![entity.clone()],
                    relations: Vec::new(),
                    description: format!("è¯†åˆ«åˆ°{:?}: {}", entity.entity_type, entity.name),
                    confidence: entity.confidence,
                    importance: self.calculate_entity_importance(&entity.entity_type),
                    source_messages: messages
                        .iter()
                        .enumerate()
                        .map(|(i, _)| format!("msg_{i}"))
                        .collect(),
                    metadata: HashMap::new(),
                };
                facts.push(fact);
            }
        }

        Ok(facts)
    }

    /// ç®€åŒ–çš„å®ä½“è¯†åˆ«
    async fn extract_entities_simple(&self, messages: &[Message]) -> Result<Vec<Entity>> {
        let mut entities = Vec::new();
        let mut entity_id = 0;

        for message in messages {
            // ç®€åŒ–çš„å®ä½“è¯†åˆ«é€»è¾‘
            let words: Vec<&str> = message.content.split_whitespace().collect();

            for (i, word) in words.iter().enumerate() {
                // ç®€å•çš„äººåè¯†åˆ«
                if word.len() >= 2
                    && word.chars().all(|c| c.is_alphabetic())
                    && i > 0
                    && (words[i - 1] == "æˆ‘å«" || words[i - 1] == "å«" || words[i - 1] == "æ˜¯")
                {
                    entities.push(Entity {
                        id: format!("entity_{entity_id}"),
                        name: word.to_string(),
                        entity_type: EntityType::Person,
                        confidence: 0.8,
                        attributes: HashMap::new(),
                    });
                    entity_id += 1;
                }

                // ç®€å•çš„åœ°ç‚¹è¯†åˆ«
                if word.ends_with("å¸‚") || word.ends_with("çœ") || word.ends_with("åŒº") {
                    entities.push(Entity {
                        id: format!("entity_{entity_id}"),
                        name: word.to_string(),
                        entity_type: EntityType::Location,
                        confidence: 0.7,
                        attributes: HashMap::new(),
                    });
                    entity_id += 1;
                }

                // ç®€å•çš„ç»„ç»‡è¯†åˆ«
                if word.ends_with("å…¬å¸") || word.ends_with("ä¼ä¸š") || word.ends_with("æœºæ„")
                {
                    entities.push(Entity {
                        id: format!("entity_{entity_id}"),
                        name: word.to_string(),
                        entity_type: EntityType::Organization,
                        confidence: 0.7,
                        attributes: HashMap::new(),
                    });
                    entity_id += 1;
                }
            }
        }

        Ok(entities)
    }

    /// ç®€åŒ–çš„å…³ç³»æå–
    async fn extract_relations_simple(
        &self,
        entities: &[Entity],
        messages: &[Message],
    ) -> Result<Vec<Relation>> {
        let mut relations = Vec::new();

        // ç®€åŒ–çš„å…³ç³»æå–é€»è¾‘
        for message in messages {
            let content = &message.content;

            // æŸ¥æ‰¾å·¥ä½œå…³ç³»
            if content.contains("åœ¨") && content.contains("å·¥ä½œ") {
                for entity in entities {
                    if entity.entity_type == EntityType::Person {
                        for location in entities {
                            if location.entity_type == EntityType::Location
                                || location.entity_type == EntityType::Organization
                            {
                                relations.push(Relation {
                                    subject: entity.name.clone(),
                                    predicate: "å·¥ä½œäº".to_string(),
                                    object: location.name.clone(),
                                    relation_type: RelationType::WorksAt,
                                    confidence: 0.7,
                                    subject_id: entity.id.clone(),
                                    object_id: location.id.clone(),
                                });
                            }
                        }
                    }
                }
            }

            // æŸ¥æ‰¾å–œå¥½å…³ç³»
            if content.contains("å–œæ¬¢") {
                for entity in entities {
                    if entity.entity_type == EntityType::Person {
                        relations.push(Relation {
                            subject: entity.name.clone(),
                            predicate: "å–œæ¬¢".to_string(),
                            object: "ç¼–ç¨‹".to_string(), // ç®€åŒ–å¤„ç†
                            relation_type: RelationType::Likes,
                            confidence: 0.6,
                            subject_id: entity.id.clone(),
                            object_id: "concept_programming".to_string(),
                        });
                    }
                }
            }
        }

        Ok(relations)
    }

    /// å…³ç³»ç±»å‹è½¬æè¿°
    fn relation_to_description(&self, relation_type: &RelationType) -> &'static str {
        match relation_type {
            RelationType::HasProperty => "æ‹¥æœ‰",
            RelationType::LocatedAt => "ä½äº",
            RelationType::WorksAt => "å·¥ä½œäº",
            RelationType::FriendOf => "æ˜¯æœ‹å‹",
            RelationType::FamilyOf => "æ˜¯å®¶äºº",
            RelationType::Likes => "å–œæ¬¢",
            RelationType::Dislikes => "ä¸å–œæ¬¢",
            RelationType::ParticipatesIn => "å‚ä¸",
            RelationType::OccursAt => "å‘ç”Ÿäº",
            RelationType::Causes => "å¯¼è‡´",
            RelationType::Other(_) => "ç›¸å…³äº",
        }
    }

    /// è®¡ç®—å…³ç³»é‡è¦æ€§
    fn calculate_importance(
        &self,
        relation_type: &RelationType,
        subject: &Entity,
        object: &Entity,
    ) -> f32 {
        let base_importance = match relation_type {
            RelationType::FamilyOf => 0.9,
            RelationType::WorksAt => 0.8,
            RelationType::Likes | RelationType::Dislikes => 0.7,
            RelationType::FriendOf => 0.6,
            RelationType::HasProperty => 0.5,
            RelationType::LocatedAt => 0.4,
            RelationType::ParticipatesIn => 0.6,
            RelationType::OccursAt => 0.5,
            RelationType::Causes => 0.8,
            RelationType::Other(_) => 0.3,
        };

        // æ ¹æ®å®ä½“ç±»å‹è°ƒæ•´é‡è¦æ€§
        let entity_boost = match (&subject.entity_type, &object.entity_type) {
            (EntityType::Person, EntityType::Person) => 0.2,
            (EntityType::Person, EntityType::Organization) => 0.15,
            (EntityType::Person, EntityType::Location) => 0.1,
            _ => 0.0,
        };

        f32::min(base_importance + entity_boost, 1.0)
    }

    /// è®¡ç®—å®ä½“é‡è¦æ€§
    fn calculate_entity_importance(&self, entity_type: &EntityType) -> f32 {
        match entity_type {
            EntityType::Person => 0.8,
            EntityType::Organization => 0.7,
            EntityType::Location => 0.6,
            EntityType::Product => 0.6,
            EntityType::Concept => 0.4,
            EntityType::Date => 0.3,
            EntityType::Time => 0.3,
            EntityType::Number => 0.2,
            EntityType::Money => 0.7,
            EntityType::Percentage => 0.4,
            EntityType::Email => 0.5,
            EntityType::Phone => 0.5,
            EntityType::Url => 0.3,
            EntityType::Event => 0.7,
            EntityType::Object => 0.3,
            EntityType::Skill => 0.6,
            EntityType::Language => 0.4,
            EntityType::Technology => 0.5,
            EntityType::Other(_) => 0.2,
        }
    }
}
