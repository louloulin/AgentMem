//! Performance analysis routes
//!
//! ğŸ†• Phase 4.2: æ€§èƒ½åˆ†æåŠŸèƒ½
//! æä¾›æ€§èƒ½åˆ†æã€ç“¶é¢ˆè¯†åˆ«å’Œä¼˜åŒ–å»ºè®®

use crate::error::ServerResult;
use crate::models;
use crate::routes::memory::{get_search_stats, MemoryManager};
use axum::{extract::Extension, response::Json};
use chrono::Utc;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use tracing::info;

/// æ€§èƒ½åˆ†æå“åº”
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceAnalysisResponse {
    /// æ€»ä½“æ€§èƒ½è¯„åˆ†ï¼ˆ0-100ï¼‰
    pub overall_score: f64,
    /// æ€§èƒ½æŒ‡æ ‡
    pub metrics: HashMap<String, f64>,
    /// æ€§èƒ½ç“¶é¢ˆ
    pub bottlenecks: Vec<Bottleneck>,
    /// ä¼˜åŒ–å»ºè®®
    pub recommendations: Vec<String>,
    /// åˆ†ææ—¶é—´æˆ³
    pub timestamp: chrono::DateTime<Utc>,
}

/// æ€§èƒ½ç“¶é¢ˆ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Bottleneck {
    /// ç“¶é¢ˆç±»å‹
    pub category: String,
    /// ç“¶é¢ˆæè¿°
    pub description: String,
    /// ä¸¥é‡ç¨‹åº¦ï¼ˆLOW, MEDIUM, HIGHï¼‰
    pub severity: String,
    /// å½±å“è¯„åˆ†
    pub impact_score: f64,
}

/// ğŸ†• Phase 4.2: è®¡ç®—æ€§èƒ½è¯„åˆ†
/// 
/// åŸºäºå¤šä¸ªæ€§èƒ½æŒ‡æ ‡è®¡ç®—æ€»ä½“æ€§èƒ½è¯„åˆ†ï¼ˆ0-100ï¼‰
fn calculate_performance_score(metrics: &HashMap<String, f64>) -> f64 {
    let mut score: f64 = 100.0;
    
    // 1. æœç´¢å»¶è¿Ÿè¯„åˆ†ï¼ˆæƒé‡ï¼š30%ï¼‰
    if let Some(&search_latency) = metrics.get("avg_search_latency_ms") {
        if search_latency > 100.0 {
            score -= 30.0; // å»¶è¿Ÿè¶…è¿‡100msï¼Œæ‰£30åˆ†
        } else if search_latency > 50.0 {
            score -= 15.0; // å»¶è¿Ÿ50-100msï¼Œæ‰£15åˆ†
        } else if search_latency > 20.0 {
            score -= 5.0; // å»¶è¿Ÿ20-50msï¼Œæ‰£5åˆ†
        }
    }
    
    // 2. ç¼“å­˜å‘½ä¸­ç‡è¯„åˆ†ï¼ˆæƒé‡ï¼š25%ï¼‰
    if let Some(&cache_hit_rate) = metrics.get("cache_hit_rate") {
        if cache_hit_rate < 0.5 {
            score -= 25.0; // ç¼“å­˜å‘½ä¸­ç‡ä½äº50%ï¼Œæ‰£25åˆ†
        } else if cache_hit_rate < 0.7 {
            score -= 12.0; // ç¼“å­˜å‘½ä¸­ç‡50-70%ï¼Œæ‰£12åˆ†
        } else if cache_hit_rate < 0.8 {
            score -= 5.0; // ç¼“å­˜å‘½ä¸­ç‡70-80%ï¼Œæ‰£5åˆ†
        }
    }
    
    // 3. ååé‡è¯„åˆ†ï¼ˆæƒé‡ï¼š25%ï¼‰
    if let Some(&throughput) = metrics.get("avg_throughput_ops_per_sec") {
        if throughput < 10.0 {
            score -= 25.0; // ååé‡ä½äº10 ops/sï¼Œæ‰£25åˆ†
        } else if throughput < 50.0 {
            score -= 12.0; // ååé‡10-50 ops/sï¼Œæ‰£12åˆ†
        } else if throughput < 100.0 {
            score -= 5.0; // ååé‡50-100 ops/sï¼Œæ‰£5åˆ†
        }
    }
    
    // 4. é”™è¯¯ç‡è¯„åˆ†ï¼ˆæƒé‡ï¼š20%ï¼‰
    if let Some(&error_rate) = metrics.get("error_rate") {
        if error_rate > 0.1 {
            score -= 20.0; // é”™è¯¯ç‡è¶…è¿‡10%ï¼Œæ‰£20åˆ†
        } else if error_rate > 0.05 {
            score -= 10.0; // é”™è¯¯ç‡5-10%ï¼Œæ‰£10åˆ†
        } else if error_rate > 0.01 {
            score -= 5.0; // é”™è¯¯ç‡1-5%ï¼Œæ‰£5åˆ†
        }
    }
    
    score.max(0.0f64).min(100.0f64)
}

/// ğŸ†• Phase 4.2: è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ
fn identify_bottlenecks(metrics: &HashMap<String, f64>) -> Vec<Bottleneck> {
    let mut bottlenecks = Vec::new();
    
    // 1. æœç´¢å»¶è¿Ÿç“¶é¢ˆ
    if let Some(&latency) = metrics.get("avg_search_latency_ms") {
        if latency > 100.0 {
            bottlenecks.push(Bottleneck {
                category: "æœç´¢å»¶è¿Ÿ".to_string(),
                description: format!("å¹³å‡æœç´¢å»¶è¿Ÿ {}ms è¿‡é«˜ï¼Œå»ºè®®ä¼˜åŒ–å‘é‡æœç´¢æˆ–å¢åŠ ç¼“å­˜", latency),
                severity: "HIGH".to_string(),
                impact_score: 0.8,
            });
        } else if latency > 50.0 {
            bottlenecks.push(Bottleneck {
                category: "æœç´¢å»¶è¿Ÿ".to_string(),
                description: format!("å¹³å‡æœç´¢å»¶è¿Ÿ {}ms è¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–æŸ¥è¯¢é€»è¾‘", latency),
                severity: "MEDIUM".to_string(),
                impact_score: 0.5,
            });
        }
    }
    
    // 2. ç¼“å­˜å‘½ä¸­ç‡ç“¶é¢ˆ
    if let Some(&hit_rate) = metrics.get("cache_hit_rate") {
        if hit_rate < 0.5 {
            bottlenecks.push(Bottleneck {
                category: "ç¼“å­˜æ•ˆç‡".to_string(),
                description: format!("ç¼“å­˜å‘½ä¸­ç‡ {:.1}% è¿‡ä½ï¼Œå»ºè®®å¢åŠ ç¼“å­˜å®¹é‡æˆ–ä¼˜åŒ–ç¼“å­˜ç­–ç•¥", hit_rate * 100.0),
                severity: "HIGH".to_string(),
                impact_score: 0.7,
            });
        } else if hit_rate < 0.7 {
            bottlenecks.push(Bottleneck {
                category: "ç¼“å­˜æ•ˆç‡".to_string(),
                description: format!("ç¼“å­˜å‘½ä¸­ç‡ {:.1}% è¾ƒä½ï¼Œå»ºè®®ä¼˜åŒ–ç¼“å­˜é¢„çƒ­ç­–ç•¥", hit_rate * 100.0),
                severity: "MEDIUM".to_string(),
                impact_score: 0.4,
            });
        }
    }
    
    // 3. ååé‡ç“¶é¢ˆ
    if let Some(&throughput) = metrics.get("avg_throughput_ops_per_sec") {
        if throughput < 10.0 {
            bottlenecks.push(Bottleneck {
                category: "ååé‡".to_string(),
                description: format!("ååé‡ {:.1} ops/s è¿‡ä½ï¼Œå»ºè®®ä¼˜åŒ–æ‰¹é‡æ“ä½œæˆ–å¢åŠ å¹¶å‘", throughput),
                severity: "HIGH".to_string(),
                impact_score: 0.9,
            });
        } else if throughput < 50.0 {
            bottlenecks.push(Bottleneck {
                category: "ååé‡".to_string(),
                description: format!("ååé‡ {:.1} ops/s è¾ƒä½ï¼Œå»ºè®®ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢æˆ–ç´¢å¼•", throughput),
                severity: "MEDIUM".to_string(),
                impact_score: 0.5,
            });
        }
    }
    
    bottlenecks
}

/// ğŸ†• Phase 4.2: ç”Ÿæˆä¼˜åŒ–å»ºè®®
fn generate_recommendations(
    _metrics: &HashMap<String, f64>,
    bottlenecks: &[Bottleneck],
) -> Vec<String> {
    let mut recommendations = Vec::new();
    
    // åŸºäºç“¶é¢ˆç”Ÿæˆå»ºè®®
    for bottleneck in bottlenecks {
        match bottleneck.category.as_str() {
            "æœç´¢å»¶è¿Ÿ" => {
                recommendations.push("ä¼˜åŒ–å‘é‡æœç´¢ï¼šè€ƒè™‘ä½¿ç”¨æ›´é«˜æ•ˆçš„å‘é‡ç´¢å¼•ï¼ˆå¦‚HNSWï¼‰".to_string());
                recommendations.push("å¢åŠ ç¼“å­˜ï¼šæé«˜æŸ¥è¯¢ç»“æœç¼“å­˜å‘½ä¸­ç‡".to_string());
            }
            "ç¼“å­˜æ•ˆç‡" => {
                recommendations.push("å¢åŠ ç¼“å­˜å®¹é‡ï¼šè°ƒæ•´SEARCH_CACHE_CAPACITYç¯å¢ƒå˜é‡".to_string());
                recommendations.push("ä¼˜åŒ–ç¼“å­˜é¢„çƒ­ï¼šå®šæœŸæ‰§è¡Œç¼“å­˜é¢„çƒ­æ“ä½œ".to_string());
            }
            "ååé‡" => {
                recommendations.push("ä¼˜åŒ–æ‰¹é‡æ“ä½œï¼šä½¿ç”¨æ‰¹é‡APIå‡å°‘ç½‘ç»œå¾€è¿”".to_string());
                recommendations.push("å¢åŠ å¹¶å‘ï¼šè°ƒæ•´è¿æ¥æ± å¤§å°æˆ–ä½¿ç”¨å¼‚æ­¥å¤„ç†".to_string());
            }
            _ => {}
        }
    }
    
    // é€šç”¨å»ºè®®
    if bottlenecks.is_empty() {
        recommendations.push("æ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œç»§ç»­ä¿æŒå½“å‰é…ç½®".to_string());
    } else {
        recommendations.push("å®šæœŸç›‘æ§æ€§èƒ½æŒ‡æ ‡ï¼ŒåŠæ—¶å‘ç°é—®é¢˜".to_string());
        recommendations.push("è€ƒè™‘ä½¿ç”¨æ€§èƒ½åŸºå‡†æµ‹è¯•APIè¿›è¡Œå®šæœŸæµ‹è¯•".to_string());
    }
    
    // å»é‡
    recommendations.sort();
    recommendations.dedup();
    
    recommendations
}

/// è·å–æ€§èƒ½åˆ†ææŠ¥å‘Š
/// 
/// ğŸ†• Phase 4.2: æ€§èƒ½åˆ†æ - æä¾›æ€§èƒ½åˆ†æã€ç“¶é¢ˆè¯†åˆ«å’Œä¼˜åŒ–å»ºè®®
#[utoipa::path(
    get,
    path = "/api/v1/performance/analysis",
    tag = "performance",
    responses(
        (status = 200, description = "Performance analysis completed successfully", body = PerformanceAnalysisResponse),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn get_performance_analysis(
    Extension(_memory_manager): Extension<Arc<MemoryManager>>,
) -> ServerResult<Json<models::ApiResponse<PerformanceAnalysisResponse>>> {
    info!("ğŸ“Š ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š");

    // 1. æ”¶é›†æ€§èƒ½æŒ‡æ ‡
    let search_stats = get_search_stats();
    let stats_read = search_stats.read().await;
    
    let mut metrics = HashMap::new();
    
    // æœç´¢ç›¸å…³æŒ‡æ ‡
    metrics.insert("avg_search_latency_ms".to_string(), stats_read.avg_latency_ms());
    metrics.insert("cache_hit_rate".to_string(), stats_read.cache_hit_rate());
    metrics.insert("total_searches".to_string(), stats_read.get_total_searches() as f64);
    metrics.insert("cache_hits".to_string(), stats_read.get_cache_hits() as f64);
    metrics.insert("cache_misses".to_string(), stats_read.get_cache_misses() as f64);
    
    // è®¡ç®—ååé‡ï¼ˆåŸºäºæ€»æœç´¢æ¬¡æ•°å’Œå¹³å‡å»¶è¿Ÿï¼‰
    let total_searches = stats_read.get_total_searches() as f64;
    let avg_latency_ms = stats_read.avg_latency_ms();
    let throughput = if avg_latency_ms > 0.0 {
        1000.0 / avg_latency_ms // ops per second
    } else {
        0.0
    };
    metrics.insert("avg_throughput_ops_per_sec".to_string(), throughput);
    
    // è®¡ç®—é”™è¯¯ç‡ï¼ˆåŸºäºç¼“å­˜æœªå‘½ä¸­ç‡ä½œä¸ºä»£ç†ï¼‰
    let error_rate = if total_searches > 0.0 {
        let failed_searches = stats_read.get_cache_misses() as f64;
        failed_searches / total_searches * 0.1 // å‡è®¾10%çš„æœªå‘½ä¸­ä¼šå¯¼è‡´é”™è¯¯
    } else {
        0.0
    };
    metrics.insert("error_rate".to_string(), error_rate);
    
    // 2. è®¡ç®—æ€§èƒ½è¯„åˆ†
    let overall_score = calculate_performance_score(&metrics);
    
    // 3. è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ
    let bottlenecks = identify_bottlenecks(&metrics);
    
    // 4. ç”Ÿæˆä¼˜åŒ–å»ºè®®
    let recommendations = generate_recommendations(&metrics, &bottlenecks);
    
    let response = PerformanceAnalysisResponse {
        overall_score,
        metrics,
        bottlenecks,
        recommendations,
        timestamp: Utc::now(),
    };
    
    info!("ğŸ“Š æ€§èƒ½åˆ†æå®Œæˆ: æ€»ä½“è¯„åˆ†={:.1}, ç“¶é¢ˆæ•°={}, å»ºè®®æ•°={}",
        response.overall_score,
        response.bottlenecks.len(),
        response.recommendations.len());
    
    Ok(Json(models::ApiResponse::success(response)))
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::collections::HashMap;

    /// ğŸ†• Phase 4.2: æµ‹è¯•æ€§èƒ½è¯„åˆ†è®¡ç®—
    #[test]
    fn test_performance_score_calculation() {
        // æµ‹è¯•1: ä¼˜ç§€æ€§èƒ½
        let mut metrics1 = HashMap::new();
        metrics1.insert("avg_search_latency_ms".to_string(), 10.0);
        metrics1.insert("cache_hit_rate".to_string(), 0.9);
        metrics1.insert("avg_throughput_ops_per_sec".to_string(), 100.0);
        metrics1.insert("error_rate".to_string(), 0.0);
        let score1 = calculate_performance_score(&metrics1);
        assert!(score1 >= 90.0, "ä¼˜ç§€æ€§èƒ½åº”è¯¥å¾—åˆ°é«˜åˆ†");

        // æµ‹è¯•2: è¾ƒå·®æ€§èƒ½
        let mut metrics2 = HashMap::new();
        metrics2.insert("avg_search_latency_ms".to_string(), 200.0);
        metrics2.insert("cache_hit_rate".to_string(), 0.3);
        metrics2.insert("avg_throughput_ops_per_sec".to_string(), 5.0);
        metrics2.insert("error_rate".to_string(), 0.2);
        let score2 = calculate_performance_score(&metrics2);
        assert!(score2 < 50.0, "è¾ƒå·®æ€§èƒ½åº”è¯¥å¾—åˆ°ä½åˆ†");
        assert!(score1 > score2, "ä¼˜ç§€æ€§èƒ½åº”è¯¥æ¯”è¾ƒå·®æ€§èƒ½å¾—åˆ†é«˜");
    }

    /// ğŸ†• Phase 4.2: æµ‹è¯•ç“¶é¢ˆè¯†åˆ«
    #[test]
    fn test_bottleneck_identification() {
        let mut metrics = HashMap::new();
        metrics.insert("avg_search_latency_ms".to_string(), 150.0); // é«˜å»¶è¿Ÿ
        metrics.insert("cache_hit_rate".to_string(), 0.3); // ä½å‘½ä¸­ç‡
        metrics.insert("avg_throughput_ops_per_sec".to_string(), 5.0); // ä½ååé‡
        
        let bottlenecks = identify_bottlenecks(&metrics);
        
        assert!(bottlenecks.len() >= 2, "åº”è¯¥è¯†åˆ«å‡ºå¤šä¸ªç“¶é¢ˆ");
        assert!(bottlenecks.iter().any(|b| b.category == "æœç´¢å»¶è¿Ÿ"), "åº”è¯¥è¯†åˆ«æœç´¢å»¶è¿Ÿç“¶é¢ˆ");
        assert!(bottlenecks.iter().any(|b| b.category == "ç¼“å­˜æ•ˆç‡"), "åº”è¯¥è¯†åˆ«ç¼“å­˜æ•ˆç‡ç“¶é¢ˆ");
    }

    /// ğŸ†• Phase 4.2: æµ‹è¯•ä¼˜åŒ–å»ºè®®ç”Ÿæˆ
    #[test]
    fn test_recommendations_generation() {
        let mut metrics = HashMap::new();
        metrics.insert("avg_search_latency_ms".to_string(), 150.0);
        metrics.insert("cache_hit_rate".to_string(), 0.3);
        
        let bottlenecks = identify_bottlenecks(&metrics);
        let recommendations = generate_recommendations(&metrics, &bottlenecks);
        
        assert!(!recommendations.is_empty(), "åº”è¯¥ç”Ÿæˆä¼˜åŒ–å»ºè®®");
        assert!(recommendations.iter().any(|r| r.contains("ç¼“å­˜")), "åº”è¯¥åŒ…å«ç¼“å­˜ç›¸å…³å»ºè®®");
    }
}

