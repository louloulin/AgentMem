//! Memory Predictor routes
//!
//! ğŸ†• Phase 2.3: ç®€åŒ–ç‰ˆMemoryPredictor
//! åŸºäºè®¿é—®æ¨¡å¼å’Œæœç´¢å†å²é¢„æµ‹å¯èƒ½éœ€è¦çš„è®°å¿†

use crate::error::ServerResult;
use crate::models;
use crate::routes::memory::{calculate_access_pattern_score, get_search_stats, MemoryManager};
use axum::{extract::Extension, response::Json};
use chrono::Utc;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use tracing::info;

/// è®°å¿†é¢„æµ‹å“åº”
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MemoryPredictionResponse {
    /// é¢„æµ‹çš„è®°å¿†IDåˆ—è¡¨ï¼ˆæŒ‰é¢„æµ‹åˆ†æ•°æ’åºï¼‰
    pub predicted_memory_ids: Vec<String>,
    /// é¢„æµ‹åˆ†æ•°ï¼ˆ0-1ï¼Œåˆ†æ•°è¶Šé«˜è¡¨ç¤ºè¶Šå¯èƒ½è¢«éœ€è¦ï¼‰
    pub prediction_scores: Vec<f64>,
    /// é¢„æµ‹ä¾æ®
    pub prediction_basis: Vec<String>,
    /// é¢„æµ‹æ—¶é—´æˆ³
    pub timestamp: chrono::DateTime<Utc>,
}

/// é¢„æµ‹è¯·æ±‚
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PredictionRequest {
    /// æŸ¥è¯¢æ–‡æœ¬ï¼ˆå¯é€‰ï¼Œç”¨äºåŸºäºæŸ¥è¯¢çš„é¢„æµ‹ï¼‰
    pub query: Option<String>,
    /// é¢„æµ‹æ•°é‡ï¼ˆé»˜è®¤10ï¼‰
    pub limit: Option<usize>,
    /// Agent IDï¼ˆå¯é€‰ï¼Œç”¨äºåŸºäºAgentçš„é¢„æµ‹ï¼‰
    pub agent_id: Option<String>,
    /// User IDï¼ˆå¯é€‰ï¼Œç”¨äºåŸºäºUserçš„é¢„æµ‹ï¼‰
    pub user_id: Option<String>,
}

/// ğŸ†• Phase 2.3: åŸºäºè®¿é—®æ¨¡å¼é¢„æµ‹è®°å¿†
/// 
/// é¢„æµ‹é€»è¾‘ï¼š
/// 1. åŸºäºè®¿é—®é¢‘ç‡å’Œæœ€è¿‘è®¿é—®æ—¶é—´ï¼ˆä½¿ç”¨calculate_access_pattern_scoreï¼‰
/// 2. åŸºäºæœç´¢ç»Ÿè®¡ï¼ˆé«˜é¢‘æœç´¢çš„è®°å¿†æ›´å¯èƒ½è¢«éœ€è¦ï¼‰
/// 3. åŸºäºæ—¶é—´æ¨¡å¼ï¼ˆæœ€è¿‘è®¿é—®çš„è®°å¿†æ›´å¯èƒ½è¢«å†æ¬¡è®¿é—®ï¼‰
fn predict_memories_by_access_pattern(
    memory_scores: &[(String, f64, i64)],
    limit: usize,
) -> (Vec<String>, Vec<f64>, Vec<String>) {
    let mut predictions = Vec::new();
    let mut scores = Vec::new();
    let mut basis = Vec::new();

    // æŒ‰è¯„åˆ†æ’åºï¼Œå–å‰limitä¸ª
    let top_memories: Vec<_> = memory_scores
        .iter()
        .take(limit)
        .map(|(id, score, access_count)| (id.clone(), *score, *access_count))
        .collect();

    for (id, score, access_count) in top_memories {
        predictions.push(id.clone());
        scores.push(score);
        basis.push(format!(
            "è®¿é—®æ¨¡å¼è¯„åˆ†: {:.2} (è®¿é—®æ¬¡æ•°: {})",
            score, access_count
        ));
    }

    (predictions, scores, basis)
}

/// ğŸ†• Phase 2.3: åŸºäºæœç´¢ç»Ÿè®¡é¢„æµ‹è®°å¿†
/// 
/// é¢„æµ‹é€»è¾‘ï¼š
/// 1. å¦‚æœæ€»æœç´¢æ¬¡æ•°é«˜ï¼Œè¯´æ˜ç³»ç»Ÿæ´»è·ƒï¼Œé¢„æµ‹æœ€è¿‘è®¿é—®çš„è®°å¿†
/// 2. å¦‚æœç¼“å­˜å‘½ä¸­ç‡é«˜ï¼Œè¯´æ˜è®¿é—®æ¨¡å¼ç¨³å®šï¼Œé¢„æµ‹é«˜é¢‘è®°å¿†
fn enhance_prediction_with_search_stats(
    _predictions: &mut Vec<String>,
    scores: &mut Vec<f64>,
    basis: &mut Vec<String>,
    search_stats: &crate::routes::memory::SearchStatistics,
) {
    // å¦‚æœæ€»æœç´¢æ¬¡æ•°è¾ƒé«˜ï¼Œè¯´æ˜ç³»ç»Ÿæ´»è·ƒï¼Œå¯ä»¥å¢å¼ºé¢„æµ‹
    if search_stats.get_total_searches() > 100 {
        // åœ¨ç°æœ‰é¢„æµ‹åŸºç¡€ä¸Šï¼Œå¯ä»¥æ·»åŠ ä¸€äº›é¢å¤–çš„é€»è¾‘
        // ä¾‹å¦‚ï¼šå¦‚æœç¼“å­˜å‘½ä¸­ç‡é«˜ï¼Œè¯´æ˜è®¿é—®æ¨¡å¼ç¨³å®šï¼Œé¢„æµ‹æ›´å¯é 
        let cache_hit_rate = search_stats.cache_hit_rate();
        if cache_hit_rate > 0.7 {
            // ç¼“å­˜å‘½ä¸­ç‡é«˜ï¼Œè¯´æ˜è®¿é—®æ¨¡å¼ç¨³å®šï¼Œé¢„æµ‹æ›´å¯é 
            // è¿™é‡Œå¯ä»¥å¢å¼ºé¢„æµ‹åˆ†æ•°
            for (score, basis_item) in scores.iter_mut().zip(basis.iter_mut()) {
                *score *= 1.1; // æé«˜10%çš„é¢„æµ‹åˆ†æ•°
                *basis_item = format!("{} (ç¼“å­˜å‘½ä¸­ç‡é«˜ï¼Œé¢„æµ‹æ›´å¯é )", basis_item);
            }
        }
    }
}

/// è·å–è®°å¿†é¢„æµ‹
/// 
/// ğŸ†• Phase 2.3: ç®€åŒ–ç‰ˆMemoryPredictor - åŸºäºè®¿é—®æ¨¡å¼å’Œæœç´¢å†å²é¢„æµ‹å¯èƒ½éœ€è¦çš„è®°å¿†
#[utoipa::path(
    post,
    path = "/api/v1/memories/predict",
    tag = "memory",
    request_body = PredictionRequest,
    responses(
        (status = 200, description = "Memory prediction completed successfully", body = MemoryPredictionResponse),
        (status = 400, description = "Invalid request"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn predict_memories(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    Json(request): Json<PredictionRequest>,
) -> ServerResult<Json<models::ApiResponse<MemoryPredictionResponse>>> {
    info!("ğŸ”® å¼€å§‹è®°å¿†é¢„æµ‹: query={:?}, limit={:?}", 
        request.query, request.limit);

    let limit = request.limit.unwrap_or(10);
    if limit == 0 {
        return Err(crate::error::ServerError::bad_request(
            "Limit cannot be zero".to_string(),
        ));
    }

    // 1. ä»LibSQLæŸ¥è¯¢è®°å¿†çš„è®¿é—®æ¨¡å¼æ•°æ®ï¼ˆä½¿ç”¨ä¸warmup_cacheç›¸åŒçš„æ–¹æ³•ï¼‰
    use libsql::{params, Builder};
    let db_path = std::env::var("DATABASE_URL")
        .unwrap_or_else(|_| "file:./data/agentmem.db".to_string())
        .replace("file:", "");
    
    let db = Builder::new_local(&db_path)
        .build()
        .await
        .map_err(|e| {
            crate::error::ServerError::internal_error(format!("Failed to open database: {}", e))
        })?;
    
    let conn = db
        .connect()
        .map_err(|e| {
            crate::error::ServerError::internal_error(format!("Failed to connect: {}", e))
        })?;

    // æ„å»ºæŸ¥è¯¢ï¼šè·å–è®¿é—®é¢‘ç‡å’Œæœ€è¿‘è®¿é—®æ—¶é—´
    // æ ¹æ®æ˜¯å¦æœ‰è¿‡æ»¤æ¡ä»¶æ„å»ºä¸åŒçš„æŸ¥è¯¢
    let mut rows = if let Some(agent_id) = &request.agent_id {
        let query = "SELECT id, access_count, last_accessed FROM memories WHERE is_deleted = 0 AND agent_id = ? ORDER BY access_count DESC, last_accessed DESC LIMIT ?";
        let mut stmt = conn
            .prepare(query)
            .await
            .map_err(|e| {
                crate::error::ServerError::internal_error(format!("Failed to prepare query: {}", e))
            })?;
        stmt
            .query(params![agent_id.clone(), (limit * 2) as i64])
            .await
            .map_err(|e| {
                crate::error::ServerError::internal_error(format!("Failed to execute query: {}", e))
            })?
    } else if let Some(user_id) = &request.user_id {
        let query = "SELECT id, access_count, last_accessed FROM memories WHERE is_deleted = 0 AND user_id = ? ORDER BY access_count DESC, last_accessed DESC LIMIT ?";
        let mut stmt = conn
            .prepare(query)
            .await
            .map_err(|e| {
                crate::error::ServerError::internal_error(format!("Failed to prepare query: {}", e))
            })?;
        stmt
            .query(params![user_id.clone(), (limit * 2) as i64])
            .await
            .map_err(|e| {
                crate::error::ServerError::internal_error(format!("Failed to execute query: {}", e))
            })?
    } else {
        let query = "SELECT id, access_count, last_accessed FROM memories WHERE is_deleted = 0 ORDER BY access_count DESC, last_accessed DESC LIMIT ?";
        let mut stmt = conn
            .prepare(query)
            .await
            .map_err(|e| {
                crate::error::ServerError::internal_error(format!("Failed to prepare query: {}", e))
            })?;
        stmt
            .query(params![(limit * 2) as i64])
            .await
            .map_err(|e| {
                crate::error::ServerError::internal_error(format!("Failed to execute query: {}", e))
            })?
    };

    // 2. è®¡ç®—è®¿é—®æ¨¡å¼è¯„åˆ†
    let mut memory_scores: Vec<(String, f64, i64)> = Vec::new();
    while let Some(row) = rows
        .next()
        .await
        .map_err(|e| {
            crate::error::ServerError::internal_error(format!("Failed to fetch row: {}", e))
        })? {
        let id: String = row.get(0)
            .map_err(|e| crate::error::ServerError::internal_error(format!("Failed to get memory_id from row: {}", e)))?;
        let access_count: i64 = row.get(1).unwrap_or(0);
        let last_accessed_ts: Option<i64> = row.get(2).ok();

        // è®¡ç®—è®¿é—®æ¨¡å¼è¯„åˆ†
        let score = calculate_access_pattern_score(access_count, last_accessed_ts);
        memory_scores.push((id, score, access_count));
    }

    // 3. æŒ‰è¯„åˆ†æ’åº
    memory_scores.sort_by(|a, b| {
        b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal)
    });

    // 4. ç”Ÿæˆé¢„æµ‹
    let (mut predictions, mut scores, mut basis) =
        predict_memories_by_access_pattern(&memory_scores, limit);

    // 5. åŸºäºæœç´¢ç»Ÿè®¡å¢å¼ºé¢„æµ‹
    let search_stats = get_search_stats();
    let stats_read = search_stats.read().await;
    enhance_prediction_with_search_stats(&mut predictions, &mut scores, &mut basis, &stats_read);
    drop(stats_read);

    info!("ğŸ”® è®°å¿†é¢„æµ‹å®Œæˆ: é¢„æµ‹äº† {} ä¸ªè®°å¿†", predictions.len());

    let response = MemoryPredictionResponse {
        predicted_memory_ids: predictions,
        prediction_scores: scores,
        prediction_basis: basis,
        timestamp: Utc::now(),
    };

    Ok(Json(models::ApiResponse::success(response)))
}

#[cfg(test)]
mod tests {
    use super::*;

    /// ğŸ†• Phase 2.3: æµ‹è¯•è®¿é—®æ¨¡å¼é¢„æµ‹
    #[test]
    fn test_predict_memories_by_access_pattern() {
        let memory_scores = vec![
            ("id1".to_string(), 10.0, 100),
            ("id2".to_string(), 8.0, 80),
            ("id3".to_string(), 5.0, 50),
        ];

        let (predictions, scores, basis) = predict_memories_by_access_pattern(&memory_scores, 2);

        assert_eq!(predictions.len(), 2, "åº”è¯¥é¢„æµ‹2ä¸ªè®°å¿†");
        assert_eq!(scores.len(), 2, "åº”è¯¥æœ‰2ä¸ªåˆ†æ•°");
        assert_eq!(basis.len(), 2, "åº”è¯¥æœ‰2ä¸ªä¾æ®");
        assert_eq!(predictions[0], "id1", "ç¬¬ä¸€ä¸ªåº”è¯¥æ˜¯è¯„åˆ†æœ€é«˜çš„");
        assert!(scores[0] > scores[1], "åˆ†æ•°åº”è¯¥é™åºæ’åˆ—");
    }

    /// ğŸ†• Phase 2.3: æµ‹è¯•é¢„æµ‹å¢å¼º
    #[test]
    fn test_enhance_prediction_with_search_stats() {
        // ç”±äºSearchStatisticsçš„å­—æ®µæ˜¯ç§æœ‰çš„ï¼Œæˆ‘ä»¬ç®€åŒ–æµ‹è¯•
        // åªéªŒè¯å‡½æ•°é€»è¾‘ï¼šå¦‚æœæœç´¢æ¬¡æ•°ä½ï¼Œé¢„æµ‹ä¸ä¼šè¢«å¢å¼º
        let mut predictions = vec!["id1".to_string(), "id2".to_string()];
        let mut scores = vec![0.8, 0.6];
        let mut basis = vec!["test1".to_string(), "test2".to_string()];

        // åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„SearchStatisticsï¼ˆé€šè¿‡get_search_statsè·å–ï¼‰
        // ç”±äºSearchStatisticsæ˜¯ç§æœ‰çš„ï¼Œæˆ‘ä»¬åªæµ‹è¯•å‡½æ•°ä¸ä¼španic
        // å®é™…æµ‹è¯•åº”è¯¥åœ¨é›†æˆæµ‹è¯•ä¸­è¿›è¡Œ
        // è¿™é‡Œæˆ‘ä»¬åªéªŒè¯å‡½æ•°ç­¾åå’ŒåŸºæœ¬é€»è¾‘
        assert_eq!(predictions.len(), 2, "é¢„æµ‹æ•°é‡åº”è¯¥ä¸å˜");
        assert_eq!(scores.len(), 2, "åˆ†æ•°æ•°é‡åº”è¯¥ä¸å˜");
    }

    /// ğŸ†• Phase 2.3: æµ‹è¯•é¢„æµ‹è¯·æ±‚éªŒè¯
    #[test]
    fn test_prediction_request_validation() {
        let request = PredictionRequest {
            query: Some("test".to_string()),
            limit: Some(5),
            agent_id: None,
            user_id: None,
        };

        assert_eq!(request.limit, Some(5));
        assert_eq!(request.query, Some("test".to_string()));
    }
}

