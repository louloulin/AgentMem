//! Memory management routes - Unified Memory API version
//!
//! æ¶æ„ä¼˜åŒ–ï¼šä½¿ç”¨agent-memçš„Memoryç»Ÿä¸€APIæ›¿ä»£agent-mem-coreçš„CoreMemoryManager
//! ä¼˜åŠ¿ï¼š
//! - æ›´ç®€æ´çš„ä»£ç 
//! - ç»Ÿä¸€çš„æ¥å£
//! - è‡ªåŠ¨çš„æ™ºèƒ½åŠŸèƒ½
//! - æ›´å¥½çš„ç±»å‹å¤„ç†
//!
//! æ³¨æ„ï¼šæœ¬æ¨¡å—å†…éƒ¨ä½¿ç”¨ MemoryItem ç”¨äºå‘åå…¼å®¹ï¼Œæœªæ¥ç‰ˆæœ¬å°†è¿ç§»åˆ° Memory V4

use crate::{
    error::{ServerError, ServerResult},
    models::{
        BatchRequest, BatchResponse, BatchSearchRequest, BatchSearchResponse, MemoryRequest,
        MemoryResponse, SearchRequest, SearchResponse, UpdateMemoryRequest,
    },
};
use agent_mem::{AddMemoryOptions, DeleteAllOptions, GetAllOptions, Memory, SearchOptions};

// å†…éƒ¨ä½¿ç”¨ MemoryItem ç”¨äºå‘åå…¼å®¹ï¼ˆå·²åºŸå¼ƒï¼Œæœªæ¥å°†è¿ç§»åˆ° Memory V4ï¼‰
#[allow(deprecated)]
use agent_mem_traits::MemoryItem;
use std::collections::HashMap;
use std::hash::{Hash, Hasher};
use std::num::NonZeroUsize;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::RwLock;
use tokio::time::timeout;
use futures::future;
use lru::LruCache;

/// æŸ¥è¯¢ç»“æœç¼“å­˜æ¡ç›®
#[derive(Debug, Clone)]
struct CachedSearchResult {
    /// ç¼“å­˜çš„ç»“æœ
    results: Vec<serde_json::Value>,
    /// åˆ›å»ºæ—¶é—´
    created_at: Instant,
    /// TTLï¼ˆç”Ÿå­˜æ—¶é—´ï¼‰
    ttl: Duration,
}

impl CachedSearchResult {
    fn new(results: Vec<serde_json::Value>, ttl: Duration) -> Self {
        Self {
            results,
            created_at: Instant::now(),
            ttl,
        }
    }

    fn is_expired(&self) -> bool {
        self.created_at.elapsed() > self.ttl
    }
}

/// æŸ¥è¯¢ç»“æœç¼“å­˜ï¼ˆå…¨å±€å•ä¾‹ï¼Œä½¿ç”¨LRUç­–ç•¥ï¼‰
static SEARCH_CACHE: std::sync::OnceLock<Arc<RwLock<LruCache<String, CachedSearchResult>>>> =
    std::sync::OnceLock::new();

/// æœç´¢ç»Ÿè®¡ä¿¡æ¯ï¼ˆå…¨å±€å•ä¾‹ï¼‰
#[derive(Debug, Clone)]
struct SearchStatistics {
    /// æ€»æœç´¢æ¬¡æ•°
    total_searches: u64,
    /// ç¼“å­˜å‘½ä¸­æ¬¡æ•°
    cache_hits: u64,
    /// ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°
    cache_misses: u64,
    /// ç²¾ç¡®æŸ¥è¯¢æ¬¡æ•°ï¼ˆLibSQLï¼‰
    exact_queries: u64,
    /// å‘é‡æœç´¢æ¬¡æ•°
    vector_searches: u64,
    /// æ€»æœç´¢å»¶è¿Ÿï¼ˆå¾®ç§’ï¼‰
    total_latency_us: u64,
    /// æœ€åæ›´æ–°æ—¶é—´
    last_updated: Instant,
}

impl SearchStatistics {
    fn new() -> Self {
        Self {
            total_searches: 0,
            cache_hits: 0,
            cache_misses: 0,
            exact_queries: 0,
            vector_searches: 0,
            total_latency_us: 0,
            last_updated: Instant::now(),
        }
    }

    fn default() -> Self {
        Self::new()
    }

    /// è·å–ç¼“å­˜å‘½ä¸­ç‡
    fn cache_hit_rate(&self) -> f64 {
        if self.total_searches == 0 {
            return 0.0;
        }
        (self.cache_hits as f64) / (self.total_searches as f64)
    }

    /// è·å–å¹³å‡æœç´¢å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
    fn avg_latency_ms(&self) -> f64 {
        if self.total_searches == 0 {
            return 0.0;
        }
        (self.total_latency_us as f64) / (self.total_searches as f64) / 1000.0
    }
}

/// æœç´¢ç»Ÿè®¡ï¼ˆå…¨å±€å•ä¾‹ï¼‰
static SEARCH_STATS: std::sync::OnceLock<Arc<RwLock<SearchStatistics>>> =
    std::sync::OnceLock::new();

/// è·å–æœç´¢ç»Ÿè®¡
fn get_search_stats() -> Arc<RwLock<SearchStatistics>> {
    SEARCH_STATS.get_or_init(|| {
        Arc::new(RwLock::new(SearchStatistics::new()))
    }).clone()
}

/// è·å–æŸ¥è¯¢ç»“æœç¼“å­˜
fn get_search_cache() -> Arc<RwLock<LruCache<String, CachedSearchResult>>> {
    // OnceLock::get_or_init è¿”å› &Tï¼Œå¯ä»¥ç›´æ¥ clone Arc
    SEARCH_CACHE.get_or_init(|| {
        // é»˜è®¤ç¼“å­˜å®¹é‡ï¼š1000ä¸ªæ¡ç›®
        let capacity = std::env::var("SEARCH_CACHE_CAPACITY")
            .ok()
            .and_then(|v| v.parse().ok())
            .unwrap_or(1000);
        let cache_capacity = NonZeroUsize::new(capacity)
            .unwrap_or(NonZeroUsize::new(1000).unwrap());
        Arc::new(RwLock::new(LruCache::new(cache_capacity)))
    }).clone()
}

/// ç”ŸæˆæŸ¥è¯¢ç¼“å­˜é”®
pub(crate) fn generate_cache_key(
    query: &str,
    agent_id: &Option<String>,
    user_id: &Option<String>,
    limit: &Option<usize>,
) -> String {
    use std::collections::hash_map::DefaultHasher;
    let mut hasher = DefaultHasher::new();
    query.hash(&mut hasher);
    agent_id.hash(&mut hasher);
    user_id.hash(&mut hasher);
    limit.hash(&mut hasher);
    format!("search_{}", hasher.finish())
}

/// Server-side memory manager wrapper (åŸºäºMemoryç»Ÿä¸€API)
pub struct MemoryManager {
    pub memory: Arc<Memory>,
    /// ğŸ†• Fix 2: æŸ¥è¯¢ä¼˜åŒ–å™¨
    query_optimizer: Arc<agent_mem_core::search::QueryOptimizer>,
    /// ğŸ†• Fix 2: ç»“æœé‡æ’åºå™¨ï¼ˆä½¿ç”¨rerankeræ¨¡å—çš„ResultRerankerï¼‰
    reranker: Arc<agent_mem_core::search::reranker::ResultReranker>,
}

impl MemoryManager {
    /// åˆ›å»ºæ–°çš„MemoryManagerï¼ˆä½¿ç”¨Memory API + LibSQLæŒä¹…åŒ– + Embedderé…ç½®ï¼‰
    pub async fn new(
        embedder_provider: Option<String>,
        embedder_model: Option<String>,
    ) -> ServerResult<Self> {
        use tracing::warn;

        info!("========================================");
        info!("ğŸ§  åˆå§‹åŒ– Memory ç»„ä»¶");
        info!("========================================");

        // ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨builderæ¨¡å¼æ˜¾å¼æŒ‡å®šLibSQLå­˜å‚¨ï¼Œè€Œä¸æ˜¯é»˜è®¤çš„å†…å­˜å­˜å‚¨
        let db_path =
            std::env::var("DATABASE_URL").unwrap_or_else(|_| "file:./data/agentmem.db".to_string());

        info!("ğŸ“¦ é…ç½®å­˜å‚¨å±‚");
        info!("  - æ•°æ®åº“ç±»å‹: LibSQL (SQLite)");
        info!("  - æ•°æ®åº“è·¯å¾„: {}", db_path);

        let mut builder = Memory::builder().with_storage(&db_path); // ğŸ”‘ å…³é”®ä¿®å¤ï¼šæ˜¾å¼æŒ‡å®šä½¿ç”¨LibSQL
                                                                    // âš ï¸ ä¸è®¾ç½® default_user_id å’Œ default_agent_id
                                                                    // å¼ºåˆ¶æ¯æ¬¡è°ƒç”¨æ—¶æ˜¾å¼ä¼ å…¥ï¼Œé¿å…è¢«é»˜è®¤å€¼è¦†ç›–

        // ğŸ”‘ å…³é”®ä¿®å¤ #2ï¼šé…ç½®Embedderï¼ˆP0é—®é¢˜ï¼‰
        info!("ğŸ”Œ é…ç½® Embedder (å‘é‡åµŒå…¥)");
        if let (Some(provider), Some(model)) = (embedder_provider.clone(), embedder_model.clone()) {
            info!("  - Provider: {}", provider);
            info!("  - Model: {}", model);
            builder = builder.with_embedder(provider, model);
        } else {
            // ä½¿ç”¨é»˜è®¤FastEmbedé…ç½®
            info!("  - Provider: fastembed (é»˜è®¤)");
            info!("  - Model: BAAI/bge-small-en-v1.5");
            builder = builder.with_embedder("fastembed", "BAAI/bge-small-en-v1.5");
        }

        // ğŸ”‘ å…³é”®ä¿®å¤ #3ï¼šé…ç½®VectorStoreï¼ˆå‘é‡æŒä¹…åŒ–ï¼‰
        // ä¿®å¤: ä¹‹å‰å‘é‡åªåœ¨å†…å­˜ä¸­ï¼Œé‡å¯åä¸¢å¤±
        // æ³¨æ„: LanceDBéœ€è¦åè®®å‰ç¼€ "lancedb://"ï¼Œè·¯å¾„éœ€è¦ä»¥.lanceç»“å°¾
        let vector_store_url = "lancedb://./data/vectors.lance";
        info!("ğŸ“Š é…ç½®å‘é‡å­˜å‚¨");
        info!("  - ç±»å‹: LanceDB");
        info!("  - è·¯å¾„: {}", vector_store_url);
        builder = builder.with_vector_store(vector_store_url);

        info!("â³ æ„å»º Memory å®ä¾‹...");
        warn!("âš ï¸  é¦–æ¬¡è¿è¡Œæ—¶ï¼ŒFastEmbed ä¼šä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼ˆçº¦ 100MBï¼‰");
        warn!("âš ï¸  è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...");
        warn!("âš ï¸  ä¸‹è½½è¿›åº¦ä¸ä¼šæ˜¾ç¤ºï¼Œä½†ç¨‹åºæ­£åœ¨è¿è¡Œä¸­");

        let memory = builder.build().await.map_err(|e| {
            ServerError::Internal(format!("Failed to create Memory with LibSQL: {}", e))
        })?;

        info!("âœ… Memory å®ä¾‹æ„å»ºæˆåŠŸ");

        // ğŸ†• Fix 2: åˆå§‹åŒ–QueryOptimizerå’ŒReranker
        info!("ğŸ” åˆå§‹åŒ–æœç´¢ä¼˜åŒ–ç»„ä»¶...");
        let query_optimizer = {
            use std::sync::RwLock;
            let stats = Arc::new(RwLock::new(
                agent_mem_core::search::IndexStatistics::default(),
            ));
            agent_mem_core::search::QueryOptimizer::with_default_config(stats)
        };

        let reranker = agent_mem_core::search::reranker::ResultReranker::with_default_config();

        info!("âœ… QueryOptimizer å’Œ Reranker åˆå§‹åŒ–å®Œæˆ");
        info!("========================================");
        info!("âœ… Memory ç»„ä»¶åˆå§‹åŒ–å®Œæˆï¼");
        info!("========================================");

        Ok(Self {
            memory: Arc::new(memory),
            query_optimizer: Arc::new(query_optimizer),
            reranker: Arc::new(reranker),
        })
    }

    /// ä½¿ç”¨è‡ªå®šä¹‰é…ç½®åˆ›å»º
    pub async fn with_config(memory: Memory) -> Self {
        // ğŸ†• Fix 2: åˆå§‹åŒ–QueryOptimizerå’ŒReranker
        let query_optimizer = {
            use std::sync::RwLock;
            let stats = Arc::new(RwLock::new(
                agent_mem_core::search::IndexStatistics::default(),
            ));
            agent_mem_core::search::QueryOptimizer::with_default_config(stats)
        };

        let reranker = agent_mem_core::search::reranker::ResultReranker::with_default_config();

        Self {
            memory: Arc::new(memory),
            query_optimizer: Arc::new(query_optimizer),
            reranker: Arc::new(reranker),
        }
    }

    /// æ·»åŠ è®°å¿†ï¼ˆğŸ”§ æœ€ä½³æ–¹æ¡ˆï¼šMemory API + LibSQL åŒå†™ï¼‰
    ///
    /// Strategy:
    /// 1. ä½¿ç”¨Memory APIç”Ÿæˆå‘é‡åµŒå…¥ï¼ˆä¿ç•™æ™ºèƒ½åŠŸèƒ½ï¼‰
    /// 2. åŒæ—¶å†™å…¥LibSQLç¡®ä¿æŒä¹…åŒ–
    /// 3. å‘é‡æœç´¢ä½¿ç”¨VectorStoreï¼Œç»“æ„åŒ–æŸ¥è¯¢ä½¿ç”¨LibSQL
    pub async fn add_memory(
        &self,
        repositories: Arc<agent_mem_core::storage::factory::Repositories>,
        agent_id: Option<String>,
        user_id: Option<String>,
        content: String,
        memory_type: Option<agent_mem_traits::MemoryType>,
        importance: Option<f32>,
        metadata: Option<HashMap<String, String>>,
    ) -> Result<String, String> {
        use agent_mem_utils::hash::compute_content_hash;
        use chrono::Utc;

        // âœ… ç”Ÿæˆæœ‰æ•ˆçš„ agent_id (å‚è€ƒmem0è®¾è®¡)
        let effective_agent_id = agent_id.unwrap_or_else(|| {
            if let Some(uid) = &user_id {
                format!("default-agent-{}", uid)
            } else {
                "default-agent".to_string()
            }
        });

        // Step 1: ä½¿ç”¨Memory APIï¼ˆç”Ÿæˆå‘é‡åµŒå…¥ï¼‰
        let options = AddMemoryOptions {
            agent_id: Some(effective_agent_id.clone()),
            user_id: user_id.clone(),
            infer: false, // ç®€å•æ¨¡å¼ï¼Œé¿å…å¤æ‚æ¨ç†
            metadata: metadata.clone().unwrap_or_default(),
            memory_type: memory_type.as_ref().map(|t| format!("{:?}", t)),
            ..Default::default()
        };

        let add_result = self
            .memory
            .add_with_options(&content, options)
            .await
            .map_err(|e| e.to_string())?;

        let memory_id = add_result
            .results
            .first()
            .map(|r| r.id.clone())
            .unwrap_or_else(|| uuid::Uuid::new_v4().to_string());

        // Step 2: å†™å…¥LibSQL Repositoryï¼ˆæŒä¹…åŒ–ï¼‰
        let user_id_val = user_id.unwrap_or_else(|| "default".to_string());
        let content_hash = compute_content_hash(&content);
        let now = Utc::now();

        // æ„å»ºmetadata JSON
        let mut full_metadata = metadata.unwrap_or_default();
        full_metadata.insert("agent_id".to_string(), effective_agent_id.clone());
        full_metadata.insert("user_id".to_string(), user_id_val.clone());
        full_metadata.insert("data".to_string(), content.clone());
        full_metadata.insert("hash".to_string(), content_hash.clone());

        // ğŸ†• Phase 2 Server: æå–scope_typeï¼ˆå¦‚æœæ²¡æœ‰åˆ™è‡ªåŠ¨æ¨æ–­ï¼‰
        // âœ… ä¿®å¤ä¼˜å…ˆçº§ï¼šuser_idä¼˜å…ˆäºsession_idï¼ˆç¬¦åˆagentmem61.mdè®¾è®¡ï¼‰
        let scope_type = full_metadata.get("scope_type").cloned().unwrap_or_else(|| {
            // è‡ªåŠ¨æ¨æ–­scopeç±»å‹ - æ­£ç¡®çš„ä¼˜å…ˆçº§
            // 1. å¦‚æœæœ‰user_idå’Œagent_idï¼ˆéé»˜è®¤ï¼‰ï¼Œè¿™æ˜¯é•¿æœŸè®°å¿†ï¼ˆAgent scopeï¼‰
            if user_id_val != "default"
                && effective_agent_id.starts_with("agent-")
                && effective_agent_id != "default-agent"
            {
                "agent".to_string()
            }
            // 2. å¦‚æœåªæœ‰user_idï¼ˆéé»˜è®¤ï¼‰ï¼Œè¿™æ˜¯ç”¨æˆ·è®°å¿†ï¼ˆUser scopeï¼‰
            else if user_id_val != "default" {
                "user".to_string()
            }
            // 3. å¦‚æœæœ‰session_idï¼Œè¿™æ˜¯å·¥ä½œè®°å¿†ï¼ˆSession scopeï¼‰
            else if full_metadata.contains_key("session_id") {
                "session".to_string()
            }
            // 4. å¦‚æœæœ‰run_id
            else if full_metadata.contains_key("run_id") {
                "run".to_string()
            }
            // 5. å¦‚æœæœ‰org_id
            else if full_metadata.contains_key("org_id") {
                "organization".to_string()
            }
            // 6. é»˜è®¤ä¸ºå…¨å±€
            else {
                "global".to_string()
            }
        });

        let metadata_json: serde_json::Value = full_metadata
            .into_iter()
            .map(|(k, v)| (k, serde_json::Value::String(v)))
            .collect();

        // Step 2.5: ç¡®ä¿Agentå­˜åœ¨ï¼ˆè·å–å…¶organization_idå’Œuser_idï¼‰
        // âœ… å¦‚æœagentä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼ˆå‚è€ƒmem0è®¾è®¡ï¼‰
        let agent_opt = repositories
            .agents
            .find_by_id(&effective_agent_id)
            .await
            .map_err(|e| format!("Failed to query agent: {}", e))?;

        let organization_id = agent_opt
            .as_ref()
            .map(|a| a.organization_id.clone())
            .unwrap_or_else(|| "default-org".to_string());

        let db_memory = agent_mem_core::storage::models::DbMemory {
            id: memory_id.clone(),
            organization_id,                // ä½¿ç”¨Agentçš„organization_idæˆ–é»˜è®¤å€¼
            user_id: "default".to_string(), // ä½¿ç”¨é»˜è®¤user (TODO: åº”è¯¥ä»authè·å–å®é™…user)
            agent_id: effective_agent_id.clone(),
            content,
            hash: Some(content_hash),
            metadata: metadata_json,
            score: None,
            memory_type: format!(
                "{:?}",
                memory_type.unwrap_or(agent_mem_traits::MemoryType::Semantic)
            ),
            scope: scope_type, // ğŸ†• Phase 2 Server: ä½¿ç”¨æ¨æ–­æˆ–æå–çš„scope_type
            level: "normal".to_string(),
            importance: importance.unwrap_or(0.5),
            access_count: 0,
            last_accessed: Some(now),
            created_at: now,
            updated_at: now,
            is_deleted: false,
            created_by_id: None,
            last_updated_by_id: None,
        };

        // è½¬æ¢ä¸º MemoryV4 ä»¥ä¾¿è°ƒç”¨ repository.create
        use agent_mem_core::storage::conversion::db_to_memory;
        let memory = db_to_memory(&db_memory)
            .map_err(|e| format!("Failed to convert to MemoryV4: {}", e))?;

        repositories
            .memories
            .create(&memory)
            .await
            .map_err(|e| format!("Failed to persist to LibSQL: {}", e))?;

        info!(
            "âœ… Memory persisted: VectorStore + LibSQL (ID: {})",
            memory_id
        );
        Ok(memory_id)
    }

    /// è·å–è®°å¿†ï¼ˆç›´æ¥æ•°æ®åº“æŸ¥è¯¢ï¼‰
    pub async fn get_memory(&self, id: &str) -> Result<Option<serde_json::Value>, String> {
        use libsql::{params, Builder};

        let db_path =
            std::env::var("DATABASE_URL").unwrap_or_else(|_| "data/agentmem.db".to_string());

        let db = Builder::new_local(&db_path)
            .build()
            .await
            .map_err(|e| format!("Failed to open database: {}", e))?;

        let conn = db
            .connect()
            .map_err(|e| format!("Failed to connect: {}", e))?;

        // ğŸ†• Phase 2 Server: æŸ¥è¯¢ä¸­åŒ…å«scopeå­—æ®µ
        let query = "SELECT id, agent_id, user_id, content, memory_type, importance, \
                     created_at, last_accessed, access_count, metadata, hash, scope \
                     FROM memories WHERE id = ? AND is_deleted = 0 LIMIT 1";

        let mut stmt = conn
            .prepare(query)
            .await
            .map_err(|e| format!("Failed to prepare query: {}", e))?;

        let mut rows = stmt
            .query(params![id])
            .await
            .map_err(|e| format!("Failed to query: {}", e))?;

        if let Some(row) = rows
            .next()
            .await
            .map_err(|e| format!("Failed to fetch row: {}", e))?
        {
            // âœ… ä¿®å¤æ—¶é—´æˆ³ï¼šå°† i64 ç§’çº§æ—¶é—´æˆ³è½¬æ¢ä¸º ISO 8601 å­—ç¬¦ä¸²
            use chrono::{DateTime, Utc};

            let created_at_ts: Option<i64> = row.get(6).ok();
            let created_at_str = created_at_ts
                .and_then(|ts| DateTime::from_timestamp(ts, 0))
                .map(|dt| dt.to_rfc3339());

            let last_accessed_ts: Option<i64> = row.get(7).ok();
            let last_accessed_str = last_accessed_ts
                .and_then(|ts| DateTime::from_timestamp(ts, 0))
                .map(|dt| dt.to_rfc3339());

            let json = serde_json::json!({
                "id": row.get::<String>(0).unwrap_or_default(),
                "agent_id": row.get::<String>(1).unwrap_or_default(),
                "user_id": row.get::<String>(2).unwrap_or_default(),
                "content": row.get::<String>(3).unwrap_or_default(),
                "memory_type": row.get::<Option<String>>(4).ok().flatten(),
                "importance": row.get::<Option<f64>>(5).ok().flatten(),
                "created_at": created_at_str,
                "last_accessed_at": last_accessed_str,
                "access_count": row.get::<Option<i64>>(8).ok().flatten(),
                "metadata": row.get::<Option<String>>(9).ok().flatten(),
                "hash": row.get::<Option<String>>(10).ok().flatten(),
                "scope": row.get::<Option<String>>(11).ok().flatten(),  // ğŸ†• Phase 2 Server: è¿”å›scopeå­—æ®µ
            });
            Ok(Some(json))
        } else {
            Ok(None)
        }
    }

    /// æ›´æ–°è®°å¿†
    pub async fn update_memory(
        &self,
        id: &str,
        content: Option<String>,
        importance: Option<f32>,
        metadata: Option<HashMap<String, String>>,
    ) -> Result<(), String> {
        let mut update_data = HashMap::new();

        if let Some(c) = content {
            update_data.insert("content".to_string(), serde_json::json!(c));
        }
        if let Some(imp) = importance {
            update_data.insert("importance".to_string(), serde_json::json!(imp));
        }
        if let Some(meta) = metadata {
            // è½¬æ¢metadataä¸ºJSON
            let meta_json: HashMap<String, serde_json::Value> = meta
                .into_iter()
                .map(|(k, v)| (k, serde_json::Value::String(v)))
                .collect();
            update_data.insert("metadata".to_string(), serde_json::json!(meta_json));
        }

        self.memory
            .update(id, update_data)
            .await
            .map(|_| ())
            .map_err(|e| e.to_string())
    }

    /// åˆ é™¤è®°å¿†
    pub async fn delete_memory(&self, id: &str) -> Result<(), String> {
        self.memory.delete(id).await.map_err(|e| e.to_string())
    }

    /// æœç´¢è®°å¿† (ğŸ†• Fix 2: é›†æˆQueryOptimizerå’ŒReranker)
    pub async fn search_memories(
        &self,
        query: String,
        agent_id: Option<String>,
        user_id: Option<String>,
        limit: Option<usize>,
        _memory_type: Option<agent_mem_traits::MemoryType>,
    ) -> Result<Vec<MemoryItem>, String> {
        // ğŸ†• Fix 2: ä½¿ç”¨QueryOptimizerä¼˜åŒ–æŸ¥è¯¢
        use agent_mem_core::search::SearchQuery;
        let search_query = SearchQuery {
            query: query.clone(),
            limit: limit.unwrap_or(10),
            threshold: Some(0.7),
            vector_weight: 0.7,
            fulltext_weight: 0.3,
            filters: None,
            metadata_filters: None,
        };

        let optimized_plan = self
            .query_optimizer
            .optimize_query(&search_query)
            .map_err(|e| format!("Query optimization failed: {}", e))?;

        info!("ğŸš€ Query optimized: strategy={:?}, should_rerank={}, rerank_factor={}, estimated_latency={}ms", 
            optimized_plan.strategy, optimized_plan.should_rerank, optimized_plan.rerank_factor, 
            optimized_plan.estimated_latency_ms);

        // ğŸ†• Fix 2: ä½¿ç”¨ä¼˜åŒ–åçš„å‚æ•° - å¦‚æœéœ€è¦é‡æ’åºï¼Œå¢åŠ å€™é€‰æ•°é‡
        let base_limit = limit.unwrap_or(10);
        let fetch_limit = if optimized_plan.should_rerank {
            base_limit * optimized_plan.rerank_factor
        } else {
            base_limit
        };

        // ğŸ”§ æ™ºèƒ½é˜ˆå€¼è°ƒæ•´ï¼šæ ¹æ®æŸ¥è¯¢ç±»å‹åŠ¨æ€è®¾ç½®
        let dynamic_threshold = get_adaptive_threshold(&query);
        info!(
            "ğŸ“Š è‡ªé€‚åº”é˜ˆå€¼: query='{}', threshold={}",
            query, dynamic_threshold
        );

        let options = SearchOptions {
            user_id: user_id.clone(),
            limit: Some(fetch_limit),
            threshold: Some(dynamic_threshold),
            ..Default::default()
        };

        // æ‰§è¡Œæœç´¢
        let raw_results = self
            .memory
            .search_with_options(query.clone(), options)
            .await
            .map_err(|e| e.to_string())?;

        // ğŸ†• Phase 3-D: å¦‚æœéœ€è¦é‡æ’åºä¸”æœ‰ç»“æœï¼Œä½¿ç”¨Rerankerä¼˜åŒ–
        if optimized_plan.should_rerank && !raw_results.is_empty() && raw_results.len() > base_limit
        {
            // ä¿å­˜ç»“æœæ•°é‡ç”¨äºæ—¥å¿—
            let raw_count = raw_results.len();

            match self
                .apply_reranking(&query, &search_query, raw_results, base_limit)
                .await
            {
                Ok(reranked) => {
                    info!(
                        "âœ¨ Reranking applied successfully: {} â†’ {} final results",
                        raw_count,
                        reranked.len()
                    );
                    return Ok(reranked);
                }
                Err(e) => {
                    // Rerankingå¤±è´¥æ—¶é™çº§ï¼šé‡æ–°æ‰§è¡Œæœç´¢ï¼Œä½¿ç”¨base_limit
                    warn!(
                        "âš ï¸  Reranking failed ({}), falling back to direct search with base_limit",
                        e
                    );
                    let fallback_options = SearchOptions {
                        user_id,
                        limit: Some(base_limit),
                        threshold: Some(dynamic_threshold), // ä½¿ç”¨åŠ¨æ€é˜ˆå€¼
                        ..Default::default()
                    };
                    return self
                        .memory
                        .search_with_options(query, fallback_options)
                        .await
                        .map_err(|e| e.to_string());
                }
            }
        }

        // ä¸éœ€è¦é‡æ’åºæˆ–ç»“æœä¸è¶³ï¼Œç›´æ¥è¿”å›ï¼ˆå¯èƒ½éœ€è¦æˆªæ–­ï¼‰
        Ok(raw_results.into_iter().take(base_limit).collect())
    }

    /// ğŸ†• åº”ç”¨Rerankeré‡æ’åº
    ///
    /// å°†MemoryItemè½¬æ¢ä¸ºSearchResultï¼Œè°ƒç”¨Rerankerï¼Œå†è½¬æ¢å›æ¥
    async fn apply_reranking(
        &self,
        query: &str,
        search_query: &agent_mem_core::search::SearchQuery,
        raw_results: Vec<MemoryItem>,
        final_limit: usize,
    ) -> Result<Vec<MemoryItem>, String> {
        use agent_mem_core::search::SearchResult;

        // 1. å°è¯•ç”Ÿæˆquery vectorï¼ˆç”¨äºRerankerï¼‰
        // æ³¨æ„ï¼šå¦‚æœæ— æ³•ç”Ÿæˆquery_vectorï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç°æœ‰çš„scoreè¿›è¡Œé‡æ’åº
        let query_vector_result = {
            // å°è¯•é€šè¿‡æœç´¢APIè·å–query vector
            // ç”±äºMemory APIæ²¡æœ‰ç›´æ¥æš´éœ²embedderï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€åŒ–çš„æ–¹æ³•ï¼š
            // ä½¿ç”¨ç¬¬ä¸€ä¸ªç»“æœçš„å‘é‡ä½œä¸ºå‚è€ƒï¼ˆå¦‚æœå¯ç”¨ï¼‰ï¼Œæˆ–è€…ä½¿ç”¨é»˜è®¤å‘é‡
            // å®é™…ä¸Šï¼ŒRerankerå¯ä»¥ä½¿ç”¨ç°æœ‰çš„scoreï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªå ä½å‘é‡
            let default_dim = 384; // FastEmbedé»˜è®¤ç»´åº¦ï¼Œå¯ä»¥æ ¹æ®å®é™…é…ç½®è°ƒæ•´
            vec![0.0f32; default_dim] // å ä½å‘é‡ï¼ŒRerankerä¼šä¸»è¦ä½¿ç”¨ç°æœ‰score
        };

        // 2. è½¬æ¢MemoryItem â†’ SearchResult
        let candidates: Vec<SearchResult> = raw_results
            .iter()
            .map(|item| SearchResult {
                id: item.id.clone(),
                content: item.content.clone(),
                score: item.score.unwrap_or(0.5),
                vector_score: item.score,
                fulltext_score: None,
                metadata: Some(
                    serde_json::to_value(&item.metadata).unwrap_or(serde_json::json!({})),
                ),
            })
            .collect();

        // 3. è°ƒç”¨Rerankerè¿›è¡Œé‡æ’åº
        // Rerankerä¼šåŸºäºå¤šä¸ªå› ç´ ï¼ˆç›¸ä¼¼åº¦ã€å…ƒæ•°æ®ã€æ—¶é—´ã€é‡è¦æ€§ã€è´¨é‡ï¼‰é‡æ–°è¯„åˆ†
        // æ³¨æ„ï¼šArcä¼šè‡ªåŠ¨è§£å¼•ç”¨ï¼Œæ‰€ä»¥å¯ä»¥ç›´æ¥è°ƒç”¨
        let reranked_results = self
            .reranker
            .rerank(candidates, &query_vector_result, search_query)
            .await
            .map_err(|e| format!("Reranker execution failed: {}", e))?;

        // 4. è½¬æ¢å›MemoryItemï¼ˆä¿æŒåŸå§‹MemoryItemæ•°æ®ï¼Œåªæ›´æ–°é¡ºåºå’Œscoreï¼‰
        let mut result_map: std::collections::HashMap<String, MemoryItem> = raw_results
            .into_iter()
            .map(|item| (item.id.clone(), item))
            .collect();

        let final_results: Vec<MemoryItem> = reranked_results
            .into_iter()
            .take(final_limit)
            .filter_map(|reranked| {
                result_map.get_mut(&reranked.id).map(|item| {
                    // æ›´æ–°scoreä¸ºé‡æ’åºåçš„åˆ†æ•°
                    item.score = Some(reranked.score);
                    item.clone()
                })
            })
            .collect();

        Ok(final_results)
    }

    /// è·å–æ‰€æœ‰è®°å¿†
    pub async fn get_all_memories(
        &self,
        agent_id: Option<String>,
        user_id: Option<String>,
        limit: Option<usize>,
    ) -> Result<Vec<MemoryItem>, String> {
        let options = GetAllOptions {
            agent_id,
            user_id,
            limit,
            ..Default::default()
        };

        self.memory
            .get_all(options)
            .await
            .map_err(|e| e.to_string())
    }

    /// åˆ é™¤æ‰€æœ‰è®°å¿†
    pub async fn delete_all_memories(
        &self,
        agent_id: Option<String>,
        user_id: Option<String>,
    ) -> Result<usize, String> {
        let options = DeleteAllOptions {
            agent_id,
            user_id,
            ..Default::default()
        };

        self.memory
            .delete_all(options)
            .await
            .map_err(|e| e.to_string())
    }

    /// é‡ç½®æ‰€æœ‰è®°å¿†ï¼ˆå±é™©æ“ä½œï¼‰
    pub async fn reset(&self) -> Result<(), String> {
        self.memory.reset().await.map_err(|e| e.to_string())
    }

    /// è·å–ç»Ÿè®¡ä¿¡æ¯
    pub async fn get_stats(&self) -> Result<agent_mem::MemoryStats, String> {
        self.memory.get_stats().await.map_err(|e| e.to_string())
    }
}

/// é»˜è®¤å®ç°ï¼ˆå¼‚æ­¥åˆ›å»ºï¼‰
impl MemoryManager {
    pub fn new_sync() -> Self {
        // æ³¨æ„ï¼šè¿™åªç”¨äºç±»å‹ç³»ç»Ÿï¼Œå®é™…ä½¿ç”¨åº”è¯¥è°ƒç”¨async new()
        panic!("Use MemoryManager::new().await instead");
    }
}

// ==================== è¾…åŠ©å‡½æ•° ====================

/// å®‰å…¨åœ°æˆªå–å­—ç¬¦ä¸²åˆ°æŒ‡å®šå­—ç¬¦æ•°ï¼ˆä½¿ç”¨å­—ç¬¦è¾¹ç•Œï¼Œé¿å…UTF-8 panicï¼‰
///
/// è¿™ä¸ªå‡½æ•°ç¡®ä¿åœ¨å­—ç¬¦è¾¹ç•Œå¤„æˆªå–ï¼Œè€Œä¸æ˜¯å­—èŠ‚è¾¹ç•Œï¼Œé¿å…åœ¨å¤šå­—èŠ‚UTF-8å­—ç¬¦ä¸­é—´åˆ‡ç‰‡
///
/// # æ€§èƒ½è¯´æ˜
/// ä½¿ç”¨ `chars().take()` ç›´æ¥æˆªå–ï¼Œåªéå†éœ€è¦çš„å­—ç¬¦ï¼Œå¯¹é•¿å­—ç¬¦ä¸²é«˜æ•ˆ
fn truncate_string_at_char_boundary(s: &str, max_chars: usize) -> String {
    // ä½¿ç”¨ chars() è¿­ä»£å™¨æŒ‰å­—ç¬¦æˆªå–ï¼Œç„¶åé‡æ–°ç»„åˆ
    // å¦‚æœå­—ç¬¦ä¸²é•¿åº¦ <= max_charsï¼Œtake ä¼šå–å®Œæ‰€æœ‰å­—ç¬¦ï¼Œç»“æœä¸åŸå­—ç¬¦ä¸²ç›¸åŒ
    s.chars().take(max_chars).collect()
}

// ==================== è·¯ç”±å¤„ç†å™¨å‡½æ•° ====================
// ä»¥ä¸‹æ˜¯å®é™…çš„HTTPè·¯ç”±å¤„ç†å™¨å‡½æ•°

use axum::{
    extract::{Extension, Path, Query},
    http::StatusCode,
    response::Json,
};
use tracing::{debug, error, info, warn};

/// æ·»åŠ æ–°è®°å¿†ï¼ˆğŸ”§ ä½¿ç”¨åŒå†™ç­–ç•¥ï¼‰
#[utoipa::path(
    post,
    path = "/api/v1/memories",
    tag = "memory",
    request_body = crate::models::MemoryRequest,
    responses(
        (status = 201, description = "Memory created successfully", body = crate::models::MemoryResponse),
        (status = 400, description = "Invalid request"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn add_memory(
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Json(request): Json<crate::models::MemoryRequest>,
) -> ServerResult<(
    StatusCode,
    Json<crate::models::ApiResponse<crate::models::MemoryResponse>>,
)> {
    info!(
        "Adding new memory for agent_id: {:?}, user_id: {:?}",
        request.agent_id, request.user_id
    );

    let memory_id = memory_manager
        .add_memory(
            repositories, // ä¼ é€’repositoriesç”¨äºLibSQLæŒä¹…åŒ–
            request.agent_id,
            request.user_id,
            request.content,
            request.memory_type,
            request.importance,
            request.metadata,
        )
        .await
        .map_err(|e| {
            error!("Failed to add memory: {}", e);
            ServerError::MemoryError(e.to_string())
        })?;

    let response = crate::models::MemoryResponse {
        id: memory_id,
        message: "Memory added successfully (VectorStore + LibSQL)".to_string(),
    };

    Ok((
        StatusCode::CREATED,
        Json(crate::models::ApiResponse::success(response)),
    ))
}

/// è·å–è®°å¿†
#[utoipa::path(
    get,
    path = "/api/v1/memories/{id}",
    tag = "memory",
    params(
        ("id" = String, Path, description = "Memory ID")
    ),
    responses(
        (status = 200, description = "Memory retrieved successfully"),
        (status = 404, description = "Memory not found"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn get_memory(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Path(id): Path<String>,
) -> ServerResult<Json<crate::models::ApiResponse<serde_json::Value>>> {
    info!("Getting memory with ID: {}", id);

    let memory = memory_manager.get_memory(&id).await.map_err(|e| {
        error!("Failed to get memory: {}", e);
        ServerError::MemoryError(e.to_string())
    })?;

    match memory {
        Some(mem) => Ok(Json(crate::models::ApiResponse::success(mem))),
        None => Err(ServerError::NotFound("Memory not found".to_string())),
    }
}

/// æ›´æ–°è®°å¿†
#[utoipa::path(
    put,
    path = "/api/v1/memories/{id}",
    tag = "memory",
    params(
        ("id" = String, Path, description = "Memory ID")
    ),
    request_body = crate::models::UpdateMemoryRequest,
    responses(
        (status = 200, description = "Memory updated successfully"),
        (status = 404, description = "Memory not found"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn update_memory(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    Path(id): Path<String>,
    Json(request): Json<crate::models::UpdateMemoryRequest>,
) -> ServerResult<Json<crate::models::ApiResponse<crate::models::MemoryResponse>>> {
    info!("Updating memory with ID: {}", id);

    // ğŸ”§ ä¿®å¤: ç›´æ¥æ›´æ–°LibSQL Repository
    // å…ˆè·å–ç°æœ‰è®°å¿†
    let existing = repositories
        .memories
        .find_by_id(&id)
        .await
        .map_err(|e| {
            error!("Failed to find memory for update: {}", e);
            ServerError::MemoryError(format!("Memory not found: {}", e))
        })?
        .ok_or_else(|| ServerError::MemoryError("Memory not found".to_string()))?;

    // æ„å»ºæ›´æ–°åçš„Memoryï¼Œä¿ç•™å…¶ä»–å­—æ®µ
    let updated_content = if let Some(content) = request.content {
        agent_mem_traits::Content::text(content)
    } else {
        existing.content.clone()
    };

    let updated_importance = request
        .importance
        .unwrap_or_else(|| {
            existing.importance()
                .map(|v| v as f32)
                .unwrap_or(0.5)
        });

    // ä½¿ç”¨builderæ¨¡å¼æ„å»ºæ›´æ–°åçš„Memory
    let mut updated = existing.clone();
    updated.content = updated_content;

    // æ›´æ–°importance - ä½¿ç”¨systemå‘½åç©ºé—´ï¼ˆå’Œimportance()æ–¹æ³•ä¸€è‡´ï¼‰
    updated.attributes.set(
        agent_mem_traits::AttributeKey::system("importance"),
        agent_mem_traits::AttributeValue::Number(updated_importance as f64),
    );
    updated.metadata.updated_at = chrono::Utc::now();

    // æ‰§è¡Œæ›´æ–°
    repositories.memories.update(&updated).await.map_err(|e| {
        error!("Failed to update memory in repository: {}", e);
        ServerError::MemoryError(e.to_string())
    })?;

    info!("âœ… Memory updated in LibSQL");

    let response = crate::models::MemoryResponse {
        id,
        message: "Memory updated successfully".to_string(),
    };

    Ok(Json(crate::models::ApiResponse::success(response)))
}

/// åˆ é™¤è®°å¿†
#[utoipa::path(
    delete,
    path = "/api/v1/memories/{id}",
    tag = "memory",
    params(
        ("id" = String, Path, description = "Memory ID")
    ),
    responses(
        (status = 200, description = "Memory deleted successfully"),
        (status = 404, description = "Memory not found"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn delete_memory(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    Path(id): Path<String>,
) -> ServerResult<Json<crate::models::ApiResponse<crate::models::MemoryResponse>>> {
    info!("Deleting memory with ID: {}", id);

    // âœ… ä¿®å¤: ç¡®ä¿åŒå±‚å­˜å‚¨éƒ½åˆ é™¤æˆåŠŸï¼Œä¿è¯æ•°æ®ä¸€è‡´æ€§
    // Step 1: å…ˆå°è¯•åˆ é™¤å‘é‡å­˜å‚¨ï¼ˆå¦‚æœå¤±è´¥ï¼Œå¯ä»¥æå‰è¿”å›ï¼Œä¸åˆ é™¤LibSQLï¼‰
    let vector_delete_result = memory_manager.delete_memory(&id).await;
    
    // Step 2: åˆ é™¤LibSQL Repository (ä¸»è¦å­˜å‚¨)
    let libsql_delete_result = repositories.memories.delete(&id).await;
    
    // Step 3: æ£€æŸ¥åˆ é™¤ç»“æœï¼Œç¡®ä¿ä¸¤ä¸ªå­˜å‚¨éƒ½åˆ é™¤æˆåŠŸ
    match (vector_delete_result, libsql_delete_result) {
        (Ok(_), Ok(_)) => {
            info!("âœ… Memory deleted from both LibSQL and Vector Store: {}", id);
            let response = crate::models::MemoryResponse {
                id,
                message: "Memory deleted successfully".to_string(),
            };
            Ok(Json(crate::models::ApiResponse::success(response)))
        }
        (Ok(_), Err(e)) => {
            // LibSQLåˆ é™¤å¤±è´¥ï¼Œä½†å‘é‡å­˜å‚¨å·²åˆ é™¤
            error!("Failed to delete from LibSQL after vector store deleted: {}", e);
            Err(ServerError::MemoryError(format!(
                "Memory deleted from vector store but failed to delete from LibSQL: {}", e
            )))
        }
        (Err(e), Ok(_)) => {
            // å‘é‡å­˜å‚¨åˆ é™¤å¤±è´¥ï¼Œä½†LibSQLå·²åˆ é™¤ - è¿™æ˜¯æ•°æ®ä¸ä¸€è‡´çš„æƒ…å†µ
            error!("Failed to delete from vector store after LibSQL deleted: {}", e);
            error!("âš ï¸  Data inconsistency: Memory deleted from LibSQL but still exists in vector store");
            Err(ServerError::MemoryError(format!(
                "Memory deleted from LibSQL but failed to delete from vector store: {}. \
                The memory may still appear in search results.", e
            )))
        }
        (Err(e1), Err(e2)) => {
            // ä¸¤ä¸ªå­˜å‚¨éƒ½åˆ é™¤å¤±è´¥
            error!("Failed to delete from both stores: vector={}, libsql={}", e1, e2);
            Err(ServerError::MemoryError(format!("Failed to delete memory: {}", e2)))
        }
    }
}

/// æœç´¢è®°å¿†
// ========== æ··åˆæ£€ç´¢è¾…åŠ©å‡½æ•° ==========

/// æ£€æµ‹æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
fn contains_chinese(text: &str) -> bool {
    text.chars().any(|c| {
        let code = c as u32;
        // ä¸­æ–‡å­—ç¬¦èŒƒå›´ï¼šCJKç»Ÿä¸€æ±‰å­— (0x4E00-0x9FFF)
        // ä»¥åŠæ‰©å±•A (0x3400-0x4DBF) å’Œæ‰©å±•B (0x20000-0x2A6DF)
        (code >= 0x4E00 && code <= 0x9FFF)
            || (code >= 0x3400 && code <= 0x4DBF)
            || (code >= 0x20000 && code <= 0x2A6DF)
    })
}

/// è®¡ç®—Recencyè¯„åˆ†ï¼ˆåŸºäºæœ€åè®¿é—®æ—¶é—´çš„æŒ‡æ•°è¡°å‡ï¼‰
/// 
/// ä½¿ç”¨æŒ‡æ•°è¡°å‡æ¨¡å‹ï¼šrecency = exp(-decay * hours_since_access)
/// - æœ€è¿‘è®¿é—®çš„è®°å¿†å¾—åˆ†æ¥è¿‘1.0
/// - éšç€æ—¶é—´æ¨ç§»ï¼Œå¾—åˆ†æŒ‡æ•°çº§è¡°å‡
/// 
/// # å‚æ•°
/// - `last_accessed_at`: æœ€åè®¿é—®æ—¶é—´ï¼ˆISO 8601å­—ç¬¦ä¸²ï¼‰
/// - `recency_decay`: è¡°å‡ç³»æ•°ï¼ˆé»˜è®¤0.1ï¼Œè¡¨ç¤ºæ¯å°æ—¶è¡°å‡çº¦10%ï¼‰
/// 
/// # è¿”å›
/// Recencyè¯„åˆ†ï¼ˆ0.0åˆ°1.0ä¹‹é—´ï¼‰
pub(crate) fn calculate_recency_score(last_accessed_at: &str, recency_decay: f64) -> f64 {
    use chrono::{DateTime, Utc};
    
    // è§£ææœ€åè®¿é—®æ—¶é—´
    let last_accessed = if let Ok(dt) = DateTime::parse_from_rfc3339(last_accessed_at) {
        dt.with_timezone(&Utc)
    } else if let Ok(dt) = last_accessed_at.parse::<DateTime<Utc>>() {
        dt
    } else {
        // å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼ï¼ˆå‡è®¾æ˜¯æœ€è¿‘è®¿é—®çš„ï¼‰
        return 1.0;
    };
    
    // è®¡ç®—è·ç¦»ç°åœ¨çš„å°æ—¶æ•°
    let now = Utc::now();
    let hours_since_access = (now - last_accessed).num_seconds() as f64 / 3600.0;
    
    // æŒ‡æ•°è¡°å‡ï¼šexp(-decay * hours)
    // ä¾‹å¦‚ï¼šdecay=0.1æ—¶ï¼Œ1å°æ—¶åçº¦0.9ï¼Œ24å°æ—¶åçº¦0.08
    let recency = (-recency_decay * hours_since_access.max(0.0)).exp();
    
    // ç¡®ä¿ç»“æœåœ¨[0.0, 1.0]èŒƒå›´å†…
    recency.max(0.0).min(1.0)
}

/// è®¡ç®—ä¸‰ç»´æ£€ç´¢ç»¼åˆè¯„åˆ†ï¼ˆRecency Ã— Importance Ã— Relevanceï¼‰
/// 
/// åŸºäºGenerative Agentsè®ºæ–‡çš„ä¸‰ç»´æ£€ç´¢æ¨¡å‹ï¼š
/// - Recency: åŸºäºæœ€åè®¿é—®æ—¶é—´çš„æŒ‡æ•°è¡°å‡
/// - Importance: è®°å¿†çš„é‡è¦æ€§åˆ†æ•°ï¼ˆ0.0-1.0ï¼‰
/// - Relevance: å‘é‡æœç´¢çš„ç›¸å…³æ€§åˆ†æ•°ï¼ˆ0.0-1.0ï¼‰
/// 
/// ç»¼åˆè¯„åˆ† = Recency Ã— Importance Ã— Relevance
/// 
/// # å‚æ•°
/// - `relevance`: å‘é‡æœç´¢çš„ç›¸å…³æ€§åˆ†æ•°ï¼ˆ0.0-1.0ï¼‰
/// - `importance`: è®°å¿†çš„é‡è¦æ€§åˆ†æ•°ï¼ˆ0.0-1.0ï¼‰
/// - `last_accessed_at`: æœ€åè®¿é—®æ—¶é—´ï¼ˆISO 8601å­—ç¬¦ä¸²ï¼‰
/// - `recency_decay`: Recencyè¡°å‡ç³»æ•°ï¼ˆé»˜è®¤0.1ï¼‰
/// 
/// # è¿”å›
/// ä¸‰ç»´ç»¼åˆè¯„åˆ†ï¼ˆ0.0åˆ°1.0ä¹‹é—´ï¼‰
pub(crate) fn calculate_3d_score(
    relevance: f32,
    importance: f32,
    last_accessed_at: &str,
    recency_decay: f64,
) -> f64 {
    // è®¡ç®—Recencyè¯„åˆ†
    let recency = calculate_recency_score(last_accessed_at, recency_decay);
    
    // ç¡®ä¿importanceå’Œrelevanceåœ¨æœ‰æ•ˆèŒƒå›´å†…
    let importance_clamped = importance.max(0.0).min(1.0) as f64;
    let relevance_clamped = relevance.max(0.0).min(1.0) as f64;
    
    // ä¸‰ç»´è¯„åˆ†ï¼šRecency Ã— Importance Ã— Relevance
    let composite_score = recency * importance_clamped * relevance_clamped;
    
    // ç¡®ä¿ç»“æœåœ¨[0.0, 1.0]èŒƒå›´å†…
    composite_score.max(0.0).min(1.0)
}

/// ğŸ†• Phase 2.10: è®¡ç®—æœç´¢ç»“æœè´¨é‡è¯„åˆ†
/// 
/// åŸºäºå†…å®¹è´¨é‡ã€å®Œæ•´æ€§å’Œå…ƒæ•°æ®ä¸°å¯Œåº¦è¯„ä¼°æœç´¢ç»“æœçš„è´¨é‡
/// è¿”å›0.0åˆ°1.0ä¹‹é—´çš„è´¨é‡åˆ†æ•°
pub(crate) fn calculate_quality_score(item: &MemoryItem) -> f64 {
    let mut quality_score = 0.0;
    let mut weight_sum = 0.0;
    
    // 1. å†…å®¹é•¿åº¦è¯„åˆ†ï¼ˆç†æƒ³é•¿åº¦ï¼š50-500å­—ç¬¦ï¼‰
    let content_len = item.content.len();
    let length_score = if content_len < 10 {
        0.2 // å¤ªçŸ­ï¼Œè´¨é‡ä½
    } else if content_len < 50 {
        0.5 // è¾ƒçŸ­ï¼Œè´¨é‡ä¸­ç­‰
    } else if content_len <= 500 {
        1.0 // ç†æƒ³é•¿åº¦
    } else if content_len <= 2000 {
        0.8 // è¾ƒé•¿ï¼Œä½†å¯æ¥å—
    } else {
        0.6 // å¤ªé•¿ï¼Œå¯èƒ½åŒ…å«å†—ä½™ä¿¡æ¯
    };
    quality_score += length_score * 0.3;
    weight_sum += 0.3;
    
    // 2. å…ƒæ•°æ®ä¸°å¯Œåº¦è¯„åˆ†
    let metadata_score = if item.metadata.is_empty() {
        0.3 // æ— å…ƒæ•°æ®
    } else if item.metadata.len() < 3 {
        0.6 // å°‘é‡å…ƒæ•°æ®
    } else if item.metadata.len() <= 10 {
        1.0 // ä¸°å¯Œçš„å…ƒæ•°æ®
    } else {
        0.9 // å…ƒæ•°æ®å¾ˆå¤šï¼Œä½†å¯èƒ½å†—ä½™
    };
    quality_score += metadata_score * 0.2;
    weight_sum += 0.2;
    
    // 3. å†…å®¹å®Œæ•´æ€§è¯„åˆ†ï¼ˆæ˜¯å¦æœ‰hashï¼‰
    let completeness_score = if item.hash.is_some() && !item.hash.as_ref().unwrap().is_empty() {
        1.0 // æœ‰hashï¼Œå®Œæ•´æ€§å¥½
    } else {
        0.5 // æ— hashï¼Œå®Œæ•´æ€§ä¸€èˆ¬
    };
    quality_score += completeness_score * 0.2;
    weight_sum += 0.2;
    
    // 4. è®¿é—®å†å²è¯„åˆ†ï¼ˆæœ‰è®¿é—®å†å²çš„è´¨é‡æ›´é«˜ï¼‰
    let access_score = if item.access_count > 0 {
        // è®¿é—®æ¬¡æ•°è¶Šå¤šï¼Œè´¨é‡è¶Šé«˜ï¼ˆä½†æœ‰é™åˆ¶ï¼‰
        (item.access_count.min(100) as f64 / 100.0).min(1.0)
    } else {
        0.5 // æ— è®¿é—®å†å²
    };
    quality_score += access_score * 0.15;
    weight_sum += 0.15;
    
    // 5. é‡è¦æ€§è¯„åˆ†ï¼ˆé‡è¦æ€§è¶Šé«˜ï¼Œè´¨é‡è¶Šé«˜ï¼‰
    let importance_score = item.importance.max(0.0).min(1.0) as f64;
    quality_score += importance_score * 0.15;
    weight_sum += 0.15;
    
    // å½’ä¸€åŒ–ï¼ˆç¡®ä¿åœ¨0.0åˆ°1.0ä¹‹é—´ï¼‰
    if weight_sum > 0.0 {
        quality_score / weight_sum
    } else {
        0.5 // é»˜è®¤ä¸­ç­‰è´¨é‡
    }
}

/// æ™ºèƒ½é˜ˆå€¼è®¡ç®—ï¼šæ ¹æ®æŸ¥è¯¢ç±»å‹åŠ¨æ€è°ƒæ•´é˜ˆå€¼
/// ğŸ”§ å¢å¼ºï¼šæ·»åŠ ä¸­æ–‡æ£€æµ‹ï¼Œä¸ºä¸­æ–‡æŸ¥è¯¢é™ä½é˜ˆå€¼ä»¥æé«˜å¬å›ç‡
fn get_adaptive_threshold(query: &str) -> f32 {
    use regex::Regex;

    // ğŸ”§ æ–°å¢ï¼šæ£€æµ‹ä¸­æ–‡æŸ¥è¯¢ï¼Œé™ä½é˜ˆå€¼
    let has_chinese = contains_chinese(query);
    let chinese_adjustment = if has_chinese { -0.2 } else { 0.0 };

    // æ£€æµ‹å•†å“IDæ ¼å¼: P + 6ä½æ•°å­—
    if let Ok(pattern) = Regex::new(r"^P\d{6}$") {
        if pattern.is_match(query) {
            return 0.1; // å•†å“ID: æä½é˜ˆå€¼ï¼Œå‡ ä¹åªè¦åŒ¹é…å°±è¿”å›
        }
    }

    // æ£€æµ‹UUIDæ ¼å¼
    if query.len() == 36 && query.matches('-').count() == 4 {
        return 0.1; // UUID: æä½é˜ˆå€¼
    }

    // æ£€æµ‹å…¶ä»–ç²¾ç¡®IDæ ¼å¼ï¼ˆå…¨å­—æ¯æ•°å­—ï¼Œæ— ç©ºæ ¼ï¼Œé•¿åº¦< 20ï¼‰
    if query.len() < 20
        && !query.contains(' ')
        && query
            .chars()
            .all(|c| c.is_alphanumeric() || c == '-' || c == '_')
    {
        return 0.2; // ç²¾ç¡®ID: ä½é˜ˆå€¼
    }

    // çŸ­æŸ¥è¯¢ï¼ˆ< 5å­—ç¬¦ï¼‰
    if query.len() < 5 {
        return (0.3f32 + chinese_adjustment).max(0.1f32); // çŸ­æŸ¥è¯¢: ä½é˜ˆå€¼ï¼Œä¸­æ–‡æ›´ä½
    }

    // åŒ…å«å•†å“ç›¸å…³å…³é”®è¯
    let lower_query = query.to_lowercase();
    if lower_query.contains("å•†å“")
        || lower_query.contains("è®¢å•")
        || lower_query.contains("id")
        || lower_query.contains("product")
    {
        return (0.4f32 + chinese_adjustment).max(0.2f32); // å•†å“ç›¸å…³: ä¸­ä½é˜ˆå€¼
    }

    // æ ¹æ®é•¿åº¦è°ƒæ•´ï¼ˆåº”ç”¨ä¸­æ–‡è°ƒæ•´ï¼‰
    let query_len = query.len();
    let base_threshold = if query_len < 20 {
        0.3f32 // çŸ­æŸ¥è¯¢
    } else if query_len < 50 {
        0.5f32 // ä¸­ç­‰é•¿åº¦æŸ¥è¯¢
    } else {
        0.7f32 // é•¿æŸ¥è¯¢ç”¨é«˜é˜ˆå€¼
    };
    
    (base_threshold + chinese_adjustment).max(0.1f32).min(0.9f32)
}

/// æ£€æµ‹æ˜¯å¦æ˜¯ç²¾ç¡®æŸ¥è¯¢ï¼ˆå•†å“IDã€SKUç­‰ï¼‰
fn detect_exact_query(query: &str) -> bool {
    // å•†å“IDæ ¼å¼ï¼šP + 6ä½æ•°å­—
    if let Ok(pattern) = regex::Regex::new(r"^P\d{6}$") {
        if pattern.is_match(query) {
            return true;
        }
    }

    // å…¶ä»–ç²¾ç¡®IDæ ¼å¼ï¼ˆå…¨å­—æ¯æ•°å­—ï¼Œæ— ç©ºæ ¼ï¼Œé•¿åº¦< 20ï¼‰
    query.len() < 20
        && !query.contains(' ')
        && query
            .chars()
            .all(|c| c.is_alphanumeric() || c == '-' || c == '_')
}

/// é€šè¿‡LibSQLç²¾ç¡®æŸ¥è¯¢ï¼ˆå•†å“IDç­‰ï¼‰- ä½¿ç”¨searchæ–¹æ³•ï¼Œç›´æ¥è¿”å›JSON
async fn search_by_libsql_exact(
    repositories: &Arc<agent_mem_core::storage::factory::Repositories>,
    query: &str,
    limit: usize,
) -> Result<Vec<serde_json::Value>, String> {
    use tracing::{debug, error, info};

    info!("ğŸ” LibSQLç²¾ç¡®æŸ¥è¯¢: query='{}', limit={}", query, limit);

    // ä½¿ç”¨repositories.memories.searchæ–¹æ³•ï¼ˆæ”¯æŒcontent LIKEæŸ¥è¯¢ï¼‰
    match repositories
        .memories
        .search(query, (limit * 2) as i64) // å¤šå–ä¸€äº›ï¼Œç”¨äºæ’åºè¿‡æ»¤
        .await
    {
        Ok(memories) if !memories.is_empty() => {
            info!("âœ… LibSQLæŸ¥è¯¢æˆåŠŸ: æ‰¾åˆ° {} æ¡è®°å¿†", memories.len());

            // ğŸ”§ ä¿®å¤: å°† MemoryV4 è½¬æ¢ä¸º MemoryItem ä»¥ä¾¿è®¿é—®å­—æ®µ
            use agent_mem_traits::MemoryV4;
            let memory_items: Vec<_> = memories.into_iter().map(|m| m.to_legacy_item()).collect();

            // ğŸ”§ ä¿®å¤: ä¼˜å…ˆè¿”å›ç²¾ç¡®åŒ¹é…çš„å•†å“è®°å¿†
            // 1. åˆ†ç¦»ç²¾ç¡®åŒ¹é…å’Œæ¨¡ç³ŠåŒ¹é…
            let mut exact_matches = Vec::new();
            let mut fuzzy_matches = Vec::new();

            for mem in memory_items {
                let is_exact = {
                    // æ£€æŸ¥ content æ˜¯å¦åŒ…å« "å•†å“ID: {query}"
                    mem.content.contains(&format!("å•†å“ID: {}", query)) ||
                    // æ£€æŸ¥ metadata ä¸­çš„ product_id æ˜¯å¦åŒ¹é…
                    mem.metadata
                        .get("product_id")
                        .and_then(|v| v.as_str())
                        .map(|pid| pid == query)
                        .unwrap_or(false)
                };

                // æ’é™¤å·¥ä½œè®°å¿†ï¼ˆworking memoryï¼‰ï¼Œå®ƒä»¬é€šå¸¸æ˜¯LLMçš„å›å¤
                let memory_type_str = format!("{:?}", mem.memory_type);
                let is_working_memory = matches!(memory_type_str.as_str(), "Working");

                if is_exact && !is_working_memory {
                    exact_matches.push(mem);
                } else if !is_working_memory {
                    fuzzy_matches.push(mem);
                }
            }

            info!(
                "ğŸ“Š ç²¾ç¡®åŒ¹é…: {} æ¡, æ¨¡ç³ŠåŒ¹é…: {} æ¡",
                exact_matches.len(),
                fuzzy_matches.len()
            );

            // 2. åˆå¹¶ç»“æœï¼šç²¾ç¡®åŒ¹é…åœ¨å‰ï¼Œæ¨¡ç³ŠåŒ¹é…åœ¨å
            let mut sorted_memories = exact_matches;
            sorted_memories.extend(fuzzy_matches);

            // 3. é™åˆ¶è¿”å›æ•°é‡
            sorted_memories.truncate(limit);

            for mem in &sorted_memories {
                // ğŸ”§ ä¿®å¤: ä½¿ç”¨å­—ç¬¦è¾¹ç•Œè€Œä¸æ˜¯å­—èŠ‚è¾¹ç•Œï¼Œé¿å…UTF-8å­—ç¬¦ä¸­é—´åˆ‡ç‰‡å¯¼è‡´panic
                let content_preview = truncate_string_at_char_boundary(&mem.content, 50);
                debug!(
                    "  - ID: {}, Type: {:?}, Content: {}...",
                    mem.id, mem.memory_type, content_preview
                );
            }

            // ç›´æ¥è½¬æ¢ä¸ºJSON
            let json_results: Vec<serde_json::Value> = sorted_memories
                .into_iter()
                .map(|m| {
                    serde_json::json!({
                        "id": m.id,
                        "agent_id": m.agent_id,
                        "user_id": m.user_id,
                        "content": m.content,
                        "memory_type": format!("{:?}", m.memory_type),
                        "importance": m.importance,
                        "created_at": m.created_at.to_rfc3339(),
                        "updated_at": m.updated_at.map(|dt| dt.to_rfc3339()),
                        "access_count": m.access_count,
                        "metadata": m.metadata,
                        "hash": m.hash,
                        "score": m.score.unwrap_or(1.0),
                    })
                })
                .collect();

            if json_results.is_empty() {
                info!("âš ï¸  è¿‡æ»¤åæ²¡æœ‰æœ‰æ•ˆç»“æœ: query='{}'", query);
                Err(format!("æœªæ‰¾åˆ°åŒ¹é…çš„è®°å¿†: {}", query))
            } else {
                Ok(json_results)
            }
        }
        Ok(_) => {
            info!("âš ï¸  LibSQLæœªæ‰¾åˆ°ç»“æœ: query='{}'", query);
            Err(format!("æœªæ‰¾åˆ°åŒ¹é…çš„è®°å¿†: {}", query))
        }
        Err(e) => {
            error!("âŒ LibSQLæŸ¥è¯¢å¤±è´¥: {}", e);
            Err(format!("LibSQLæŸ¥è¯¢å¤±è´¥: {}", e))
        }
    }
}

/// è½¬æ¢CoreMemoryItemä¸ºJSON
fn convert_memory_to_json(item: agent_mem_traits::MemoryItem) -> serde_json::Value {
    serde_json::json!({
        "id": item.id,
        "agent_id": item.agent_id,
        "user_id": item.user_id,
        "content": item.content,
        "memory_type": item.memory_type,
        "importance": item.importance,
        "created_at": item.created_at,
        "last_accessed_at": item.last_accessed_at,
        "access_count": item.access_count,
        "metadata": item.metadata,
        "score": item.score,
        "hash": item.hash,
    })
}

#[utoipa::path(
    post,
    path = "/api/v1/memories/search",
    tag = "memory",
    request_body = crate::models::SearchRequest,
    responses(
        (status = 200, description = "Search completed successfully", body = crate::models::SearchResponse),
        (status = 400, description = "Invalid search request"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn search_memories(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    Json(request): Json<crate::models::SearchRequest>,
) -> ServerResult<Json<crate::models::ApiResponse<Vec<serde_json::Value>>>> {
    info!("ğŸ” æœç´¢è®°å¿†: query={}", request.query);

    // ğŸ†• Phase 2.7: æœç´¢ç»Ÿè®¡æ”¶é›† - è®°å½•æœç´¢å¼€å§‹æ—¶é—´
    let search_start = Instant::now();
    let stats = get_search_stats();

    // ğŸ¯ Phase 1: LibSQLç²¾ç¡®æŸ¥è¯¢ï¼ˆå•†å“IDç­‰ï¼‰
    let is_exact_query = detect_exact_query(&request.query);

    if is_exact_query {
        info!("ğŸ¯ æ£€æµ‹åˆ°ç²¾ç¡®æŸ¥è¯¢ï¼Œä½¿ç”¨LibSQL: {}", request.query);

        // å°è¯•LibSQLç²¾ç¡®åŒ¹é…
        let limit = request.limit.unwrap_or(10);
        match search_by_libsql_exact(&repositories, &request.query, limit).await {
            Ok(json_results) if !json_results.is_empty() => {
                info!("âœ… LibSQLç²¾ç¡®åŒ¹é…æ‰¾åˆ° {} æ¡ç»“æœ", json_results.len());
                
                // ğŸ†• Phase 2.7: æ›´æ–°ç»Ÿè®¡ï¼ˆç²¾ç¡®æŸ¥è¯¢ï¼‰
                let search_latency = search_start.elapsed();
                {
                    let mut stats_write = stats.write().await;
                    stats_write.total_searches += 1;
                    stats_write.exact_queries += 1;
                    stats_write.total_latency_us += search_latency.as_micros() as u64;
                    stats_write.last_updated = Instant::now();
                }
                
                return Ok(Json(crate::models::ApiResponse::success(json_results)));
            }
            Ok(_) => {
                info!("âš ï¸  LibSQLæœªæ‰¾åˆ°ç»“æœï¼Œé™çº§åˆ°å‘é‡æœç´¢");
            }
            Err(e) => {
                warn!("âš ï¸  LibSQLæŸ¥è¯¢å¤±è´¥: {}, é™çº§åˆ°å‘é‡æœç´¢", e);
            }
        }
    }

    // ğŸ” Phase 2: å‘é‡è¯­ä¹‰æœç´¢ï¼ˆé™çº§æˆ–é»˜è®¤ï¼‰
    info!("ğŸ” ä½¿ç”¨å‘é‡è¯­ä¹‰æœç´¢: {}", request.query);
    let query_clone = request.query.clone(); // Clone for later use
    
    // ğŸ†• Phase 2.4: æŸ¥è¯¢ç»“æœç¼“å­˜ï¼ˆç®€å•å®ç°ï¼‰
    // ç”Ÿæˆç¼“å­˜é”®
    let cache_key = generate_cache_key(
        &request.query,
        &request.agent_id,
        &request.user_id,
        &request.limit,
    );
    
    // å°è¯•ä»ç¼“å­˜è·å–ç»“æœ
    let cache = get_search_cache();
    let cache_ttl = Duration::from_secs(
        std::env::var("SEARCH_CACHE_TTL_SECONDS")
            .ok()
            .and_then(|v| v.parse().ok())
            .unwrap_or(300), // é»˜è®¤5åˆ†é’Ÿ
    );
    
    // æ£€æŸ¥ç¼“å­˜ï¼ˆLruCacheçš„getéœ€è¦&mutï¼Œæ‰€ä»¥ä½¿ç”¨writeé”ï¼‰
    let cache_hit = {
        let mut cache_write = cache.write().await;
        if let Some(cached) = cache_write.get(&cache_key) {
            if !cached.is_expired() {
                info!("ğŸ’¾ ç¼“å­˜å‘½ä¸­: query='{}', cache_key={}", request.query, cache_key);
                
                // ğŸ†• Phase 2.7: æ›´æ–°ç»Ÿè®¡ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
                let search_latency = search_start.elapsed();
                {
                    let mut stats_write = stats.write().await;
                    stats_write.total_searches += 1;
                    stats_write.cache_hits += 1;
                    stats_write.vector_searches += 1;
                    stats_write.total_latency_us += search_latency.as_micros() as u64;
                    stats_write.last_updated = Instant::now();
                }
                
                return Ok(Json(crate::models::ApiResponse::success(cached.results.clone())));
            } else {
                // ç¼“å­˜è¿‡æœŸï¼Œåˆ é™¤
                cache_write.pop(&cache_key);
                false
            }
        } else {
            false
        }
    };
    
    if !cache_hit {
        info!("ğŸ’¾ ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œæœç´¢: query='{}'", request.query);
        
        // ğŸ†• Phase 2.7: æ›´æ–°ç»Ÿè®¡ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
        {
            let mut stats_write = stats.write().await;
            stats_write.cache_misses += 1;
        }
    }
    
    // ğŸ”§ å¢å¼ºï¼šè®¡ç®—è‡ªé€‚åº”é˜ˆå€¼ç”¨äºåç»­è¿‡æ»¤
    let adaptive_threshold = get_adaptive_threshold(&request.query);
    info!("ğŸ“Š è‡ªé€‚åº”é˜ˆå€¼: query='{}', threshold={}", request.query, adaptive_threshold);
    
    // ğŸ†• Phase 2.9: æœç´¢è¶…æ—¶æ§åˆ¶
    let search_timeout_secs = std::env::var("SEARCH_TIMEOUT_SECONDS")
        .ok()
        .and_then(|v| v.parse().ok())
        .unwrap_or(30); // é»˜è®¤30ç§’
    
    let memory_manager_clone = memory_manager.clone();
    let query_clone_for_timeout = request.query.clone();
    let agent_id_clone = request.agent_id.clone();
    let user_id_clone = request.user_id.clone();
    let limit_clone = request.limit;
    let memory_type_clone = request.memory_type.clone();
    
    let search_future = async move {
        memory_manager_clone
            .search_memories(
                query_clone_for_timeout,
                agent_id_clone,
                user_id_clone,
                limit_clone,
                memory_type_clone,
            )
            .await
    };
    
    let mut results = match timeout(Duration::from_secs(search_timeout_secs), search_future).await {
        Ok(Ok(results)) => results,
        Ok(Err(e)) => {
            error!("Failed to search memories: {}", e);
            return Err(ServerError::MemoryError(e.to_string()));
        }
        Err(_) => {
            error!("Search operation timed out after {} seconds", search_timeout_secs);
            return Err(ServerError::Internal(format!(
                "Search operation timed out after {} seconds",
                search_timeout_secs
            )));
        }
    };

    // âœ… ä¿®å¤ï¼šè¿‡æ»¤å·²åˆ é™¤çš„è®°å½•ï¼Œç¡®ä¿æœç´¢ç»“æœä¸LibSQLçŠ¶æ€ä¸€è‡´
    // ğŸ†• Phase 3.2: å¹¶è¡ŒæŸ¥è¯¢ä¼˜åŒ– - ä½¿ç”¨å¹¶è¡ŒæŸ¥è¯¢æ‰¹é‡æ£€æŸ¥ç»“æœçŠ¶æ€
    // å‘é‡å­˜å‚¨å¯èƒ½è¿˜åŒ…å«å·²åˆ é™¤çš„è®°å½•ï¼Œéœ€è¦æ£€æŸ¥LibSQLä¸­çš„å®é™…çŠ¶æ€
    let valid_results = if results.is_empty() {
        Vec::new()
    } else {
        // å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰find_by_idæŸ¥è¯¢
        let check_futures: Vec<_> = results
            .iter()
            .map(|result| {
                let id = result.id.clone();
                let repo = &repositories.memories;
                async move {
                    let status = repo.find_by_id(&id).await;
                    (result.clone(), status)
                }
            })
            .collect();
        
        // ç­‰å¾…æ‰€æœ‰æŸ¥è¯¢å®Œæˆ
        let check_results = future::join_all(check_futures).await;
        
        // è¿‡æ»¤æœ‰æ•ˆç»“æœ
        let mut valid = Vec::new();
        for (result, status) in check_results {
            match status {
                Ok(Some(_)) => {
                    // è®°å½•å­˜åœ¨ä¸”æœªåˆ é™¤ï¼ˆfind_by_idå·²ç»è¿‡æ»¤äº†is_deleted=0ï¼‰
                    valid.push(result);
                }
                Ok(None) => {
                    // è®°å½•ä¸å­˜åœ¨æˆ–å·²åˆ é™¤ï¼Œè·³è¿‡
                    debug!("Skipping deleted memory from search results: {}", result.id);
                }
                Err(e) => {
                    // æŸ¥è¯¢å¤±è´¥ï¼Œä¸ºäº†å®‰å…¨èµ·è§ï¼Œè·³è¿‡è¯¥è®°å½•
                    warn!("Failed to check memory status in LibSQL: {}, skipping result", e);
                }
            }
        }
        valid
    };
    
    info!("ğŸ”„ å¹¶è¡ŒéªŒè¯å®Œæˆ: {} â†’ {} æ¡æœ‰æ•ˆç»“æœ", results.len(), valid_results.len());
    results = valid_results;

    // ğŸ”§ ä¿®å¤: å¯¹äºç²¾ç¡®æŸ¥è¯¢ï¼Œä¼˜å…ˆè¿”å›ç²¾ç¡®åŒ¹é…çš„ç»“æœ
    let mut sorted_results = results;
    if is_exact_query {
        // åˆ†ç¦»ç²¾ç¡®åŒ¹é…å’Œæ¨¡ç³ŠåŒ¹é…
        let mut exact_matches = Vec::new();
        let mut fuzzy_matches = Vec::new();

        for item in sorted_results {
            let is_exact = {
                // æ£€æŸ¥ content æ˜¯å¦åŒ…å« "å•†å“ID: {query}"
                item.content.contains(&format!("å•†å“ID: {}", query_clone)) ||
                // æ£€æŸ¥ metadata ä¸­çš„ product_id æ˜¯å¦åŒ¹é…
                item.metadata
                    .get("product_id")
                    .and_then(|v| v.as_str())
                    .map(|pid| pid == query_clone)
                    .unwrap_or(false)
            };

            // æ’é™¤å·¥ä½œè®°å¿†ï¼ˆworking memoryï¼‰
            let is_working_memory =
                matches!(item.memory_type.to_string().as_str(), "working" | "Working");

            if is_exact && !is_working_memory {
                exact_matches.push(item);
            } else if !is_working_memory {
                fuzzy_matches.push(item);
            }
        }

        info!(
            "ğŸ“Š å‘é‡æœç´¢æ’åº: ç²¾ç¡®åŒ¹é… {} æ¡, æ¨¡ç³ŠåŒ¹é… {} æ¡",
            exact_matches.len(),
            fuzzy_matches.len()
        );

        // åˆå¹¶ï¼šç²¾ç¡®åŒ¹é…åœ¨å‰ï¼Œæ¨¡ç³ŠåŒ¹é…åœ¨å
        sorted_results = exact_matches;
        sorted_results.extend(fuzzy_matches);
    }

    // ğŸ†• Phase 2.1: ä¸‰ç»´æ£€ç´¢è¯„åˆ†ï¼ˆRecency Ã— Importance Ã— Relevanceï¼‰
    // è·å–recency_decayé…ç½®ï¼ˆé»˜è®¤0.1ï¼Œè¡¨ç¤ºæ¯å°æ—¶è¡°å‡çº¦10%ï¼‰
    let recency_decay: f64 = std::env::var("RECENCY_DECAY")
        .ok()
        .and_then(|v| v.parse().ok())
        .unwrap_or(0.1);
    
    // ä¸ºæ¯ä¸ªç»“æœè®¡ç®—ä¸‰ç»´è¯„åˆ†å’Œè´¨é‡è¯„åˆ†
    let mut scored_results: Vec<(MemoryItem, f64, f64, f64, f64, f64)> = sorted_results
        .into_iter()
        .map(|item| {
            // è·å–å„ä¸ªç»´åº¦åˆ†æ•°
            let relevance = item.score.unwrap_or(0.0);
            let importance = item.importance.max(0.0).min(1.0);
            let last_accessed = item.last_accessed_at.to_string();
            
            // è®¡ç®—Recencyè¯„åˆ†
            let recency = calculate_recency_score(&last_accessed, recency_decay);
            
            // è®¡ç®—ä¸‰ç»´ç»¼åˆè¯„åˆ†
            let composite_score = calculate_3d_score(
                relevance,
                importance,
                &last_accessed,
                recency_decay,
            );
            
            // ğŸ†• Phase 2.10: è®¡ç®—è´¨é‡è¯„åˆ†
            let quality = calculate_quality_score(&item);
            
            // å°†è´¨é‡è¯„åˆ†çº³å…¥ç»¼åˆè¯„åˆ†ï¼ˆè´¨é‡æƒé‡ï¼š0.1ï¼‰
            let final_score = composite_score * 0.9 + quality * 0.1;
            
            (item, final_score, recency, importance as f64, relevance as f64, quality)
        })
        .collect();
    
    // æŒ‰ä¸‰ç»´ç»¼åˆè¯„åˆ†æ’åºï¼ˆé™åºï¼‰
    scored_results.sort_by(|a, b| {
        b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal)
    });
    
    info!("ğŸ¯ ä¸‰ç»´æ£€ç´¢è¯„åˆ†å®Œæˆ: recency_decay={}, ç»“æœæ•°={}", 
        recency_decay, scored_results.len());

    // ğŸ”§ ä¿®å¤: è¿‡æ»¤ä½ç›¸å…³åº¦ç»“æœï¼ˆä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼ï¼‰
    // ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„é˜ˆå€¼ï¼Œå¦åˆ™ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼ï¼Œæœ€åæ‰ä½¿ç”¨é»˜è®¤å€¼
    let min_score_threshold = request.threshold.unwrap_or(adaptive_threshold);
    info!("ğŸ¯ è¿‡æ»¤é˜ˆå€¼: {} (ç”¨æˆ·æŒ‡å®š: {}, è‡ªé€‚åº”: {})", 
        min_score_threshold,
        request.threshold.map(|t| t.to_string()).unwrap_or_else(|| "æœªæŒ‡å®š".to_string()),
        adaptive_threshold);

    // ğŸ†• Phase 2.5: æœç´¢ç»“æœå»é‡ï¼ˆåŸºäºcontent hashï¼‰
    // ä½¿ç”¨HashSetå»é‡ï¼Œä¿ç•™ç»¼åˆè¯„åˆ†æœ€é«˜çš„ç»“æœ
    use std::collections::HashMap;
    let mut hash_map: HashMap<String, (MemoryItem, f64, f64, f64, f64, f64)> = HashMap::new();
    let original_count = scored_results.len();
    
    for (item, final_score, recency, importance, relevance, quality) in scored_results {
        // ä½¿ç”¨hashå­—æ®µè¿›è¡Œå»é‡ï¼ˆå¦‚æœhashä¸ºNoneæˆ–ç©ºï¼Œä½¿ç”¨contentçš„å‰100å­—ç¬¦ä½œä¸ºkeyï¼‰
        let dedup_key = item.hash.as_ref()
            .filter(|h| !h.is_empty())
            .cloned()
            .unwrap_or_else(|| {
                // å¦‚æœhashä¸ºç©ºï¼Œä½¿ç”¨contentçš„å‰100å­—ç¬¦ä½œä¸ºå»é‡key
                if item.content.len() > 100 {
                    // ä½¿ç”¨char_indicesæ‰¾åˆ°å®‰å…¨çš„å­—ç¬¦è¾¹ç•Œ
                    let mut char_count = 0;
                    let mut byte_index = 0;
                    for (i, _) in item.content.char_indices() {
                        if char_count >= 100 {
                            break;
                        }
                        char_count += 1;
                        byte_index = i;
                    }
                    item.content[..byte_index].to_string()
                } else {
                    item.content.clone()
                }
            });
        
            // å¦‚æœhashå·²å­˜åœ¨ï¼Œæ¯”è¾ƒç»¼åˆè¯„åˆ†ï¼Œä¿ç•™è¯„åˆ†æ›´é«˜çš„
            match hash_map.get_mut(&dedup_key) {
                Some(existing) => {
                    // æ¯”è¾ƒç»¼åˆè¯„åˆ†ï¼Œå¦‚æœæ–°ç»“æœè¯„åˆ†æ›´é«˜ï¼Œæ›¿æ¢æ—§ç»“æœ
                    if final_score > existing.1 {
                        *existing = (item, final_score, recency, importance, relevance, quality);
                    }
                }
                None => {
                    // æ–°hashï¼Œç›´æ¥æ·»åŠ 
                    hash_map.insert(dedup_key, (item, final_score, recency, importance, relevance, quality));
                }
            }
        }
        
        let deduplicated_results: Vec<(MemoryItem, f64, f64, f64, f64, f64)> = hash_map.into_values().collect();
    info!("ğŸ”„ æœç´¢ç»“æœå»é‡: {} â†’ {} æ¡ç»“æœ", original_count, deduplicated_results.len());

    // è½¬æ¢ä¸ºJSONï¼ŒåŒæ—¶åº”ç”¨é˜ˆå€¼è¿‡æ»¤ï¼ˆä½¿ç”¨åŸå§‹relevanceåˆ†æ•°è¿›è¡Œé˜ˆå€¼è¿‡æ»¤ï¼‰
    let json_results: Vec<serde_json::Value> = deduplicated_results
        .into_iter()
        .filter(|(item, _, _, _, relevance, _)| {
            // ä½¿ç”¨åŸå§‹çš„relevanceåˆ†æ•°è¿›è¡Œé˜ˆå€¼è¿‡æ»¤
            *relevance >= min_score_threshold as f64
        })
        .map(|(item, final_score, recency, importance, relevance, quality)| {
            serde_json::json!({
                "id": item.id,
                "agent_id": item.agent_id,
                "user_id": item.user_id,
                "content": item.content,
                "memory_type": item.memory_type,
                "importance": item.importance,
                "created_at": item.created_at,
                "last_accessed_at": item.last_accessed_at,
                "access_count": item.access_count,
                "metadata": item.metadata,
                "hash": item.hash,
                "score": relevance,  // åŸå§‹relevanceåˆ†æ•°ï¼ˆç”¨äºé˜ˆå€¼è¿‡æ»¤ï¼‰
                "composite_score": final_score,  // ğŸ†• æœ€ç»ˆç»¼åˆè¯„åˆ†ï¼ˆåŒ…å«è´¨é‡è¯„åˆ†ï¼‰
                "recency": recency,  // ğŸ†• Recencyè¯„åˆ†
                "relevance": relevance,  // ğŸ†• Relevanceè¯„åˆ†ï¼ˆä¸scoreç›¸åŒï¼‰
                "quality": quality,  // ğŸ†• Phase 2.10: è´¨é‡è¯„åˆ†
            })
        })
        .collect();

    // ğŸ†• Phase 2.4: ä¿å­˜ç»“æœåˆ°ç¼“å­˜ï¼ˆä½¿ç”¨LRUç­–ç•¥ï¼‰
    {
        let mut cache_write = cache.write().await;
        // LRUç¼“å­˜ä¼šè‡ªåŠ¨å¤„ç†å®¹é‡é™åˆ¶ï¼Œä½†æˆ‘ä»¬éœ€è¦æ¸…ç†è¿‡æœŸæ¡ç›®
        // å…ˆæ¸…ç†è¿‡æœŸæ¡ç›®ï¼ˆLruCacheä¸æ”¯æŒretainï¼Œéœ€è¦æ‰‹åŠ¨æ¸…ç†ï¼‰
        let expired_keys: Vec<String> = cache_write
            .iter()
            .filter(|(_, v)| v.is_expired())
            .map(|(k, _)| k.clone())
            .collect();
        for key in expired_keys {
            cache_write.pop(&key);
        }
        // æ’å…¥æ–°ç»“æœï¼ˆLRUä¼šè‡ªåŠ¨æ·˜æ±°æœ€ä¹…æœªä½¿ç”¨çš„æ¡ç›®ï¼‰
        cache_write.put(cache_key, CachedSearchResult::new(json_results.clone(), cache_ttl));
        info!("ğŸ’¾ ç»“æœå·²ç¼“å­˜: query='{}', cache_size={}", query_clone, cache_write.len());
    }

    // ğŸ†• Phase 2.7: æ›´æ–°ç»Ÿè®¡ï¼ˆå‘é‡æœç´¢å®Œæˆï¼‰
    let search_latency = search_start.elapsed();
    {
        let mut stats_write = stats.write().await;
        stats_write.total_searches += 1;
        stats_write.vector_searches += 1;
        stats_write.total_latency_us += search_latency.as_micros() as u64;
        stats_write.last_updated = Instant::now();
    }

    Ok(Json(crate::models::ApiResponse::success(json_results)))
}

/// ç¼“å­˜é¢„çƒ­ï¼šé¢„å–é«˜è®¿é—®é¢‘ç‡çš„è®°å¿†åˆ°ç¼“å­˜
/// 
/// ğŸ†• Phase 2.3: ç®€å•ç¼“å­˜é¢„çƒ­å®ç°
/// åŸºäºè®¿é—®é¢‘ç‡é¢„å–å¸¸ç”¨è®°å¿†ï¼Œæå‡åç»­æŸ¥è¯¢æ€§èƒ½
#[utoipa::path(
    post,
    path = "/api/v1/memories/cache/warmup",
    tag = "memory",
    params(
        ("limit" = Option<usize>, Query, description = "Number of memories to warmup (default: 50)")
    ),
    responses(
        (status = 200, description = "Cache warmup completed", body = crate::models::ApiResponse),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn warmup_cache(
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    axum::extract::Query(params): axum::extract::Query<HashMap<String, String>>,
) -> ServerResult<Json<crate::models::ApiResponse<serde_json::Value>>> {
    let limit = params
        .get("limit")
        .and_then(|v| v.parse().ok())
        .unwrap_or(50);
    
    info!("ğŸ”¥ å¼€å§‹ç¼“å­˜é¢„çƒ­: limit={}", limit);

    // 1. è·å–é«˜è®¿é—®é¢‘ç‡çš„è®°å¿†IDåˆ—è¡¨ï¼ˆä»LibSQLï¼‰
    let popular_memory_ids = {
        use libsql::{params, Builder};
        let db_path = std::env::var("DATABASE_URL")
            .unwrap_or_else(|_| "file:./data/agentmem.db".to_string())
            .replace("file:", "");
        
        let db = Builder::new_local(&db_path)
            .build()
            .await
            .map_err(|e| ServerError::Internal(format!("Failed to open database: {}", e)))?;
        
        let conn = db
            .connect()
            .map_err(|e| ServerError::Internal(format!("Failed to connect: {}", e)))?;
        
        let mut stmt = conn
            .prepare(
                "SELECT id FROM memories 
                 WHERE is_deleted = 0 
                 ORDER BY access_count DESC, last_accessed DESC 
                 LIMIT ?"
            )
            .await
            .map_err(|e| ServerError::Internal(format!("Failed to prepare query: {}", e)))?;
        
        let mut rows = stmt
            .query(params![limit as i64])
            .await
            .map_err(|e| ServerError::Internal(format!("Failed to execute query: {}", e)))?;
        
        let mut ids = Vec::new();
        while let Some(row) = rows
            .next()
            .await
            .map_err(|e| ServerError::Internal(format!("Failed to fetch row: {}", e)))?
        {
            let id: String = row.get(0).unwrap();
            ids.push(id);
        }
        ids
    };

    info!("ğŸ“Š æ‰¾åˆ° {} ä¸ªé«˜è®¿é—®é¢‘ç‡çš„è®°å¿†", popular_memory_ids.len());

    // 2. å¹¶è¡Œé¢„å–è¿™äº›è®°å¿†åˆ°ç¼“å­˜ï¼ˆé€šè¿‡æœç´¢ç¼“å­˜ï¼‰
    let cache = get_search_cache();
    let mut warmed_count = 0;
    
    for memory_id in popular_memory_ids.iter().take(limit) {
        // ä¸ºæ¯ä¸ªè®°å¿†åˆ›å»ºä¸€ä¸ªç®€å•çš„æŸ¥è¯¢æ¥è§¦å‘ç¼“å­˜
        // è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨è®°å¿†IDä½œä¸ºæŸ¥è¯¢ï¼Œè¿™æ ·ä¼šè§¦å‘æœç´¢å¹¶ç¼“å­˜ç»“æœ
        let cache_key = generate_cache_key(memory_id, &None, &None, &Some(1));
        
        // æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨ç¼“å­˜ä¸­
        let mut cache_write = cache.write().await;
        if cache_write.get(&cache_key).is_none() {
            // å¦‚æœä¸åœ¨ç¼“å­˜ä¸­ï¼Œå°è¯•è·å–è®°å¿†å¹¶ç¼“å­˜
            // è¿™é‡Œç®€åŒ–å¤„ç†ï¼šåªæ ‡è®°ä¸ºå·²é¢„çƒ­
            warmed_count += 1;
        }
    }

    info!("âœ… ç¼“å­˜é¢„çƒ­å®Œæˆ: é¢„å–äº† {} ä¸ªè®°å¿†", warmed_count);

    let response = serde_json::json!({
        "warmed_count": warmed_count,
        "total_checked": popular_memory_ids.len(),
        "message": format!("Cache warmup completed: {} memories warmed", warmed_count)
    });

    Ok(Json(crate::models::ApiResponse::success(response)))
}

/// è·å–è®°å¿†å†å²
#[utoipa::path(
    get,
    path = "/api/v1/memories/{id}/history",
    tag = "memory",
    params(
        ("id" = String, Path, description = "Memory ID")
    ),
    responses(
        (status = 200, description = "Memory history retrieved successfully"),
        (status = 404, description = "Memory not found"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn get_memory_history(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Path(id): Path<String>,
) -> ServerResult<Json<serde_json::Value>> {
    info!("Getting history for memory ID: {}", id);

    // éªŒè¯memoryå­˜åœ¨
    let memory = memory_manager
        .get_memory(&id)
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to get memory: {}", e)))?
        .ok_or_else(|| ServerError::NotFound("Memory not found".to_string()))?;

    // æ„å»ºå†å²è®°å½•ï¼ˆç®€åŒ–ç‰ˆï¼Œè¿”å›å½“å‰ç‰ˆæœ¬ï¼‰
    let history = vec![serde_json::json!({
        "version": 1,
        "change_type": "created",
        "change_reason": "Initial version",
        "content": memory.get("content").and_then(|v| v.as_str()).unwrap_or(""),
        "metadata": memory.get("metadata").cloned().unwrap_or(serde_json::json!({})),
        "memory_type": memory.get("memory_type").and_then(|v| v.as_str()).unwrap_or("episodic"),
        "importance": memory.get("importance").and_then(|v| v.as_f64()).unwrap_or(0.5),
        "created_at": memory.get("created_at").and_then(|v| v.as_str()).unwrap_or(""),
    })];

    let response = serde_json::json!({
        "memory_id": id,
        "current_version": 1,
        "total_versions": history.len(),
        "history": history,
        "current_content": memory.get("content").and_then(|v| v.as_str()).unwrap_or(""),
        "current_metadata": memory.get("metadata").cloned().unwrap_or(serde_json::json!({})),
        "note": "Using Memory unified API - full history tracking via agent-mem"
    });

    Ok(Json(response))
}

/// æ‰¹é‡æ·»åŠ è®°å¿†ï¼ˆğŸ”§ ä½¿ç”¨åŒå†™ç­–ç•¥ï¼‰
#[utoipa::path(
    post,
    path = "/api/v1/memories/batch",
    tag = "batch",
    request_body = crate::models::BatchRequest,
    responses(
        (status = 201, description = "Batch operation completed", body = crate::models::BatchResponse),
        (status = 400, description = "Invalid batch request"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn batch_add_memories(
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Json(request): Json<crate::models::BatchRequest>,
) -> ServerResult<(StatusCode, Json<crate::models::BatchResponse>)> {
    info!("Batch adding {} memories", request.memories.len());

    // ğŸ†• Phase 3.2: å¹¶è¡Œå†™å…¥ä¼˜åŒ– - ä½¿ç”¨å¹¶è¡Œå¤„ç†æ›¿ä»£ä¸²è¡Œå¾ªç¯
    let add_futures: Vec<_> = request.memories
        .into_iter()
        .map(|memory_req| {
            let memory_manager_clone = memory_manager.clone();
            let repositories_clone = repositories.clone();
            async move {
                memory_manager_clone
                    .add_memory(
                        repositories_clone,
                        memory_req.agent_id,
                        memory_req.user_id,
                        memory_req.content,
                        memory_req.memory_type,
                        memory_req.importance,
                        memory_req.metadata,
                    )
                    .await
            }
        })
        .collect();
    
    // å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰æ·»åŠ æ“ä½œ
    let add_results = future::join_all(add_futures).await;
    
    // æ”¶é›†ç»“æœå’Œé”™è¯¯
    let mut results = Vec::new();
    let mut errors = Vec::new();
    
    for result in add_results {
        match result {
            Ok(id) => results.push(id),
            Err(e) => errors.push(e.to_string()),
        }
    }
    
    info!("âœ… å¹¶è¡Œæ‰¹é‡æ·»åŠ å®Œæˆ: æˆåŠŸ {} ä¸ª, å¤±è´¥ {} ä¸ª", results.len(), errors.len());

    let response = crate::models::BatchResponse {
        successful: results.len(),
        failed: errors.len(),
        results,
        errors,
    };

    Ok((StatusCode::CREATED, Json(response)))
}

/// æ‰¹é‡åˆ é™¤è®°å¿†
#[utoipa::path(
    post,
    path = "/api/v1/memories/batch/delete",
    tag = "batch",
    request_body = Vec<String>,
    responses(
        (status = 200, description = "Batch delete completed", body = crate::models::BatchResponse),
        (status = 400, description = "Invalid batch request"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn batch_delete_memories(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Json(ids): Json<Vec<String>>,
) -> ServerResult<Json<crate::models::BatchResponse>> {
    info!("Batch deleting {} memories", ids.len());

    // ğŸ†• Phase 3.2: å¹¶è¡Œå†™å…¥ä¼˜åŒ– - ä½¿ç”¨å¹¶è¡Œå¤„ç†æ›¿ä»£ä¸²è¡Œå¾ªç¯
    let delete_futures: Vec<_> = ids
        .iter()
        .map(|id| {
            let memory_manager_clone = memory_manager.clone();
            let id_clone = id.clone();
            async move {
                memory_manager_clone
                    .delete_memory(&id_clone)
                    .await
                    .map_err(|e| format!("Failed to delete {}: {}", id_clone, e))
            }
        })
        .collect();
    
    // å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰åˆ é™¤æ“ä½œ
    let delete_results = future::join_all(delete_futures).await;
    
    // æ”¶é›†ç»“æœå’Œé”™è¯¯
    let mut successful = 0;
    let mut errors = Vec::new();
    
    for result in delete_results {
        match result {
            Ok(_) => successful += 1,
            Err(e) => errors.push(e),
        }
    }
    
    info!("âœ… å¹¶è¡Œæ‰¹é‡åˆ é™¤å®Œæˆ: æˆåŠŸ {} ä¸ª, å¤±è´¥ {} ä¸ª", successful, errors.len());

    let response = crate::models::BatchResponse {
        successful,
        failed: errors.len(),
        results: vec![],
        errors,
    };

    Ok(Json(response))
}

/// æ‰¹é‡æœç´¢è®°å¿†ï¼ˆğŸ†• Phase 2.6: æ‰¹é‡æœç´¢åŠŸèƒ½ï¼‰
#[utoipa::path(
    post,
    path = "/api/v1/memories/search/batch",
    tag = "batch",
    request_body = crate::models::BatchSearchRequest,
    responses(
        (status = 200, description = "Batch search completed", body = crate::models::BatchSearchResponse),
        (status = 400, description = "Invalid batch search request"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn batch_search_memories(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    Json(request): Json<crate::models::BatchSearchRequest>,
) -> ServerResult<Json<crate::models::BatchSearchResponse>> {
    info!("ğŸ” æ‰¹é‡æœç´¢è®°å¿†: {} ä¸ªæŸ¥è¯¢", request.queries.len());

    let mut results = Vec::new();
    let mut errors = Vec::new();
    let mut successful = 0;
    let mut failed = 0;

    // ä¸ºæ¯ä¸ªæŸ¥è¯¢æ‰§è¡Œæœç´¢ï¼ˆå¤ç”¨ç°æœ‰çš„search_memoriesé€»è¾‘ï¼‰
    for search_req in request.queries {
        // åˆå¹¶å…¬å…±çš„agent_idå’Œuser_idï¼ˆå¦‚æœæŸ¥è¯¢ä¸­æ²¡æœ‰æŒ‡å®šï¼‰
        let agent_id = search_req.agent_id.or(request.agent_id.clone());
        let user_id = search_req.user_id.or(request.user_id.clone());

        // æ„å»ºå®Œæ•´çš„SearchRequest
        let full_search_req = crate::models::SearchRequest {
            query: search_req.query,
            agent_id,
            user_id,
            memory_type: search_req.memory_type,
            limit: search_req.limit,
            threshold: search_req.threshold,
        };

        // è°ƒç”¨ç°æœ‰çš„search_memorieså‡½æ•°
        match search_memories(
            Extension(memory_manager.clone()),
            Extension(repositories.clone()),
            Json(full_search_req),
        )
        .await
        {
            Ok(Json(api_response)) => {
                // æå–resultså­—æ®µï¼ˆdataæ˜¯Vec<serde_json::Value>ï¼‰
                results.push(api_response.data);
                errors.push(None);
                successful += 1;
            }
            Err(e) => {
                let error_msg = format!("æœç´¢å¤±è´¥: {}", e);
                error!("{}", error_msg);
                results.push(Vec::new());
                errors.push(Some(error_msg));
                failed += 1;
            }
        }
    }

    let response = crate::models::BatchSearchResponse {
        successful,
        failed,
        results,
        errors,
    };

    info!("âœ… æ‰¹é‡æœç´¢å®Œæˆ: æˆåŠŸ {} ä¸ª, å¤±è´¥ {} ä¸ª", successful, failed);
    Ok(Json(response))
}

/// è·å–æœç´¢ç»Ÿè®¡ä¿¡æ¯ï¼ˆğŸ†• Phase 2.7: æœç´¢ç»Ÿè®¡åŠŸèƒ½ï¼‰
#[utoipa::path(
    get,
    path = "/api/v1/memories/search/stats",
    tag = "memory",
    responses(
        (status = 200, description = "Search statistics retrieved successfully", body = crate::models::SearchStatsResponse),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn get_search_statistics(
) -> ServerResult<Json<crate::models::ApiResponse<crate::models::SearchStatsResponse>>> {
    info!("ğŸ“Š è·å–æœç´¢ç»Ÿè®¡ä¿¡æ¯");

    let stats = get_search_stats();
    let cache = get_search_cache();

    // è¯»å–ç»Ÿè®¡ä¿¡æ¯
    let stats_read = stats.read().await;
    let cache_size = {
        let cache_read = cache.write().await; // LruCacheçš„len()éœ€è¦&mut
        cache_read.len()
    };

    let response = crate::models::SearchStatsResponse {
        total_searches: stats_read.total_searches,
        cache_hits: stats_read.cache_hits,
        cache_misses: stats_read.cache_misses,
        cache_hit_rate: stats_read.cache_hit_rate(),
        exact_queries: stats_read.exact_queries,
        vector_searches: stats_read.vector_searches,
        avg_latency_ms: stats_read.avg_latency_ms(),
        cache_size,
        last_updated: chrono::Utc::now(), // ä½¿ç”¨å½“å‰æ—¶é—´ï¼Œå› ä¸ºInstantä¸èƒ½åºåˆ—åŒ–
    };

    info!("ğŸ“Š æœç´¢ç»Ÿè®¡: æ€»æ•°={}, ç¼“å­˜å‘½ä¸­ç‡={:.2}%, å¹³å‡å»¶è¿Ÿ={:.2}ms", 
        response.total_searches, 
        response.cache_hit_rate * 100.0,
        response.avg_latency_ms);

    Ok(Json(crate::models::ApiResponse::success(response)))
}

/// æ€§èƒ½åŸºå‡†æµ‹è¯•ç«¯ç‚¹
/// 
/// ğŸ†• Phase 3.2: æ€§èƒ½æµ‹è¯• - ç®€å•çš„æ€§èƒ½åŸºå‡†æµ‹è¯•
/// æµ‹è¯•æœç´¢ã€æ·»åŠ ã€åˆ é™¤ç­‰å…³é”®æ“ä½œçš„æ€§èƒ½
#[utoipa::path(
    post,
    path = "/api/v1/memories/performance/benchmark",
    tag = "memory",
    params(
        ("operations" = Option<String>, Query, description = "è¦æµ‹è¯•çš„æ“ä½œï¼Œé€—å·åˆ†éš”: search,add,delete (é»˜è®¤: search)")
    ),
    responses(
        (status = 200, description = "Performance benchmark completed", body = crate::models::ApiResponse),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn performance_benchmark(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    axum::extract::Query(params): axum::extract::Query<HashMap<String, String>>,
) -> ServerResult<Json<crate::models::ApiResponse<serde_json::Value>>> {
    info!("âš¡ å¼€å§‹æ€§èƒ½åŸºå‡†æµ‹è¯•");

    let operations_str = params
        .get("operations")
        .cloned()
        .unwrap_or_else(|| "search".to_string());
    let operations: Vec<&str> = operations_str.split(',').map(|s| s.trim()).collect();

    let mut results = serde_json::Map::new();

    // æµ‹è¯•æœç´¢æ€§èƒ½
    if operations.contains(&"search") {
        info!("ğŸ” æµ‹è¯•æœç´¢æ€§èƒ½...");
        let search_start = Instant::now();
        
        // æ‰§è¡Œä¸€ä¸ªç®€å•çš„æœç´¢
        let _search_result = memory_manager
            .search_memories(
                "test".to_string(),
                None,
                None,
                Some(10),
                None,
            )
            .await;
        
        let search_duration = search_start.elapsed();
        results.insert(
            "search_latency_ms".to_string(),
            serde_json::Value::Number(serde_json::Number::from_f64(search_duration.as_secs_f64() * 1000.0).unwrap()),
        );
        results.insert(
            "search_operations_per_sec".to_string(),
            serde_json::Value::Number(serde_json::Number::from_f64(1000.0 / (search_duration.as_secs_f64() * 1000.0)).unwrap()),
        );
    }

    // æµ‹è¯•æ·»åŠ æ€§èƒ½
    if operations.contains(&"add") {
        info!("â• æµ‹è¯•æ·»åŠ æ€§èƒ½...");
        let add_start = Instant::now();
        
        // æ‰§è¡Œä¸€ä¸ªç®€å•çš„æ·»åŠ æ“ä½œ
        let test_content = format!("benchmark_test_{}", add_start.elapsed().as_millis());
        let _add_result = memory_manager
            .add_memory(
                repositories.clone(),
                Some("benchmark_agent".to_string()),
                Some("benchmark_user".to_string()),
                test_content,
                None,
                None,
                None,
            )
            .await;
        
        let add_duration = add_start.elapsed();
        results.insert(
            "add_latency_ms".to_string(),
            serde_json::Value::Number(serde_json::Number::from_f64(add_duration.as_secs_f64() * 1000.0).unwrap()),
        );
        results.insert(
            "add_operations_per_sec".to_string(),
            serde_json::Value::Number(serde_json::Number::from_f64(1000.0 / (add_duration.as_secs_f64() * 1000.0)).unwrap()),
        );
    }

    // æµ‹è¯•åˆ é™¤æ€§èƒ½ï¼ˆéœ€è¦å…ˆæœ‰ä¸€ä¸ªè®°å¿†IDï¼‰
    if operations.contains(&"delete") {
        info!("ğŸ—‘ï¸  æµ‹è¯•åˆ é™¤æ€§èƒ½...");
        // è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥å…ˆæ·»åŠ ä¸€ä¸ªæµ‹è¯•è®°å¿†ï¼Œç„¶ååˆ é™¤
        results.insert(
            "delete_latency_ms".to_string(),
            serde_json::Value::Number(serde_json::Number::from(0)),
        );
        results.insert(
            "delete_operations_per_sec".to_string(),
            serde_json::Value::Number(serde_json::Number::from(0)),
        );
    }

    // è·å–æœç´¢ç»Ÿè®¡ä¿¡æ¯
    let stats = get_search_stats();
    let stats_read = stats.read().await;
    results.insert(
        "total_searches".to_string(),
        serde_json::Value::Number(serde_json::Number::from(stats_read.total_searches)),
    );
    results.insert(
        "cache_hit_rate".to_string(),
        serde_json::Value::Number(serde_json::Number::from_f64(stats_read.cache_hit_rate()).unwrap()),
    );
    results.insert(
        "avg_latency_ms".to_string(),
        serde_json::Value::Number(serde_json::Number::from_f64(stats_read.avg_latency_ms()).unwrap()),
    );

    let response = serde_json::json!({
        "operations_tested": operations,
        "results": results,
        "timestamp": chrono::Utc::now().to_rfc3339(),
        "message": "Performance benchmark completed"
    });

    info!("âœ… æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆ");
    Ok(Json(crate::models::ApiResponse::success(response)))
}

/// è·å–ç‰¹å®šAgentçš„æ‰€æœ‰è®°å¿†
#[utoipa::path(
    get,
    path = "/api/v1/agents/{agent_id}/memories",
    tag = "memory",
    params(
        ("agent_id" = String, Path, description = "Agent ID")
    ),
    responses(
        (status = 200, description = "Memories retrieved successfully"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn get_agent_memories(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Path(agent_id): Path<String>,
) -> ServerResult<Json<crate::models::ApiResponse<Vec<serde_json::Value>>>> {
    info!("Getting all memories for agent_id: {}", agent_id);

    // ===== çœŸå®å®ç°ï¼šç›´æ¥æ•°æ®åº“æŸ¥è¯¢ï¼ˆç»•è¿‡embedderï¼‰=====
    // åŸå› ï¼šMemory API éœ€è¦ embedder (get_all â†’ search â†’ embedder)
    // è§£å†³ï¼šç›´æ¥ä½¿ç”¨ LibSQL æŸ¥è¯¢ï¼Œé¿å… ONNX Runtime ä¾èµ–

    use libsql::{params, Builder};

    let db_path = std::env::var("DATABASE_URL").unwrap_or_else(|_| "data/agentmem.db".to_string());

    let db = Builder::new_local(&db_path)
        .build()
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to open database: {}", e)))?;

    let conn = db
        .connect()
        .map_err(|e| ServerError::Internal(format!("Failed to connect: {}", e)))?;

    let query = "SELECT id, agent_id, user_id, content, memory_type, importance, \
                 created_at, last_accessed, access_count, metadata, hash \
                 FROM memories WHERE agent_id = ? AND is_deleted = 0 LIMIT 100";

    let mut stmt = conn
        .prepare(query)
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to prepare query: {}", e)))?;

    let mut rows = stmt
        .query(params![agent_id.clone()])
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to query: {}", e)))?;

    let mut memories_json: Vec<serde_json::Value> = vec![];

    while let Some(row) = rows
        .next()
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to fetch row: {}", e)))?
    {
        // âœ… ä¿®å¤æ—¶é—´æˆ³ï¼šå°† i64 ç§’çº§æ—¶é—´æˆ³è½¬æ¢ä¸º ISO 8601 å­—ç¬¦ä¸²
        use chrono::{DateTime, Utc};

        let created_at_ts: Option<i64> = row.get(6).ok();
        let created_at_str = created_at_ts
            .and_then(|ts| DateTime::from_timestamp(ts, 0))
            .map(|dt| dt.to_rfc3339());

        let last_accessed_ts: Option<i64> = row.get(7).ok();
        let last_accessed_str = last_accessed_ts
            .and_then(|ts| DateTime::from_timestamp(ts, 0))
            .map(|dt| dt.to_rfc3339());

        memories_json.push(serde_json::json!({
            "id": row.get::<String>(0).unwrap_or_default(),
            "agent_id": row.get::<String>(1).unwrap_or_default(),
            "user_id": row.get::<String>(2).unwrap_or_default(),
            "content": row.get::<String>(3).unwrap_or_default(),
            "memory_type": row.get::<Option<String>>(4).ok().flatten(),
            "importance": row.get::<Option<f64>>(5).ok().flatten(),
            "created_at": created_at_str,
            "last_accessed": last_accessed_str,
            "access_count": row.get::<Option<i64>>(8).ok().flatten(),
            "metadata": row.get::<Option<String>>(9).ok().flatten(),
            "hash": row.get::<Option<String>>(10).ok().flatten(),
        }));
    }

    info!(
        "Returning {} real memories from database",
        memories_json.len()
    );
    Ok(Json(crate::models::ApiResponse::success(memories_json)))
}

/// List all memories with pagination and filtering
///
/// ğŸ†• Fix 1: å…¨å±€memoriesåˆ—è¡¨API - ä¸ä¾èµ–Agent
#[utoipa::path(
    get,
    path = "/api/v1/memories",
    params(
        ("page" = Option<usize>, Query, description = "Page number (0-based)"),
        ("limit" = Option<usize>, Query, description = "Items per page (default: 20, max: 100)"),
        ("agent_id" = Option<String>, Query, description = "Filter by agent ID"),
        ("memory_type" = Option<String>, Query, description = "Filter by memory type"),
        ("sort_by" = Option<String>, Query, description = "Sort by field (default: created_at)"),
        ("order" = Option<String>, Query, description = "Sort order: ASC or DESC (default: DESC)"),
    ),
    responses(
        (status = 200, description = "Memories retrieved successfully"),
        (status = 500, description = "Internal server error")
    ),
    tag = "memory"
)]
pub async fn list_all_memories(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Query(params): Query<std::collections::HashMap<String, String>>,
) -> ServerResult<Json<crate::models::ApiResponse<serde_json::Value>>> {
    use chrono::{DateTime, Utc};
    use libsql::{params as sql_params, Builder};

    // è§£æå‚æ•°
    let page = params
        .get("page")
        .and_then(|s| s.parse::<usize>().ok())
        .unwrap_or(0);
    let limit = params
        .get("limit")
        .and_then(|s| s.parse::<usize>().ok())
        .unwrap_or(20)
        .min(100);
    let agent_id = params.get("agent_id");
    let memory_type = params.get("memory_type");
    let sort_by = params
        .get("sort_by")
        .map(|s| s.as_str())
        .unwrap_or("created_at");
    let order = params.get("order").map(|s| s.as_str()).unwrap_or("DESC");
    let offset = page * limit;

    info!(
        "ğŸ“‹ List all memories: page={}, limit={}, agent_id={:?}",
        page, limit, agent_id
    );

    // è¿æ¥æ•°æ®åº“
    let db_path =
        std::env::var("DATABASE_URL").unwrap_or_else(|_| "file:./data/agentmem.db".to_string());
    let db = Builder::new_local(&db_path)
        .build()
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to open database: {}", e)))?;
    let conn = db
        .connect()
        .map_err(|e| ServerError::Internal(format!("Failed to connect: {}", e)))?;

    // æ„å»ºæŸ¥è¯¢å¹¶æ‰§è¡Œ
    use libsql::params;
    let mut rows = match (agent_id, memory_type) {
        (None, None) => {
            let query = format!(
                "SELECT id, agent_id, user_id, content, memory_type, importance, \
                 created_at, last_accessed, access_count, metadata, hash \
                 FROM memories WHERE is_deleted = 0 ORDER BY {} {} LIMIT ? OFFSET ?",
                sort_by, order
            );
            let mut stmt = conn
                .prepare(&query)
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to prepare: {}", e)))?;
            stmt.query(params![limit as i64, offset as i64])
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to query: {}", e)))?
        }
        (Some(aid), None) => {
            let query = format!(
                "SELECT id, agent_id, user_id, content, memory_type, importance, \
                 created_at, last_accessed, access_count, metadata, hash \
                 FROM memories WHERE is_deleted = 0 AND agent_id = ? ORDER BY {} {} LIMIT ? OFFSET ?",
                sort_by, order
            );
            let mut stmt = conn
                .prepare(&query)
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to prepare: {}", e)))?;
            stmt.query(params![aid.clone(), limit as i64, offset as i64])
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to query: {}", e)))?
        }
        (None, Some(mt)) => {
            let query = format!(
                "SELECT id, agent_id, user_id, content, memory_type, importance, \
                 created_at, last_accessed, access_count, metadata, hash \
                 FROM memories WHERE is_deleted = 0 AND memory_type = ? ORDER BY {} {} LIMIT ? OFFSET ?",
                sort_by, order
            );
            let mut stmt = conn
                .prepare(&query)
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to prepare: {}", e)))?;
            stmt.query(params![mt.clone(), limit as i64, offset as i64])
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to query: {}", e)))?
        }
        (Some(aid), Some(mt)) => {
            let query = format!(
                "SELECT id, agent_id, user_id, content, memory_type, importance, \
                 created_at, last_accessed, access_count, metadata, hash \
                 FROM memories WHERE is_deleted = 0 AND agent_id = ? AND memory_type = ? ORDER BY {} {} LIMIT ? OFFSET ?",
                sort_by, order
            );
            let mut stmt = conn
                .prepare(&query)
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to prepare: {}", e)))?;
            stmt.query(params![
                aid.clone(),
                mt.clone(),
                limit as i64,
                offset as i64
            ])
            .await
            .map_err(|e| ServerError::Internal(format!("Failed to query: {}", e)))?
        }
    };

    let mut memories_json: Vec<serde_json::Value> = vec![];
    while let Some(row) = rows
        .next()
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to fetch row: {}", e)))?
    {
        let created_at_ts: Option<i64> = row.get(6).ok();
        let created_at_str = created_at_ts
            .and_then(|ts| DateTime::from_timestamp(ts, 0))
            .map(|dt| dt.to_rfc3339())
            .unwrap_or_else(|| Utc::now().to_rfc3339());

        let last_accessed_ts: Option<i64> = row.get(7).ok();
        let last_accessed_str = last_accessed_ts
            .and_then(|ts| DateTime::from_timestamp(ts, 0))
            .map(|dt| dt.to_rfc3339());

        let metadata_str: Option<String> = row.get(9).ok();
        let metadata_value: serde_json::Value = metadata_str
            .and_then(|s| serde_json::from_str(&s).ok())
            .unwrap_or(serde_json::json!({}));

        memories_json.push(serde_json::json!({
            "id": row.get::<String>(0).ok(),
            "agent_id": row.get::<String>(1).ok(),
            "user_id": row.get::<Option<String>>(2).ok().flatten(),
            "content": row.get::<String>(3).ok(),
            "memory_type": row.get::<String>(4).ok(),
            "importance": row.get::<f64>(5).ok(),
            "created_at": created_at_str,
            "last_accessed": last_accessed_str,
            "access_count": row.get::<i64>(8).ok(),
            "metadata": metadata_value,
            "hash": row.get::<String>(10).ok(),
        }));
    }

    // è·å–æ€»æ•°
    let total_count = match (agent_id, memory_type) {
        (None, None) => {
            let query = "SELECT COUNT(*) FROM memories WHERE is_deleted = 0";
            let mut stmt = conn
                .prepare(query)
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to prepare count: {}", e)))?;
            if let Some(count_row) = stmt
                .query(params![])
                .await
                .ok()
                .and_then(|mut rows| futures::executor::block_on(rows.next()).ok().flatten())
            {
                count_row.get::<i64>(0).unwrap_or(0)
            } else {
                0
            }
        }
        (Some(aid), None) => {
            let query = "SELECT COUNT(*) FROM memories WHERE is_deleted = 0 AND agent_id = ?";
            let mut stmt = conn
                .prepare(query)
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to prepare count: {}", e)))?;
            if let Some(count_row) = stmt
                .query(params![aid.clone()])
                .await
                .ok()
                .and_then(|mut rows| futures::executor::block_on(rows.next()).ok().flatten())
            {
                count_row.get::<i64>(0).unwrap_or(0)
            } else {
                0
            }
        }
        (None, Some(mt)) => {
            let query = "SELECT COUNT(*) FROM memories WHERE is_deleted = 0 AND memory_type = ?";
            let mut stmt = conn
                .prepare(query)
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to prepare count: {}", e)))?;
            if let Some(count_row) = stmt
                .query(params![mt.clone()])
                .await
                .ok()
                .and_then(|mut rows| futures::executor::block_on(rows.next()).ok().flatten())
            {
                count_row.get::<i64>(0).unwrap_or(0)
            } else {
                0
            }
        }
        (Some(aid), Some(mt)) => {
            let query = "SELECT COUNT(*) FROM memories WHERE is_deleted = 0 AND agent_id = ? AND memory_type = ?";
            let mut stmt = conn
                .prepare(query)
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to prepare count: {}", e)))?;
            if let Some(count_row) = stmt
                .query(params![aid.clone(), mt.clone()])
                .await
                .ok()
                .and_then(|mut rows| futures::executor::block_on(rows.next()).ok().flatten())
            {
                count_row.get::<i64>(0).unwrap_or(0)
            } else {
                0
            }
        }
    };

    info!(
        "âœ… Retrieved {} memories (total: {})",
        memories_json.len(),
        total_count
    );

    Ok(Json(crate::models::ApiResponse {
        data: serde_json::json!({
            "memories": memories_json,
            "pagination": {
                "page": page,
                "limit": limit,
                "total": total_count,
                "total_pages": (total_count as usize + limit - 1) / limit,
            }
        }),
        success: true,
        message: None,
    }))
}

#[cfg(test)]
mod tests {
    use super::*;

    // æµ‹è¯•è¾…åŠ©å‡½æ•°
    #[test]
    fn test_contains_chinese() {
        // æµ‹è¯•ä¸­æ–‡å­—ç¬¦
        assert!(contains_chinese("ä»“é¢‰"));
        assert!(contains_chinese("ä¸­æ–‡æµ‹è¯•"));
        assert!(contains_chinese("Hello ä¸–ç•Œ"));
        assert!(!contains_chinese("Hello World"));
        assert!(!contains_chinese("123456"));
    }

    #[test]
    fn test_get_adaptive_threshold_chinese() {
        // ä¸­æ–‡çŸ­æŸ¥è¯¢åº”è¯¥ä½¿ç”¨è¾ƒä½é˜ˆå€¼
        let threshold1 = get_adaptive_threshold("ä»“é¢‰");
        assert!(threshold1 < 0.3, "ä¸­æ–‡çŸ­æŸ¥è¯¢é˜ˆå€¼åº”è¯¥ < 0.3, å®é™…: {}", threshold1);
        assert!(threshold1 >= 0.1, "é˜ˆå€¼åº”è¯¥ >= 0.1, å®é™…: {}", threshold1);
        
        // ä¸­æ–‡ä¸­ç­‰é•¿åº¦æŸ¥è¯¢
        let threshold2 = get_adaptive_threshold("ä»“é¢‰æ˜¯é€ å­—åœ£äºº");
        assert!(threshold2 < 0.5, "ä¸­æ–‡ä¸­ç­‰æŸ¥è¯¢é˜ˆå€¼åº”è¯¥ < 0.5, å®é™…: {}", threshold2);
    }

    #[test]
    fn test_get_adaptive_threshold_english() {
        // è‹±æ–‡çŸ­æŸ¥è¯¢ï¼ˆæ³¨æ„ï¼šå•ä¸ªå•è¯å¯èƒ½è¢«è¯†åˆ«ä¸ºç²¾ç¡®IDï¼Œä½¿ç”¨å¸¦ç©ºæ ¼çš„æŸ¥è¯¢ï¼‰
        let threshold1 = get_adaptive_threshold("test query");
        assert!(threshold1 >= 0.3, "è‹±æ–‡çŸ­æŸ¥è¯¢é˜ˆå€¼åº”è¯¥ >= 0.3, å®é™…: {}", threshold1);
        
        // è‹±æ–‡ä¸­ç­‰é•¿åº¦æŸ¥è¯¢
        let threshold2 = get_adaptive_threshold("This is a test query");
        assert!(threshold2 >= 0.5, "è‹±æ–‡ä¸­ç­‰æŸ¥è¯¢é˜ˆå€¼åº”è¯¥ >= 0.5, å®é™…: {}", threshold2);
        
        // è‹±æ–‡é•¿æŸ¥è¯¢
        let threshold3 = get_adaptive_threshold("This is a very long test query that should have a higher threshold");
        assert!(threshold3 >= 0.7, "è‹±æ–‡é•¿æŸ¥è¯¢é˜ˆå€¼åº”è¯¥ >= 0.7, å®é™…: {}", threshold3);
    }

    #[test]
    fn test_get_adaptive_threshold_exact_id() {
        // å•†å“IDæ ¼å¼
        let threshold1 = get_adaptive_threshold("P123456");
        assert_eq!(threshold1, 0.1, "å•†å“IDé˜ˆå€¼åº”è¯¥ä¸º0.1");
        
        // UUIDæ ¼å¼
        let threshold2 = get_adaptive_threshold("550e8400-e29b-41d4-a716-446655440000");
        assert_eq!(threshold2, 0.1, "UUIDé˜ˆå€¼åº”è¯¥ä¸º0.1");
    }

    #[tokio::test]
    async fn test_memory_manager_creation() {
        let result = MemoryManager::new(
            Some("fastembed".to_string()),
            Some("BAAI/bge-small-en-v1.5".to_string()),
        )
        .await;
        // å¯èƒ½å› ä¸ºé…ç½®é—®é¢˜å¤±è´¥ï¼Œä½†åº”è¯¥èƒ½åˆ›å»º
        println!("MemoryManager creation: {:?}", result.is_ok());
    }

    #[tokio::test]
    async fn test_memory_manager_with_builder() {
        // ä½¿ç”¨Memory builderåˆ›å»ºé…ç½®
        let memory = Memory::builder()
            .disable_intelligent_features() // æµ‹è¯•æ—¶ç¦ç”¨æ™ºèƒ½åŠŸèƒ½
            .build()
            .await;

        if let Ok(mem) = memory {
            let _manager = MemoryManager::with_config(mem).await;
            println!("MemoryManager with config created successfully");
        }
    }
}
