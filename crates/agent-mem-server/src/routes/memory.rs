//! Memory management routes - Unified Memory API version
//!
//! æ¶æ„ä¼˜åŒ–ï¼šä½¿ç”¨agent-memçš„Memoryç»Ÿä¸€APIæ›¿ä»£agent-mem-coreçš„CoreMemoryManager
//! ä¼˜åŠ¿ï¼š
//! - æ›´ç®€æ´çš„ä»£ç 
//! - ç»Ÿä¸€çš„æ¥å£
//! - è‡ªåŠ¨çš„æ™ºèƒ½åŠŸèƒ½
//! - æ›´å¥½çš„ç±»å‹å¤„ç†
//!
//! æ³¨æ„ï¼šæœ¬æ¨¡å—å†…éƒ¨ä½¿ç”¨ MemoryItem ç”¨äºå‘åå…¼å®¹ï¼Œæœªæ¥ç‰ˆæœ¬å°†è¿ç§»åˆ° Memory V4
//!
//! ğŸ†• æ¨¡å—æ‹†åˆ†ï¼ˆ2025-12-10ï¼‰ï¼š
//! - memory/cache.rs: æŸ¥è¯¢ç»“æœç¼“å­˜é€»è¾‘
//! - memory/stats.rs: æœç´¢ç»Ÿè®¡é€»è¾‘
//! - è·¯ç”±å¤„ç†å‡½æ•°ä¿ç•™åœ¨æ­¤æ–‡ä»¶ä¸­ï¼ˆæœªæ¥å¯è¿›ä¸€æ­¥æ‹†åˆ†åˆ° handlers.rsï¼‰

// ä½¿ç”¨æ‹†åˆ†çš„æ¨¡å—ï¼ˆä½œä¸ºå­æ¨¡å—ï¼‰
#[path = "memory/cache.rs"]
mod cache;
#[path = "memory/stats.rs"]
mod stats;
#[path = "memory/utils.rs"]
mod utils;

// é‡æ–°å¯¼å‡ºä»¥ä¾¿å‘åå…¼å®¹
pub use cache::{get_search_cache, generate_cache_key, CachedSearchResult};
pub use stats::{get_search_stats, SearchStatistics};
pub use utils::{
    truncate_string_at_char_boundary, contains_chinese, calculate_recency_score,
    calculate_3d_score, calculate_quality_score, get_adaptive_threshold,
    detect_exact_query, convert_memory_to_json, calculate_access_pattern_score,
    calculate_auto_importance, apply_hierarchical_sorting, apply_intelligent_filtering,
    compute_prefetch_candidates,
};

use crate::{
    error::{ServerError, ServerResult},
    models::{
        BatchRequest, BatchResponse, BatchSearchRequest, BatchSearchResponse, MemoryRequest,
        MemoryResponse, SearchRequest, SearchResponse, UpdateMemoryRequest,
    },
};
use agent_mem::{AddMemoryOptions, DeleteAllOptions, GetAllOptions, Memory, SearchOptions};

// å†…éƒ¨ä½¿ç”¨ MemoryItem ç”¨äºå‘åå…¼å®¹ï¼ˆå·²åºŸå¼ƒï¼Œæœªæ¥å°†è¿ç§»åˆ° Memory V4ï¼‰
#[allow(deprecated)]
use agent_mem_traits::MemoryItem;
use std::collections::HashMap;
use std::hash::{Hash, Hasher};
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::RwLock;
use tokio::time::timeout;
use futures::future::{self, join_all};

/// Server-side memory manager wrapper (åŸºäºMemoryç»Ÿä¸€API)
pub struct MemoryManager {
    pub memory: Arc<Memory>,
    /// ğŸ†• Fix 2: æŸ¥è¯¢ä¼˜åŒ–å™¨
    query_optimizer: Arc<agent_mem_core::search::QueryOptimizer>,
    /// ğŸ†• Fix 2: ç»“æœé‡æ’åºå™¨ï¼ˆä½¿ç”¨rerankeræ¨¡å—çš„ResultRerankerï¼‰
    reranker: Arc<agent_mem_core::search::reranker::ResultReranker>,
}

impl MemoryManager {
    /// åˆ›å»ºæ–°çš„MemoryManagerï¼ˆä½¿ç”¨Memory API + LibSQLæŒä¹…åŒ– + Embedderé…ç½®ï¼‰
    pub async fn new(
        embedder_provider: Option<String>,
        embedder_model: Option<String>,
    ) -> ServerResult<Self> {
        use tracing::warn;

        info!("========================================");
        info!("ğŸ§  åˆå§‹åŒ– Memory ç»„ä»¶");
        info!("========================================");

        // ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨builderæ¨¡å¼æ˜¾å¼æŒ‡å®šLibSQLå­˜å‚¨ï¼Œè€Œä¸æ˜¯é»˜è®¤çš„å†…å­˜å­˜å‚¨
        // æ”¯æŒ memory:// URL æ ¼å¼ï¼ˆç”¨äºæµ‹è¯•ï¼Œé¿å…æ•°æ®åº“é”å®šï¼‰
        let db_path = std::env::var("DATABASE_URL")
            .unwrap_or_else(|_| "file:./data/agentmem.db".to_string());

        info!("ğŸ“¦ é…ç½®å­˜å‚¨å±‚");
        info!("  - æ•°æ®åº“ç±»å‹: LibSQL (SQLite)");
        info!("  - æ•°æ®åº“è·¯å¾„: {}", db_path);

        let mut builder = Memory::builder().with_storage(&db_path); // ğŸ”‘ å…³é”®ä¿®å¤ï¼šæ˜¾å¼æŒ‡å®šä½¿ç”¨LibSQL
                                                                    // âš ï¸ ä¸è®¾ç½® default_user_id å’Œ default_agent_id
                                                                    // å¼ºåˆ¶æ¯æ¬¡è°ƒç”¨æ—¶æ˜¾å¼ä¼ å…¥ï¼Œé¿å…è¢«é»˜è®¤å€¼è¦†ç›–

        // ğŸ”‘ å…³é”®ä¿®å¤ #2ï¼šé…ç½®Embedderï¼ˆP0é—®é¢˜ï¼‰
        info!("ğŸ”Œ é…ç½® Embedder (å‘é‡åµŒå…¥)");
        if let (Some(provider), Some(model)) = (embedder_provider.clone(), embedder_model.clone()) {
            info!("  - Provider: {}", provider);
            info!("  - Model: {}", model);
            builder = builder.with_embedder(provider, model);
        } else {
            // ä½¿ç”¨é»˜è®¤FastEmbedé…ç½®
            info!("  - Provider: fastembed (é»˜è®¤)");
            info!("  - Model: BAAI/bge-small-en-v1.5");
            builder = builder.with_embedder("fastembed", "BAAI/bge-small-en-v1.5");
        }

        // ğŸ”‘ å…³é”®ä¿®å¤ #3ï¼šé…ç½®VectorStoreï¼ˆå‘é‡æŒä¹…åŒ–ï¼‰
        // ä¿®å¤: ä¹‹å‰å‘é‡åªåœ¨å†…å­˜ä¸­ï¼Œé‡å¯åä¸¢å¤±
        // æ³¨æ„: LanceDBéœ€è¦åè®®å‰ç¼€ "lancedb://"ï¼Œè·¯å¾„éœ€è¦ä»¥.lanceç»“å°¾
        let vector_store_url = "lancedb://./data/vectors.lance";
        info!("ğŸ“Š é…ç½®å‘é‡å­˜å‚¨");
        info!("  - ç±»å‹: LanceDB");
        info!("  - è·¯å¾„: {}", vector_store_url);
        builder = builder.with_vector_store(vector_store_url);

        info!("â³ æ„å»º Memory å®ä¾‹...");
        warn!("âš ï¸  é¦–æ¬¡è¿è¡Œæ—¶ï¼ŒFastEmbed ä¼šä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼ˆçº¦ 100MBï¼‰");
        warn!("âš ï¸  è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...");
        warn!("âš ï¸  ä¸‹è½½è¿›åº¦ä¸ä¼šæ˜¾ç¤ºï¼Œä½†ç¨‹åºæ­£åœ¨è¿è¡Œä¸­");

        let memory = builder.build().await.map_err(|e| {
            ServerError::Internal(format!("Failed to create Memory with LibSQL: {}", e))
        })?;

        info!("âœ… Memory å®ä¾‹æ„å»ºæˆåŠŸ");

        // ğŸ†• Fix 2: åˆå§‹åŒ–QueryOptimizerå’ŒReranker
        info!("ğŸ” åˆå§‹åŒ–æœç´¢ä¼˜åŒ–ç»„ä»¶...");
        let query_optimizer = {
            use std::sync::RwLock;
            let stats = Arc::new(RwLock::new(
                agent_mem_core::search::IndexStatistics::default(),
            ));
            agent_mem_core::search::QueryOptimizer::with_default_config(stats)
        };

        let reranker = agent_mem_core::search::reranker::ResultReranker::with_default_config();

        info!("âœ… QueryOptimizer å’Œ Reranker åˆå§‹åŒ–å®Œæˆ");
        info!("========================================");
        info!("âœ… Memory ç»„ä»¶åˆå§‹åŒ–å®Œæˆï¼");
        info!("========================================");

        Ok(Self {
            memory: Arc::new(memory),
            query_optimizer: Arc::new(query_optimizer),
            reranker: Arc::new(reranker),
        })
    }

    /// ä½¿ç”¨è‡ªå®šä¹‰é…ç½®åˆ›å»º
    pub async fn with_config(memory: Memory) -> Self {
        // ğŸ†• Fix 2: åˆå§‹åŒ–QueryOptimizerå’ŒReranker
        let query_optimizer = {
            use std::sync::RwLock;
            let stats = Arc::new(RwLock::new(
                agent_mem_core::search::IndexStatistics::default(),
            ));
            agent_mem_core::search::QueryOptimizer::with_default_config(stats)
        };

        let reranker = agent_mem_core::search::reranker::ResultReranker::with_default_config();

        Self {
            memory: Arc::new(memory),
            query_optimizer: Arc::new(query_optimizer),
            reranker: Arc::new(reranker),
        }
    }

    /// æ·»åŠ è®°å¿†ï¼ˆğŸ”§ æœ€ä½³æ–¹æ¡ˆï¼šMemory API + LibSQL åŒå†™ï¼‰
    ///
    /// Strategy:
    /// 1. ä½¿ç”¨Memory APIç”Ÿæˆå‘é‡åµŒå…¥ï¼ˆä¿ç•™æ™ºèƒ½åŠŸèƒ½ï¼‰
    /// 2. åŒæ—¶å†™å…¥LibSQLç¡®ä¿æŒä¹…åŒ–
    /// 3. å‘é‡æœç´¢ä½¿ç”¨VectorStoreï¼Œç»“æ„åŒ–æŸ¥è¯¢ä½¿ç”¨LibSQL
    pub async fn add_memory(
        &self,
        repositories: Arc<agent_mem_core::storage::factory::Repositories>,
        agent_id: Option<String>,
        user_id: Option<String>,
        content: String,
        memory_type: Option<agent_mem_traits::MemoryType>,
        importance: Option<f32>,
        metadata: Option<HashMap<String, String>>,
    ) -> Result<String, String> {
        use agent_mem_utils::hash::compute_content_hash;
        use chrono::Utc;

        // âœ… ç”Ÿæˆæœ‰æ•ˆçš„ agent_id (å‚è€ƒmem0è®¾è®¡)
        let effective_agent_id = agent_id.unwrap_or_else(|| {
            if let Some(uid) = &user_id {
                format!("default-agent-{}", uid)
            } else {
                "default-agent".to_string()
            }
        });

        // Step 1: ä½¿ç”¨Memory APIï¼ˆç”Ÿæˆå‘é‡åµŒå…¥ï¼‰
        let options = AddMemoryOptions {
            agent_id: Some(effective_agent_id.clone()),
            user_id: user_id.clone(),
            infer: false, // ç®€å•æ¨¡å¼ï¼Œé¿å…å¤æ‚æ¨ç†
            metadata: metadata.clone().unwrap_or_default(),
            memory_type: memory_type.as_ref().map(|t| format!("{:?}", t)),
            ..Default::default()
        };

        let add_result = self
            .memory
            .add_with_options(&content, options)
            .await
            .map_err(|e| e.to_string())?;

        let memory_id = add_result
            .results
            .first()
            .map(|r| r.id.clone())
            .unwrap_or_else(|| uuid::Uuid::new_v4().to_string());

        // Step 2: å†™å…¥LibSQL Repositoryï¼ˆæŒä¹…åŒ–ï¼‰
        let user_id_val = user_id.unwrap_or_else(|| "default".to_string());
        let content_hash = compute_content_hash(&content);
        let now = Utc::now();

        // æ„å»ºmetadata JSON
        let mut full_metadata = metadata.unwrap_or_default();
        full_metadata.insert("agent_id".to_string(), effective_agent_id.clone());
        full_metadata.insert("user_id".to_string(), user_id_val.clone());
        full_metadata.insert("data".to_string(), content.clone());
        full_metadata.insert("hash".to_string(), content_hash.clone());

        // ğŸ†• Phase 2 Server: æå–scope_typeï¼ˆå¦‚æœæ²¡æœ‰åˆ™è‡ªåŠ¨æ¨æ–­ï¼‰
        // âœ… ä¿®å¤ä¼˜å…ˆçº§ï¼šuser_idä¼˜å…ˆäºsession_idï¼ˆç¬¦åˆagentmem61.mdè®¾è®¡ï¼‰
        let scope_type = full_metadata.get("scope_type").cloned().unwrap_or_else(|| {
            // è‡ªåŠ¨æ¨æ–­scopeç±»å‹ - æ­£ç¡®çš„ä¼˜å…ˆçº§
            // 1. å¦‚æœæœ‰user_idå’Œagent_idï¼ˆéé»˜è®¤ï¼‰ï¼Œè¿™æ˜¯é•¿æœŸè®°å¿†ï¼ˆAgent scopeï¼‰
            if user_id_val != "default"
                && effective_agent_id.starts_with("agent-")
                && effective_agent_id != "default-agent"
            {
                "agent".to_string()
            }
            // 2. å¦‚æœåªæœ‰user_idï¼ˆéé»˜è®¤ï¼‰ï¼Œè¿™æ˜¯ç”¨æˆ·è®°å¿†ï¼ˆUser scopeï¼‰
            else if user_id_val != "default" {
                "user".to_string()
            }
            // 3. å¦‚æœæœ‰session_idï¼Œè¿™æ˜¯å·¥ä½œè®°å¿†ï¼ˆSession scopeï¼‰
            else if full_metadata.contains_key("session_id") {
                "session".to_string()
            }
            // 4. å¦‚æœæœ‰run_id
            else if full_metadata.contains_key("run_id") {
                "run".to_string()
            }
            // 5. å¦‚æœæœ‰org_id
            else if full_metadata.contains_key("org_id") {
                "organization".to_string()
            }
            // 6. é»˜è®¤ä¸ºå…¨å±€
            else {
                "global".to_string()
            }
        });

        let metadata_json: serde_json::Value = full_metadata
            .into_iter()
            .map(|(k, v)| (k, serde_json::Value::String(v)))
            .collect();

        // Step 2.5: ç¡®ä¿Agentå­˜åœ¨ï¼ˆè·å–å…¶organization_idå’Œuser_idï¼‰
        // âœ… å¦‚æœagentä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼ˆå‚è€ƒmem0è®¾è®¡ï¼‰
        let agent_opt = repositories
            .agents
            .find_by_id(&effective_agent_id)
            .await
            .map_err(|e| format!("Failed to query agent: {}", e))?;

        let organization_id = agent_opt
            .as_ref()
            .map(|a| a.organization_id.clone())
            .unwrap_or_else(|| "default-org".to_string());

        let db_memory = agent_mem_core::storage::models::DbMemory {
            id: memory_id.clone(),
            organization_id,                // ä½¿ç”¨Agentçš„organization_idæˆ–é»˜è®¤å€¼
            user_id: "default".to_string(), // ä½¿ç”¨é»˜è®¤user (TODO: åº”è¯¥ä»authè·å–å®é™…user)
            agent_id: effective_agent_id.clone(),
            content,
            hash: Some(content_hash),
            metadata: metadata_json,
            score: None,
            memory_type: format!(
                "{:?}",
                memory_type.unwrap_or(agent_mem_traits::MemoryType::Semantic)
            ),
            scope: scope_type, // ğŸ†• Phase 2 Server: ä½¿ç”¨æ¨æ–­æˆ–æå–çš„scope_type
            level: "normal".to_string(),
            importance: importance.unwrap_or(0.5),
            access_count: 0,
            last_accessed: Some(now),
            created_at: now,
            updated_at: now,
            is_deleted: false,
            created_by_id: None,
            last_updated_by_id: None,
        };

        // è½¬æ¢ä¸º MemoryV4 ä»¥ä¾¿è°ƒç”¨ repository.create
        use agent_mem_core::storage::conversion::db_to_memory;
        let memory = db_to_memory(&db_memory)
            .map_err(|e| format!("Failed to convert to MemoryV4: {}", e))?;

        repositories
            .memories
            .create(&memory)
            .await
            .map_err(|e| format!("Failed to persist to LibSQL: {}", e))?;

        info!(
            "âœ… Memory persisted: VectorStore + LibSQL (ID: {})",
            memory_id
        );
        Ok(memory_id)
    }

    /// è·å–è®°å¿†ï¼ˆç›´æ¥æ•°æ®åº“æŸ¥è¯¢ï¼‰
    pub async fn get_memory(&self, id: &str) -> Result<Option<serde_json::Value>, String> {
        use libsql::{params, Builder};

        let db_path =
            std::env::var("DATABASE_URL").unwrap_or_else(|_| "data/agentmem.db".to_string());

        let db = Builder::new_local(&db_path)
            .build()
            .await
            .map_err(|e| format!("Failed to open database: {}", e))?;

        let conn = db
            .connect()
            .map_err(|e| format!("Failed to connect: {}", e))?;

        // ğŸ†• Phase 2 Server: æŸ¥è¯¢ä¸­åŒ…å«scopeå­—æ®µ
        let query = "SELECT id, agent_id, user_id, content, memory_type, importance, \
                     created_at, last_accessed, access_count, metadata, hash, scope \
                     FROM memories WHERE id = ? AND is_deleted = 0 LIMIT 1";

        let mut stmt = conn
            .prepare(query)
            .await
            .map_err(|e| format!("Failed to prepare query: {}", e))?;

        let mut rows = stmt
            .query(params![id])
            .await
            .map_err(|e| format!("Failed to query: {}", e))?;

        if let Some(row) = rows
            .next()
            .await
            .map_err(|e| format!("Failed to fetch row: {}", e))?
        {
            let memory_id = row.get::<String>(0).unwrap_or_default();
            
            // ğŸ†• Phase 2.11: è‡ªåŠ¨æ›´æ–°è®¿é—®ç»Ÿè®¡å’Œé‡è¦æ€§
            // æ›´æ–°access_countå’Œlast_accessed
            let now = chrono::Utc::now().timestamp();
            let current_access_count: i64 = row.get(8).unwrap_or(0);
            let new_access_count = current_access_count + 1;
            
            // åŸºäºè®¿é—®æ¨¡å¼è‡ªåŠ¨è°ƒæ•´importance
            let current_importance: f64 = row.get(5).unwrap_or(0.5);
            let last_accessed_ts: Option<i64> = row.get(7).ok();
            let new_importance = calculate_auto_importance(
                current_importance,
                new_access_count,
                last_accessed_ts,
            );
            
            // æ›´æ–°æ•°æ®åº“ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡è¿”å›ï¼‰
            let db_path_clone = db_path.clone();
            let id_clone = memory_id.clone();
            tokio::spawn(async move {
                if let Ok(update_db) = Builder::new_local(&db_path_clone).build().await {
                    if let Ok(update_conn) = update_db.connect() {
                        let update_query = "UPDATE memories SET access_count = ?, last_accessed = ?, importance = ?, updated_at = ? WHERE id = ?";
                        if let Ok(mut update_stmt) = update_conn.prepare(update_query).await {
                            let _ = update_stmt
                                .execute(params![new_access_count, now, new_importance, now, id_clone])
                                .await;
                        }
                    }
                }
            });
            
            // âœ… ä¿®å¤æ—¶é—´æˆ³ï¼šå°† i64 ç§’çº§æ—¶é—´æˆ³è½¬æ¢ä¸º ISO 8601 å­—ç¬¦ä¸²
            use chrono::{DateTime, Utc};

            let created_at_ts: Option<i64> = row.get(6).ok();
            let created_at_str = created_at_ts
                .and_then(|ts| DateTime::from_timestamp(ts, 0))
                .map(|dt| dt.to_rfc3339());

            // ä½¿ç”¨å½“å‰æ—¶é—´ä½œä¸ºlast_accessedï¼ˆå› ä¸ºåˆšåˆšæ›´æ–°ï¼‰
            let last_accessed_str = DateTime::from_timestamp(now, 0)
                .map(|dt| dt.to_rfc3339())
                .unwrap_or_else(|| Utc::now().to_rfc3339());

            let json = serde_json::json!({
                "id": memory_id,
                "agent_id": row.get::<String>(1).unwrap_or_default(),
                "user_id": row.get::<String>(2).unwrap_or_default(),
                "content": row.get::<String>(3).unwrap_or_default(),
                "memory_type": row.get::<Option<String>>(4).ok().flatten(),
                "importance": new_importance,  // ğŸ†• ä½¿ç”¨æ›´æ–°åçš„importance
                "created_at": created_at_str,
                "last_accessed_at": last_accessed_str,  // ğŸ†• ä½¿ç”¨å½“å‰æ—¶é—´
                "access_count": new_access_count,  // ğŸ†• ä½¿ç”¨æ›´æ–°åçš„access_count
                "metadata": row.get::<Option<String>>(9).ok().flatten(),
                "hash": row.get::<Option<String>>(10).ok().flatten(),
                "scope": row.get::<Option<String>>(11).ok().flatten(),  // ğŸ†• Phase 2 Server: è¿”å›scopeå­—æ®µ
            });
            Ok(Some(json))
        } else {
            Ok(None)
        }
    }

    /// æ›´æ–°è®°å¿†
    pub async fn update_memory(
        &self,
        id: &str,
        content: Option<String>,
        importance: Option<f32>,
        metadata: Option<HashMap<String, String>>,
    ) -> Result<(), String> {
        let mut update_data = HashMap::new();

        if let Some(c) = content {
            update_data.insert("content".to_string(), serde_json::json!(c));
        }
        if let Some(imp) = importance {
            update_data.insert("importance".to_string(), serde_json::json!(imp));
        }
        if let Some(meta) = metadata {
            // è½¬æ¢metadataä¸ºJSON
            let meta_json: HashMap<String, serde_json::Value> = meta
                .into_iter()
                .map(|(k, v)| (k, serde_json::Value::String(v)))
                .collect();
            update_data.insert("metadata".to_string(), serde_json::json!(meta_json));
        }

        self.memory
            .update(id, update_data)
            .await
            .map(|_| ())
            .map_err(|e| e.to_string())
    }

    /// åˆ é™¤è®°å¿†
    pub async fn delete_memory(&self, id: &str) -> Result<(), String> {
        self.memory.delete(id).await.map_err(|e| e.to_string())
    }

    /// æœç´¢è®°å¿† (ğŸ†• Fix 2: é›†æˆQueryOptimizerå’ŒReranker)
    pub async fn search_memories(
        &self,
        query: String,
        agent_id: Option<String>,
        user_id: Option<String>,
        limit: Option<usize>,
        _memory_type: Option<agent_mem_traits::MemoryType>,
    ) -> Result<Vec<MemoryItem>, String> {
        // ğŸ†• Fix 2: ä½¿ç”¨QueryOptimizerä¼˜åŒ–æŸ¥è¯¢
        use agent_mem_core::search::SearchQuery;
        let search_query = SearchQuery {
            query: query.clone(),
            limit: limit.unwrap_or(10),
            threshold: Some(0.7),
            vector_weight: 0.7,
            fulltext_weight: 0.3,
            filters: None,
            metadata_filters: None,
        };

        let optimized_plan = self
            .query_optimizer
            .optimize_query(&search_query)
            .map_err(|e| format!("Query optimization failed: {}", e))?;

        info!("ğŸš€ Query optimized: strategy={:?}, should_rerank={}, rerank_factor={}, estimated_latency={}ms", 
            optimized_plan.strategy, optimized_plan.should_rerank, optimized_plan.rerank_factor, 
            optimized_plan.estimated_latency_ms);

        // ğŸ†• Fix 2: ä½¿ç”¨ä¼˜åŒ–åçš„å‚æ•° - å¦‚æœéœ€è¦é‡æ’åºï¼Œå¢åŠ å€™é€‰æ•°é‡
        let base_limit = limit.unwrap_or(10);
        let fetch_limit = if optimized_plan.should_rerank {
            base_limit * optimized_plan.rerank_factor
        } else {
            base_limit
        };

        // ğŸ”§ æ™ºèƒ½é˜ˆå€¼è°ƒæ•´ï¼šæ ¹æ®æŸ¥è¯¢ç±»å‹åŠ¨æ€è®¾ç½®
        let dynamic_threshold = get_adaptive_threshold(&query);
        info!(
            "ğŸ“Š è‡ªé€‚åº”é˜ˆå€¼: query='{}', threshold={}",
            query, dynamic_threshold
        );

        let options = SearchOptions {
            user_id: user_id.clone(),
            limit: Some(fetch_limit),
            threshold: Some(dynamic_threshold),
            ..Default::default()
        };

        // æ‰§è¡Œæœç´¢
        let raw_results = self
            .memory
            .search_with_options(query.clone(), options)
            .await
            .map_err(|e| e.to_string())?;

        // ğŸ†• Phase 3-D: å¦‚æœéœ€è¦é‡æ’åºä¸”æœ‰ç»“æœï¼Œä½¿ç”¨Rerankerä¼˜åŒ–
        if optimized_plan.should_rerank && !raw_results.is_empty() && raw_results.len() > base_limit
        {
            // ä¿å­˜ç»“æœæ•°é‡ç”¨äºæ—¥å¿—
            let raw_count = raw_results.len();

            match self
                .apply_reranking(&query, &search_query, raw_results, base_limit)
                .await
            {
                Ok(reranked) => {
                    info!(
                        "âœ¨ Reranking applied successfully: {} â†’ {} final results",
                        raw_count,
                        reranked.len()
                    );
                    return Ok(reranked);
                }
                Err(e) => {
                    // Rerankingå¤±è´¥æ—¶é™çº§ï¼šé‡æ–°æ‰§è¡Œæœç´¢ï¼Œä½¿ç”¨base_limit
                    warn!(
                        "âš ï¸  Reranking failed ({}), falling back to direct search with base_limit",
                        e
                    );
                    let fallback_options = SearchOptions {
                        user_id,
                        limit: Some(base_limit),
                        threshold: Some(dynamic_threshold), // ä½¿ç”¨åŠ¨æ€é˜ˆå€¼
                        ..Default::default()
                    };
                    return self
                        .memory
                        .search_with_options(query, fallback_options)
                        .await
                        .map_err(|e| e.to_string());
                }
            }
        }

        // ä¸éœ€è¦é‡æ’åºæˆ–ç»“æœä¸è¶³ï¼Œç›´æ¥è¿”å›ï¼ˆå¯èƒ½éœ€è¦æˆªæ–­ï¼‰
        Ok(raw_results.into_iter().take(base_limit).collect())
    }

    /// ğŸ†• åº”ç”¨Rerankeré‡æ’åº
    ///
    /// å°†MemoryItemè½¬æ¢ä¸ºSearchResultï¼Œè°ƒç”¨Rerankerï¼Œå†è½¬æ¢å›æ¥
    async fn apply_reranking(
        &self,
        query: &str,
        search_query: &agent_mem_core::search::SearchQuery,
        raw_results: Vec<MemoryItem>,
        final_limit: usize,
    ) -> Result<Vec<MemoryItem>, String> {
        use agent_mem_core::search::SearchResult;

        // 1. å°è¯•ç”Ÿæˆquery vectorï¼ˆç”¨äºRerankerï¼‰
        // æ³¨æ„ï¼šå¦‚æœæ— æ³•ç”Ÿæˆquery_vectorï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç°æœ‰çš„scoreè¿›è¡Œé‡æ’åº
        let query_vector_result = {
            // å°è¯•é€šè¿‡æœç´¢APIè·å–query vector
            // ç”±äºMemory APIæ²¡æœ‰ç›´æ¥æš´éœ²embedderï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€åŒ–çš„æ–¹æ³•ï¼š
            // ä½¿ç”¨ç¬¬ä¸€ä¸ªç»“æœçš„å‘é‡ä½œä¸ºå‚è€ƒï¼ˆå¦‚æœå¯ç”¨ï¼‰ï¼Œæˆ–è€…ä½¿ç”¨é»˜è®¤å‘é‡
            // å®é™…ä¸Šï¼ŒRerankerå¯ä»¥ä½¿ç”¨ç°æœ‰çš„scoreï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªå ä½å‘é‡
            let default_dim = 384; // FastEmbedé»˜è®¤ç»´åº¦ï¼Œå¯ä»¥æ ¹æ®å®é™…é…ç½®è°ƒæ•´
            vec![0.0f32; default_dim] // å ä½å‘é‡ï¼ŒRerankerä¼šä¸»è¦ä½¿ç”¨ç°æœ‰score
        };

        // 2. è½¬æ¢MemoryItem â†’ SearchResult
        let candidates: Vec<SearchResult> = raw_results
            .iter()
            .map(|item| SearchResult {
                id: item.id.clone(),
                content: item.content.clone(),
                score: item.score.unwrap_or(0.5),
                vector_score: item.score,
                fulltext_score: None,
                metadata: Some(
                    serde_json::to_value(&item.metadata).unwrap_or(serde_json::json!({})),
                ),
            })
            .collect();

        // 3. è°ƒç”¨Rerankerè¿›è¡Œé‡æ’åº
        // Rerankerä¼šåŸºäºå¤šä¸ªå› ç´ ï¼ˆç›¸ä¼¼åº¦ã€å…ƒæ•°æ®ã€æ—¶é—´ã€é‡è¦æ€§ã€è´¨é‡ï¼‰é‡æ–°è¯„åˆ†
        // æ³¨æ„ï¼šArcä¼šè‡ªåŠ¨è§£å¼•ç”¨ï¼Œæ‰€ä»¥å¯ä»¥ç›´æ¥è°ƒç”¨
        let reranked_results = self
            .reranker
            .rerank(candidates, &query_vector_result, search_query)
            .await
            .map_err(|e| format!("Reranker execution failed: {}", e))?;

        // 4. è½¬æ¢å›MemoryItemï¼ˆä¿æŒåŸå§‹MemoryItemæ•°æ®ï¼Œåªæ›´æ–°é¡ºåºå’Œscoreï¼‰
        let mut result_map: std::collections::HashMap<String, MemoryItem> = raw_results
            .into_iter()
            .map(|item| (item.id.clone(), item))
            .collect();

        let final_results: Vec<MemoryItem> = reranked_results
            .into_iter()
            .take(final_limit)
            .filter_map(|reranked| {
                result_map.get_mut(&reranked.id).map(|item| {
                    // æ›´æ–°scoreä¸ºé‡æ’åºåçš„åˆ†æ•°
                    item.score = Some(reranked.score);
                    item.clone()
                })
            })
            .collect();

        Ok(final_results)
    }

    /// è·å–æ‰€æœ‰è®°å¿†
    pub async fn get_all_memories(
        &self,
        agent_id: Option<String>,
        user_id: Option<String>,
        limit: Option<usize>,
    ) -> Result<Vec<MemoryItem>, String> {
        let options = GetAllOptions {
            agent_id,
            user_id,
            limit,
            ..Default::default()
        };

        self.memory
            .get_all(options)
            .await
            .map_err(|e| e.to_string())
    }

    /// åˆ é™¤æ‰€æœ‰è®°å¿†
    pub async fn delete_all_memories(
        &self,
        agent_id: Option<String>,
        user_id: Option<String>,
    ) -> Result<usize, String> {
        let options = DeleteAllOptions {
            agent_id,
            user_id,
            ..Default::default()
        };

        self.memory
            .delete_all(options)
            .await
            .map_err(|e| e.to_string())
    }

    /// é‡ç½®æ‰€æœ‰è®°å¿†ï¼ˆå±é™©æ“ä½œï¼‰
    pub async fn reset(&self) -> Result<(), String> {
        self.memory.reset().await.map_err(|e| e.to_string())
    }

    /// è·å–ç»Ÿè®¡ä¿¡æ¯
    pub async fn get_stats(&self) -> Result<agent_mem::MemoryStats, String> {
        self.memory.get_stats().await.map_err(|e| e.to_string())
    }
}

/// é»˜è®¤å®ç°ï¼ˆå¼‚æ­¥åˆ›å»ºï¼‰
impl MemoryManager {
    pub fn new_sync() -> Self {
        // æ³¨æ„ï¼šè¿™åªç”¨äºç±»å‹ç³»ç»Ÿï¼Œå®é™…ä½¿ç”¨åº”è¯¥è°ƒç”¨async new()
        panic!("Use MemoryManager::new().await instead");
    }
}

// ==================== è¾…åŠ©å‡½æ•° ====================
// æ³¨æ„ï¼šè¾…åŠ©å‡½æ•°å·²è¿ç§»åˆ° utils.rs æ¨¡å—

// ==================== è·¯ç”±å¤„ç†å™¨å‡½æ•° ====================
// ä»¥ä¸‹æ˜¯å®é™…çš„HTTPè·¯ç”±å¤„ç†å™¨å‡½æ•°

use axum::{
    extract::{Extension, Path, Query},
    http::StatusCode,
    response::Json,
};
use tracing::{debug, error, info, warn};

/// æ·»åŠ æ–°è®°å¿†ï¼ˆğŸ”§ ä½¿ç”¨åŒå†™ç­–ç•¥ï¼‰
#[utoipa::path(
    post,
    path = "/api/v1/memories",
    tag = "memory",
    request_body = crate::models::MemoryRequest,
    responses(
        (status = 201, description = "Memory created successfully", body = crate::models::MemoryResponse),
        (status = 400, description = "Invalid request"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn add_memory(
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Json(request): Json<crate::models::MemoryRequest>,
) -> ServerResult<(
    StatusCode,
    Json<crate::models::ApiResponse<crate::models::MemoryResponse>>,
)> {
    info!(
        "Adding new memory for agent_id: {:?}, user_id: {:?}",
        request.agent_id, request.user_id
    );

    let memory_id = memory_manager
        .add_memory(
            repositories, // ä¼ é€’repositoriesç”¨äºLibSQLæŒä¹…åŒ–
            request.agent_id,
            request.user_id,
            request.content,
            request.memory_type,
            request.importance,
            request.metadata,
        )
        .await
        .map_err(|e| {
            error!("Failed to add memory: {}", e);
            ServerError::MemoryError(e.to_string())
        })?;

    let response = crate::models::MemoryResponse {
        id: memory_id,
        message: "Memory added successfully (VectorStore + LibSQL)".to_string(),
    };

    Ok((
        StatusCode::CREATED,
        Json(crate::models::ApiResponse::success(response)),
    ))
}

/// è·å–è®°å¿†
#[utoipa::path(
    get,
    path = "/api/v1/memories/{id}",
    tag = "memory",
    params(
        ("id" = String, Path, description = "Memory ID")
    ),
    responses(
        (status = 200, description = "Memory retrieved successfully"),
        (status = 404, description = "Memory not found"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn get_memory(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Path(id): Path<String>,
) -> ServerResult<Json<crate::models::ApiResponse<serde_json::Value>>> {
    info!("Getting memory with ID: {}", id);

    let memory = memory_manager.get_memory(&id).await.map_err(|e| {
        error!("Failed to get memory: {}", e);
        ServerError::MemoryError(e.to_string())
    })?;

    match memory {
        Some(mem) => Ok(Json(crate::models::ApiResponse::success(mem))),
        None => Err(ServerError::NotFound("Memory not found".to_string())),
    }
}

/// æ›´æ–°è®°å¿†
#[utoipa::path(
    put,
    path = "/api/v1/memories/{id}",
    tag = "memory",
    params(
        ("id" = String, Path, description = "Memory ID")
    ),
    request_body = crate::models::UpdateMemoryRequest,
    responses(
        (status = 200, description = "Memory updated successfully"),
        (status = 404, description = "Memory not found"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn update_memory(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    Path(id): Path<String>,
    Json(request): Json<crate::models::UpdateMemoryRequest>,
) -> ServerResult<Json<crate::models::ApiResponse<crate::models::MemoryResponse>>> {
    info!("Updating memory with ID: {}", id);

    // ğŸ”§ ä¿®å¤: ç›´æ¥æ›´æ–°LibSQL Repository
    // å…ˆè·å–ç°æœ‰è®°å¿†
    let existing = repositories
        .memories
        .find_by_id(&id)
        .await
        .map_err(|e| {
            error!("Failed to find memory for update: {}", e);
            ServerError::MemoryError(format!("Memory not found: {}", e))
        })?
        .ok_or_else(|| ServerError::MemoryError("Memory not found".to_string()))?;

    // æ„å»ºæ›´æ–°åçš„Memoryï¼Œä¿ç•™å…¶ä»–å­—æ®µ
    let updated_content = if let Some(content) = request.content {
        agent_mem_traits::Content::text(content)
    } else {
        existing.content.clone()
    };

    let updated_importance = request
        .importance
        .unwrap_or_else(|| {
            existing.importance()
                .map(|v| v as f32)
                .unwrap_or(0.5)
        });

    // ä½¿ç”¨builderæ¨¡å¼æ„å»ºæ›´æ–°åçš„Memory
    let mut updated = existing.clone();
    updated.content = updated_content;

    // æ›´æ–°importance - ä½¿ç”¨systemå‘½åç©ºé—´ï¼ˆå’Œimportance()æ–¹æ³•ä¸€è‡´ï¼‰
    updated.attributes.set(
        agent_mem_traits::AttributeKey::system("importance"),
        agent_mem_traits::AttributeValue::Number(updated_importance as f64),
    );
    updated.metadata.updated_at = chrono::Utc::now();

    // æ‰§è¡Œæ›´æ–°
    repositories.memories.update(&updated).await.map_err(|e| {
        error!("Failed to update memory in repository: {}", e);
        ServerError::MemoryError(e.to_string())
    })?;

    info!("âœ… Memory updated in LibSQL");

    let response = crate::models::MemoryResponse {
        id,
        message: "Memory updated successfully".to_string(),
    };

    Ok(Json(crate::models::ApiResponse::success(response)))
}

/// åˆ é™¤è®°å¿†
#[utoipa::path(
    delete,
    path = "/api/v1/memories/{id}",
    tag = "memory",
    params(
        ("id" = String, Path, description = "Memory ID")
    ),
    responses(
        (status = 200, description = "Memory deleted successfully"),
        (status = 404, description = "Memory not found"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn delete_memory(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    Path(id): Path<String>,
) -> ServerResult<Json<crate::models::ApiResponse<crate::models::MemoryResponse>>> {
    info!("åˆ é™¤è®°å¿†: {}", id);
    info!("Deleting memory with ID: {}", id);

    // ğŸ”§ ä¿®å¤: å…ˆæ£€æŸ¥è®°å¿†æ˜¯å¦å­˜åœ¨
    let memory_exists = repositories.memories.find_by_id(&id).await
        .ok()
        .flatten()
        .is_some();
    
    if !memory_exists {
        warn!("è®°å¿†ä¸å­˜åœ¨äºLibSQL: {}", id);
        return Err(ServerError::NotFound(format!("Memory not found: {}", id)));
    }
    
    // ğŸ”§ ä¿®å¤: å…ˆåˆ é™¤LibSQLï¼ˆä¸»å­˜å‚¨ï¼‰ï¼Œç„¶åå°è¯•åˆ é™¤å‘é‡å­˜å‚¨
    // å¦‚æœå‘é‡å­˜å‚¨åˆ é™¤å¤±è´¥ï¼ˆè®°å¿†ä¸å­˜åœ¨ï¼‰ï¼Œä¸åº”è¯¥å¯¼è‡´æ•´ä¸ªåˆ é™¤å¤±è´¥
    let libsql_result = repositories.memories.delete(&id).await;
    
    match libsql_result {
        Ok(_) => {
            info!("âœ… Memory deleted from LibSQL: {}", id);
            
            // å°è¯•åˆ é™¤å‘é‡å­˜å‚¨ï¼ˆéå…³é”®æ“ä½œï¼Œå¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼‰
            let vector_result = memory_manager.delete_memory(&id).await;
            match vector_result {
                Ok(_) => {
                    info!("âœ… Memory deleted from both LibSQL and Vector Store: {}", id);
                }
                Err(e) => {
                    // ğŸ”§ ä¿®å¤: å‘é‡å­˜å‚¨åˆ é™¤å¤±è´¥ä¸åº”è¯¥å¯¼è‡´æ•´ä¸ªåˆ é™¤å¤±è´¥
                    // å› ä¸ºä¸»å­˜å‚¨ï¼ˆLibSQLï¼‰å·²ç»åˆ é™¤æˆåŠŸ
                    let error_msg = e.to_string();
                    if error_msg.contains("not found") || error_msg.contains("Memory not found") {
                        warn!("âš ï¸  å‘é‡å­˜å‚¨ä¸­è®°å¿†ä¸å­˜åœ¨ï¼ˆå¯èƒ½ä»æœªæ·»åŠ æˆ–å·²åˆ é™¤ï¼‰: {}. è¿™ä¸ä¼šå½±å“åˆ é™¤æ“ä½œ", id);
                    } else {
                        warn!("âš ï¸  å‘é‡å­˜å‚¨åˆ é™¤å¤±è´¥ï¼ˆéå…³é”®ï¼‰: {}. é”™è¯¯: {}. è®°å¿†å·²ä»ä¸»å­˜å‚¨åˆ é™¤", id, error_msg);
                    }
                }
            }
            
            let response = crate::models::MemoryResponse {
                id,
                message: "Memory deleted successfully".to_string(),
            };
            Ok(Json(crate::models::ApiResponse::success(response)))
        }
        Err(e) => {
            error!("Failed to delete memory from LibSQL: {}", e);
            Err(ServerError::MemoryError(format!(
                "Failed to delete memory: {}", e
            )))
        }
    }
}

/// æœç´¢è®°å¿†
// ========== æ··åˆæ£€ç´¢è¾…åŠ©å‡½æ•° ==========
// æ³¨æ„ï¼šè¾…åŠ©å‡½æ•°å·²è¿ç§»åˆ° utils.rs æ¨¡å—ï¼Œä½¿ç”¨ utils::* å¯¼å…¥

/// é€šè¿‡LibSQLç²¾ç¡®æŸ¥è¯¢ï¼ˆå•†å“IDç­‰ï¼‰- ä½¿ç”¨searchæ–¹æ³•ï¼Œç›´æ¥è¿”å›JSON
async fn search_by_libsql_exact(
    repositories: &Arc<agent_mem_core::storage::factory::Repositories>,
    query: &str,
    limit: usize,
) -> Result<Vec<serde_json::Value>, String> {
    use tracing::{debug, error, info};

    info!("ğŸ” LibSQLç²¾ç¡®æŸ¥è¯¢: query='{}', limit={}", query, limit);

    // ä½¿ç”¨repositories.memories.searchæ–¹æ³•ï¼ˆæ”¯æŒcontent LIKEæŸ¥è¯¢ï¼‰
    match repositories
        .memories
        .search(query, (limit * 2) as i64) // å¤šå–ä¸€äº›ï¼Œç”¨äºæ’åºè¿‡æ»¤
        .await
    {
        Ok(memories) if !memories.is_empty() => {
            info!("âœ… LibSQLæŸ¥è¯¢æˆåŠŸ: æ‰¾åˆ° {} æ¡è®°å¿†", memories.len());

            // ğŸ”§ ä¿®å¤: å°† MemoryV4 è½¬æ¢ä¸º MemoryItem ä»¥ä¾¿è®¿é—®å­—æ®µ
            use agent_mem_traits::MemoryV4;
            let memory_items: Vec<_> = memories.into_iter().map(|m| m.to_legacy_item()).collect();

            // ğŸ”§ ä¿®å¤: ä¼˜å…ˆè¿”å›ç²¾ç¡®åŒ¹é…çš„å•†å“è®°å¿†
            // 1. åˆ†ç¦»ç²¾ç¡®åŒ¹é…å’Œæ¨¡ç³ŠåŒ¹é…
            let mut exact_matches = Vec::new();
            let mut fuzzy_matches = Vec::new();

            for mem in memory_items {
                let is_exact = {
                    // æ£€æŸ¥ content æ˜¯å¦åŒ…å« "å•†å“ID: {query}"
                    mem.content.contains(&format!("å•†å“ID: {}", query)) ||
                    // æ£€æŸ¥ metadata ä¸­çš„ product_id æ˜¯å¦åŒ¹é…
                    mem.metadata
                        .get("product_id")
                        .and_then(|v| v.as_str())
                        .map(|pid| pid == query)
                        .unwrap_or(false)
                };

                // æ’é™¤å·¥ä½œè®°å¿†ï¼ˆworking memoryï¼‰ï¼Œå®ƒä»¬é€šå¸¸æ˜¯LLMçš„å›å¤
                let memory_type_str = format!("{:?}", mem.memory_type);
                let is_working_memory = matches!(memory_type_str.as_str(), "Working");

                if is_exact && !is_working_memory {
                    exact_matches.push(mem);
                } else if !is_working_memory {
                    fuzzy_matches.push(mem);
                }
            }

            info!(
                "ğŸ“Š ç²¾ç¡®åŒ¹é…: {} æ¡, æ¨¡ç³ŠåŒ¹é…: {} æ¡",
                exact_matches.len(),
                fuzzy_matches.len()
            );

            // 2. åˆå¹¶ç»“æœï¼šç²¾ç¡®åŒ¹é…åœ¨å‰ï¼Œæ¨¡ç³ŠåŒ¹é…åœ¨å
            let mut sorted_memories = exact_matches;
            sorted_memories.extend(fuzzy_matches);

            // 3. é™åˆ¶è¿”å›æ•°é‡
            sorted_memories.truncate(limit);

            for mem in &sorted_memories {
                // ğŸ”§ ä¿®å¤: ä½¿ç”¨å­—ç¬¦è¾¹ç•Œè€Œä¸æ˜¯å­—èŠ‚è¾¹ç•Œï¼Œé¿å…UTF-8å­—ç¬¦ä¸­é—´åˆ‡ç‰‡å¯¼è‡´panic
                let content_preview = truncate_string_at_char_boundary(&mem.content, 50);
                debug!(
                    "  - ID: {}, Type: {:?}, Content: {}...",
                    mem.id, mem.memory_type, content_preview
                );
            }

            // ç›´æ¥è½¬æ¢ä¸ºJSON
            let json_results: Vec<serde_json::Value> = sorted_memories
                .into_iter()
                .map(|m| {
                    serde_json::json!({
                        "id": m.id,
                        "agent_id": m.agent_id,
                        "user_id": m.user_id,
                        "content": m.content,
                        "memory_type": format!("{:?}", m.memory_type),
                        "importance": m.importance,
                        "created_at": m.created_at.to_rfc3339(),
                        "updated_at": m.updated_at.map(|dt| dt.to_rfc3339()),
                        "access_count": m.access_count,
                        "metadata": m.metadata,
                        "hash": m.hash,
                        "score": m.score.unwrap_or(1.0),
                    })
                })
                .collect();

            if json_results.is_empty() {
                info!("âš ï¸  è¿‡æ»¤åæ²¡æœ‰æœ‰æ•ˆç»“æœ: query='{}'", query);
                Err(format!("æœªæ‰¾åˆ°åŒ¹é…çš„è®°å¿†: {}", query))
            } else {
                Ok(json_results)
            }
        }
        Ok(_) => {
            info!("âš ï¸  LibSQLæœªæ‰¾åˆ°ç»“æœ: query='{}'", query);
            Err(format!("æœªæ‰¾åˆ°åŒ¹é…çš„è®°å¿†: {}", query))
        }
        Err(e) => {
            error!("âŒ LibSQLæŸ¥è¯¢å¤±è´¥: {}", e);
            Err(format!("LibSQLæŸ¥è¯¢å¤±è´¥: {}", e))
        }
    }
}

// æ³¨æ„ï¼šconvert_memory_to_json å’Œ compute_prefetch_candidates å·²è¿ç§»åˆ° utils.rs

/// ğŸ†• Phase 2.3: æ™ºèƒ½é¢„å–ï¼ˆç®€åŒ–ç‰ˆï¼‰ - åŸºäºè®¿é—®æ¨¡å¼å’Œæœç´¢å†å²é¢„å–
async fn prefetch_for_query(
    repositories: Arc<agent_mem_core::storage::factory::Repositories>,
    memory_manager: Arc<MemoryManager>,
    request: &crate::models::SearchRequest,
) -> ServerResult<usize> {
    use libsql::Builder;

    let fetch_limit = request.limit.unwrap_or(10).saturating_mul(2).min(50).max(1);
    let db_path = std::env::var("DATABASE_URL")
        .unwrap_or_else(|_| "file:./data/agentmem.db".to_string())
        .replace("file:", "");

    let db = Builder::new_local(&db_path)
        .build()
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to open database: {}", e)))?;

    let conn = db
        .connect()
        .map_err(|e| ServerError::Internal(format!("Failed to connect: {}", e)))?;

    // æ ¹æ®è¿‡æ»¤æ¡ä»¶æ„å»ºæŸ¥è¯¢
    let mut rows = if let Some(agent_id) = &request.agent_id {
        let mut stmt = conn
            .prepare("SELECT id, access_count, last_accessed FROM memories WHERE is_deleted = 0 AND agent_id = ? ORDER BY access_count DESC, last_accessed DESC LIMIT ?")
            .await
            .map_err(|e| ServerError::Internal(format!("Failed to prepare query: {}", e)))?;
        stmt.query(libsql::params![agent_id.clone(), fetch_limit as i64])
            .await
            .map_err(|e| ServerError::Internal(format!("Failed to execute query: {}", e)))?
    } else if let Some(user_id) = &request.user_id {
        let mut stmt = conn
            .prepare("SELECT id, access_count, last_accessed FROM memories WHERE is_deleted = 0 AND user_id = ? ORDER BY access_count DESC, last_accessed DESC LIMIT ?")
            .await
            .map_err(|e| ServerError::Internal(format!("Failed to prepare query: {}", e)))?;
        stmt.query(libsql::params![user_id.clone(), fetch_limit as i64])
            .await
            .map_err(|e| ServerError::Internal(format!("Failed to execute query: {}", e)))?
    } else {
        let mut stmt = conn
            .prepare("SELECT id, access_count, last_accessed FROM memories WHERE is_deleted = 0 ORDER BY access_count DESC, last_accessed DESC LIMIT ?")
            .await
            .map_err(|e| ServerError::Internal(format!("Failed to prepare query: {}", e)))?;
        stmt.query(libsql::params![fetch_limit as i64])
            .await
            .map_err(|e| ServerError::Internal(format!("Failed to execute query: {}", e)))?
    };

    // æ”¶é›†è¡Œæ•°æ®
    let mut collected: Vec<(String, i64, Option<i64>)> = Vec::new();
    while let Some(row) = rows
        .next()
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to fetch row: {}", e)))?
    {
        let id: String = row
            .get(0)
            .map_err(|e| ServerError::Internal(format!("Failed to get id: {}", e)))?;
        let access_count: i64 = row.get(1).unwrap_or(0);
        let last_accessed_ts: Option<i64> = row.get(2).ok();
        collected.push((id, access_count, last_accessed_ts));
    }

    // è®¡ç®—å€™é€‰å¹¶é¢„å–
    let candidate_ids = compute_prefetch_candidates(collected, request.limit.unwrap_or(10));
    if candidate_ids.is_empty() {
        return Ok(0);
    }

    let fetch_futures = candidate_ids.iter().map(|id| {
        let mm = memory_manager.clone();
        let id_clone = id.clone();
        async move {
            match mm.get_memory(&id_clone).await {
                Ok(Some(_)) => 1usize,
                _ => 0usize,
            }
        }
    });

    let warmed_count: usize = join_all(fetch_futures).await.into_iter().sum();
    Ok(warmed_count)
}

#[utoipa::path(
    post,
    path = "/api/v1/memories/search",
    tag = "memory",
    request_body = crate::models::SearchRequest,
    responses(
        (status = 200, description = "Search completed successfully", body = crate::models::SearchResponse),
        (status = 400, description = "Invalid search request"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn search_memories(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    Json(request): Json<crate::models::SearchRequest>,
) -> ServerResult<Json<crate::models::ApiResponse<crate::models::SearchResponse>>> {
    info!("ğŸ” æœç´¢è®°å¿†: query={}", request.query);

    // ğŸ†• Phase 2.7: æœç´¢ç»Ÿè®¡æ”¶é›† - è®°å½•æœç´¢å¼€å§‹æ—¶é—´
    let search_start = Instant::now();
    let stats = get_search_stats();

    // ğŸ†• Phase 2.3: å¯é€‰é¢„å–ï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡ä¸»æœç´¢æµç¨‹ï¼‰
    if request.prefetch.unwrap_or(false) {
        let repositories_clone = repositories.clone();
        let memory_manager_clone = memory_manager.clone();
        let request_clone = request.clone();
        tokio::spawn(async move {
            match prefetch_for_query(repositories_clone, memory_manager_clone, &request_clone).await
            {
                Ok(count) => info!("ğŸ§  é¢„å–å®Œæˆ: warmed {} memories", count),
                Err(e) => warn!("âš ï¸ é¢„å–å¤±è´¥: {}", e),
            }
        });
    }

    // ğŸ¯ Phase 1: LibSQLç²¾ç¡®æŸ¥è¯¢ï¼ˆå•†å“IDç­‰ï¼‰
    let is_exact_query = detect_exact_query(&request.query);

    if is_exact_query {
        info!("ğŸ¯ æ£€æµ‹åˆ°ç²¾ç¡®æŸ¥è¯¢ï¼Œä½¿ç”¨LibSQL: {}", request.query);

        // å°è¯•LibSQLç²¾ç¡®åŒ¹é…
        let limit = request.limit.unwrap_or(10);
        match search_by_libsql_exact(&repositories, &request.query, limit * 2).await { // è·å–æ›´å¤šç»“æœä»¥æ”¯æŒåˆ†é¡µ
            Ok(json_results) if !json_results.is_empty() => {
                info!("âœ… LibSQLç²¾ç¡®åŒ¹é…æ‰¾åˆ° {} æ¡ç»“æœ", json_results.len());
                
                // ğŸ†• Phase 2.13: åº”ç”¨åˆ†é¡µï¼ˆç²¾ç¡®æŸ¥è¯¢ï¼‰
                let offset = request.offset.unwrap_or(0);
                let total = json_results.len();
                let paginated_results: Vec<serde_json::Value> = if offset < total {
                    json_results
                        .into_iter()
                        .skip(offset)
                        .take(limit)
                        .collect()
                } else {
                    Vec::new()
                };
                let has_more = offset + limit < total;
                
                // ğŸ†• Phase 2.7: æ›´æ–°ç»Ÿè®¡ï¼ˆç²¾ç¡®æŸ¥è¯¢ï¼‰
                let search_latency = search_start.elapsed();
                {
                    let mut stats_write = stats.write().await;
                    stats_write.total_searches += 1;
                    stats_write.exact_queries += 1;
                    stats_write.total_latency_us += search_latency.as_micros() as u64;
                    stats_write.last_updated = Instant::now();
                }
                
                // ğŸ†• Phase 2.13: è¿”å›å¸¦åˆ†é¡µä¿¡æ¯çš„å“åº”
                let search_response = crate::models::SearchResponse {
                    results: paginated_results,
                    total,
                    offset,
                    limit,
                    has_more,
                };
                
                return Ok(Json(crate::models::ApiResponse::success(search_response)));
            }
            Ok(_) => {
                info!("âš ï¸  LibSQLæœªæ‰¾åˆ°ç»“æœï¼Œé™çº§åˆ°å‘é‡æœç´¢");
            }
            Err(e) => {
                warn!("âš ï¸  LibSQLæŸ¥è¯¢å¤±è´¥: {}, é™çº§åˆ°å‘é‡æœç´¢", e);
            }
        }
    }

    // ğŸ” Phase 2: å‘é‡è¯­ä¹‰æœç´¢ï¼ˆé™çº§æˆ–é»˜è®¤ï¼‰
    info!("ğŸ” ä½¿ç”¨å‘é‡è¯­ä¹‰æœç´¢: {}", request.query);
    let query_clone = request.query.clone(); // Clone for later use
    
    // ğŸ†• Phase 2.4: æŸ¥è¯¢ç»“æœç¼“å­˜ï¼ˆç®€å•å®ç°ï¼‰
    // ç”Ÿæˆç¼“å­˜é”®
    let cache_key = generate_cache_key(
        &request.query,
        &request.agent_id,
        &request.user_id,
        &request.limit,
    );
    
    // å°è¯•ä»ç¼“å­˜è·å–ç»“æœ
    let cache = get_search_cache();
    let cache_ttl = Duration::from_secs(
        std::env::var("SEARCH_CACHE_TTL_SECONDS")
            .ok()
            .and_then(|v| v.parse().ok())
            .unwrap_or(300), // é»˜è®¤5åˆ†é’Ÿ
    );
    
    // æ£€æŸ¥ç¼“å­˜ï¼ˆLruCacheçš„getéœ€è¦&mutï¼Œæ‰€ä»¥ä½¿ç”¨writeé”ï¼‰
    let cache_hit = {
        let mut cache_write = cache.write().await;
        if let Some(cached) = cache_write.get(&cache_key) {
            if !cached.is_expired() {
                info!("ğŸ’¾ ç¼“å­˜å‘½ä¸­: query='{}', cache_key={}", request.query, cache_key);
                
                // ğŸ†• Phase 2.7: æ›´æ–°ç»Ÿè®¡ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
                let search_latency = search_start.elapsed();
                {
                    let mut stats_write = stats.write().await;
                    stats_write.total_searches += 1;
                    stats_write.cache_hits += 1;
                    stats_write.vector_searches += 1;
                    stats_write.total_latency_us += search_latency.as_micros() as u64;
                    stats_write.last_updated = Instant::now();
                }
                
                // ğŸ†• Phase 2.13: ä»ç¼“å­˜æ„å»ºSearchResponse
                let total = cached.results.len();
                let offset = request.offset.unwrap_or(0);
                let limit = request.limit.unwrap_or(10);
                let paginated_results: Vec<serde_json::Value> = if offset < total {
                    cached.results
                        .iter()
                        .skip(offset)
                        .take(limit)
                        .cloned()
                        .collect()
                } else {
                    Vec::new()
                };
                let has_more = offset + limit < total;
                
                let search_response = crate::models::SearchResponse {
                    results: paginated_results,
                    total,
                    offset,
                    limit,
                    has_more,
                };
                
                return Ok(Json(crate::models::ApiResponse::success(search_response)));
            } else {
                // ç¼“å­˜è¿‡æœŸï¼Œåˆ é™¤
                cache_write.pop(&cache_key);
                false
            }
        } else {
            false
        }
    };
    
    if !cache_hit {
        info!("ğŸ’¾ ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œæœç´¢: query='{}'", request.query);
        
        // ğŸ†• Phase 2.7: æ›´æ–°ç»Ÿè®¡ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
        {
            let mut stats_write = stats.write().await;
            stats_write.cache_misses += 1;
        }
    }
    
    // ğŸ”§ å¢å¼ºï¼šè®¡ç®—è‡ªé€‚åº”é˜ˆå€¼ç”¨äºåç»­è¿‡æ»¤
    let adaptive_threshold = get_adaptive_threshold(&request.query);
    info!("ğŸ“Š è‡ªé€‚åº”é˜ˆå€¼: query='{}', threshold={}", request.query, adaptive_threshold);
    
    // ğŸ†• Phase 2.9: æœç´¢è¶…æ—¶æ§åˆ¶
    let search_timeout_secs = std::env::var("SEARCH_TIMEOUT_SECONDS")
        .ok()
        .and_then(|v| v.parse().ok())
        .unwrap_or(30); // é»˜è®¤30ç§’
    
    let memory_manager_clone = memory_manager.clone();
    let query_clone_for_timeout = request.query.clone();
    let agent_id_clone = request.agent_id.clone();
    let user_id_clone = request.user_id.clone();
    let limit_clone = request.limit;
    let memory_type_clone = request.memory_type.clone();
    
    let search_future = async move {
        memory_manager_clone
            .search_memories(
                query_clone_for_timeout,
                agent_id_clone,
                user_id_clone,
                limit_clone,
                memory_type_clone,
            )
            .await
    };
    
    let mut results = match timeout(Duration::from_secs(search_timeout_secs), search_future).await {
        Ok(Ok(results)) => results,
        Ok(Err(e)) => {
            error!("Failed to search memories: {}", e);
            return Err(ServerError::MemoryError(e.to_string()));
        }
        Err(_) => {
            error!("Search operation timed out after {} seconds", search_timeout_secs);
            return Err(ServerError::Internal(format!(
                "Search operation timed out after {} seconds",
                search_timeout_secs
            )));
        }
    };

    // âœ… ä¿®å¤ï¼šè¿‡æ»¤å·²åˆ é™¤çš„è®°å½•ï¼Œç¡®ä¿æœç´¢ç»“æœä¸LibSQLçŠ¶æ€ä¸€è‡´
    // ğŸ†• Phase 3.2: å¹¶è¡ŒæŸ¥è¯¢ä¼˜åŒ– - ä½¿ç”¨å¹¶è¡ŒæŸ¥è¯¢æ‰¹é‡æ£€æŸ¥ç»“æœçŠ¶æ€
    // å‘é‡å­˜å‚¨å¯èƒ½è¿˜åŒ…å«å·²åˆ é™¤çš„è®°å½•ï¼Œéœ€è¦æ£€æŸ¥LibSQLä¸­çš„å®é™…çŠ¶æ€
    let valid_results = if results.is_empty() {
        Vec::new()
    } else {
        // å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰find_by_idæŸ¥è¯¢
        let check_futures: Vec<_> = results
            .iter()
            .map(|result| {
                let id = result.id.clone();
                let repo = &repositories.memories;
                async move {
                    let status = repo.find_by_id(&id).await;
                    (result.clone(), status)
                }
            })
            .collect();
        
        // ç­‰å¾…æ‰€æœ‰æŸ¥è¯¢å®Œæˆ
        let check_results = future::join_all(check_futures).await;
        
        // è¿‡æ»¤æœ‰æ•ˆç»“æœ
        let mut valid = Vec::new();
        for (result, status) in check_results {
            match status {
                Ok(Some(_)) => {
                    // è®°å½•å­˜åœ¨ä¸”æœªåˆ é™¤ï¼ˆfind_by_idå·²ç»è¿‡æ»¤äº†is_deleted=0ï¼‰
                    valid.push(result);
                }
                Ok(None) => {
                    // è®°å½•ä¸å­˜åœ¨æˆ–å·²åˆ é™¤ï¼Œè·³è¿‡
                    debug!("Skipping deleted memory from search results: {}", result.id);
                }
                Err(e) => {
                    // æŸ¥è¯¢å¤±è´¥ï¼Œä¸ºäº†å®‰å…¨èµ·è§ï¼Œè·³è¿‡è¯¥è®°å½•
                    warn!("Failed to check memory status in LibSQL: {}, skipping result", e);
                }
            }
        }
        valid
    };
    
    info!("ğŸ”„ å¹¶è¡ŒéªŒè¯å®Œæˆ: {} â†’ {} æ¡æœ‰æ•ˆç»“æœ", results.len(), valid_results.len());
    results = valid_results;

    // ğŸ”§ ä¿®å¤: å¯¹äºç²¾ç¡®æŸ¥è¯¢ï¼Œä¼˜å…ˆè¿”å›ç²¾ç¡®åŒ¹é…çš„ç»“æœ
    let mut sorted_results = results;
    if is_exact_query {
        // åˆ†ç¦»ç²¾ç¡®åŒ¹é…å’Œæ¨¡ç³ŠåŒ¹é…
        let mut exact_matches = Vec::new();
        let mut fuzzy_matches = Vec::new();

        for item in sorted_results {
            let is_exact = {
                // æ£€æŸ¥ content æ˜¯å¦åŒ…å« "å•†å“ID: {query}"
                item.content.contains(&format!("å•†å“ID: {}", query_clone)) ||
                // æ£€æŸ¥ metadata ä¸­çš„ product_id æ˜¯å¦åŒ¹é…
                item.metadata
                    .get("product_id")
                    .and_then(|v| v.as_str())
                    .map(|pid| pid == query_clone)
                    .unwrap_or(false)
            };

            // æ’é™¤å·¥ä½œè®°å¿†ï¼ˆworking memoryï¼‰
            let is_working_memory =
                matches!(item.memory_type.to_string().as_str(), "working" | "Working");

            if is_exact && !is_working_memory {
                exact_matches.push(item);
            } else if !is_working_memory {
                fuzzy_matches.push(item);
            }
        }

        info!(
            "ğŸ“Š å‘é‡æœç´¢æ’åº: ç²¾ç¡®åŒ¹é… {} æ¡, æ¨¡ç³ŠåŒ¹é… {} æ¡",
            exact_matches.len(),
            fuzzy_matches.len()
        );

        // åˆå¹¶ï¼šç²¾ç¡®åŒ¹é…åœ¨å‰ï¼Œæ¨¡ç³ŠåŒ¹é…åœ¨å
        sorted_results = exact_matches;
        sorted_results.extend(fuzzy_matches);
    }

    // ğŸ†• Phase 2.1: ä¸‰ç»´æ£€ç´¢è¯„åˆ†ï¼ˆRecency Ã— Importance Ã— Relevanceï¼‰
    // è·å–recency_decayé…ç½®ï¼ˆé»˜è®¤0.1ï¼Œè¡¨ç¤ºæ¯å°æ—¶è¡°å‡çº¦10%ï¼‰
    let recency_decay: f64 = std::env::var("RECENCY_DECAY")
        .ok()
        .and_then(|v| v.parse().ok())
        .unwrap_or(0.1);
    
    // ä¸ºæ¯ä¸ªç»“æœè®¡ç®—ä¸‰ç»´è¯„åˆ†å’Œè´¨é‡è¯„åˆ†
    let mut scored_results: Vec<(MemoryItem, f64, f64, f64, f64, f64)> = sorted_results
        .into_iter()
        .map(|item| {
            // è·å–å„ä¸ªç»´åº¦åˆ†æ•°
            let relevance = item.score.unwrap_or(0.0);
            let importance = item.importance.max(0.0).min(1.0);
            let last_accessed = item.last_accessed_at.to_string();
            
            // è®¡ç®—Recencyè¯„åˆ†
            let recency = calculate_recency_score(&last_accessed, recency_decay);
            
            // è®¡ç®—ä¸‰ç»´ç»¼åˆè¯„åˆ†
            let composite_score = calculate_3d_score(
                relevance,
                importance,
                &last_accessed,
                recency_decay,
            );
            
            // ğŸ†• Phase 2.10: è®¡ç®—è´¨é‡è¯„åˆ†
            let quality = calculate_quality_score(&item);
            
            // å°†è´¨é‡è¯„åˆ†çº³å…¥ç»¼åˆè¯„åˆ†ï¼ˆè´¨é‡æƒé‡ï¼š0.1ï¼‰
            let final_score = composite_score * 0.9 + quality * 0.1;
            
            (item, final_score, recency, importance as f64, relevance as f64, quality)
        })
        .collect();
    
    // æŒ‰ä¸‰ç»´ç»¼åˆè¯„åˆ†æ’åºï¼ˆé™åºï¼‰
    scored_results.sort_by(|a, b| {
        b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal)
    });
    
    info!("ğŸ¯ ä¸‰ç»´æ£€ç´¢è¯„åˆ†å®Œæˆ: recency_decay={}, ç»“æœæ•°={}", 
        recency_decay, scored_results.len());

    // ğŸ”§ ä¿®å¤: è¿‡æ»¤ä½ç›¸å…³åº¦ç»“æœï¼ˆä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼ï¼‰
    // ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„é˜ˆå€¼ï¼Œå¦åˆ™ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼ï¼Œæœ€åæ‰ä½¿ç”¨é»˜è®¤å€¼
    let min_score_threshold = request.threshold.unwrap_or(adaptive_threshold);
    info!("ğŸ¯ è¿‡æ»¤é˜ˆå€¼: {} (ç”¨æˆ·æŒ‡å®š: {}, è‡ªé€‚åº”: {})", 
        min_score_threshold,
        request.threshold.map(|t| t.to_string()).unwrap_or_else(|| "æœªæŒ‡å®š".to_string()),
        adaptive_threshold);

    // ğŸ†• Phase 2.2: å±‚æ¬¡æ£€ç´¢æ’åºï¼ˆå¯é€‰ï¼ŒåŸºäºscopeå­—æ®µï¼‰
    // å¦‚æœå¯ç”¨å±‚æ¬¡æ£€ç´¢ï¼Œå…ˆæŒ‰scopeå±‚æ¬¡æ’åºï¼Œå†åº”ç”¨å…¶ä»–æ’åºé€»è¾‘
    let use_hierarchical = std::env::var("ENABLE_HIERARCHICAL_SEARCH")
        .ok()
        .and_then(|v| v.parse().ok())
        .unwrap_or(false);
    
    if use_hierarchical {
        info!("ğŸ” å¯ç”¨å±‚æ¬¡æ£€ç´¢æ’åº");
        // æå–MemoryItemå¹¶åº”ç”¨å±‚æ¬¡æ’åº
        let items: Vec<MemoryItem> = scored_results.iter().map(|(item, _, _, _, _, _)| item.clone()).collect();
        let hierarchical_sorted = apply_hierarchical_sorting(items);
        
        // é‡æ–°æ„å»ºscored_resultsï¼Œä¿æŒå±‚æ¬¡é¡ºåº
        let mut new_scored_results = Vec::new();
        let item_map: std::collections::HashMap<String, (MemoryItem, f64, f64, f64, f64, f64)> = scored_results
            .into_iter()
            .map(|(item, score, recency, importance, relevance, quality)| (item.id.clone(), (item, score, recency, importance, relevance, quality)))
            .collect();
        
        for item in hierarchical_sorted {
            if let Some((_, score, recency, importance, relevance, quality)) = item_map.get(&item.id) {
                new_scored_results.push((item, *score, *recency, *importance, *relevance, *quality));
            }
        }
        
        scored_results = new_scored_results;
        info!("âœ… å±‚æ¬¡æ£€ç´¢æ’åºå®Œæˆ: {} æ¡ç»“æœ", scored_results.len());
    }
    
    // ğŸ†• Phase 2.5: æœç´¢ç»“æœå»é‡
    // ç¬¬ä¸€æ­¥ï¼šåŸºäºIDå»é‡ï¼ˆç¡®ä¿åŒä¸€æ¡è®°å¿†åªå‡ºç°ä¸€æ¬¡ï¼‰
    // ç¬¬äºŒæ­¥ï¼šåŸºäºcontent hashå»é‡ï¼ˆç¡®ä¿å†…å®¹é‡å¤çš„è®°å¿†åªä¿ç•™ä¸€æ¡ï¼‰
    use std::collections::HashMap;
    let original_count = scored_results.len();
    
    // ç¬¬ä¸€æ­¥ï¼šåŸºäºIDå»é‡ï¼Œä¿ç•™è¯„åˆ†æœ€é«˜çš„
    let mut id_map: HashMap<String, (MemoryItem, f64, f64, f64, f64, f64)> = HashMap::new();
    for (item, final_score, recency, importance, relevance, quality) in scored_results {
        match id_map.get_mut(&item.id) {
            Some(existing) => {
                // å¦‚æœIDå·²å­˜åœ¨ï¼Œæ¯”è¾ƒç»¼åˆè¯„åˆ†ï¼Œä¿ç•™è¯„åˆ†æ›´é«˜çš„
                if final_score > existing.1 {
                    *existing = (item, final_score, recency, importance, relevance, quality);
                }
            }
            None => {
                // æ–°IDï¼Œç›´æ¥æ·»åŠ 
                id_map.insert(item.id.clone(), (item, final_score, recency, importance, relevance, quality));
            }
        }
    }
    
    let id_dedup_count = id_map.len();
    info!("ğŸ”„ IDå»é‡: {} â†’ {} æ¡ç»“æœ", original_count, id_dedup_count);
    
    // ç¬¬äºŒæ­¥ï¼šåŸºäºhash/contentå»é‡ï¼Œä¿ç•™è¯„åˆ†æœ€é«˜çš„
    let mut hash_map: HashMap<String, (MemoryItem, f64, f64, f64, f64, f64)> = HashMap::new();
    for (item, final_score, recency, importance, relevance, quality) in id_map.into_values() {
        // ä½¿ç”¨hashå­—æ®µè¿›è¡Œå»é‡ï¼ˆå¦‚æœhashä¸ºNoneæˆ–ç©ºï¼Œä½¿ç”¨contentçš„å‰100å­—ç¬¦ä½œä¸ºkeyï¼‰
        let dedup_key = item.hash.as_ref()
            .filter(|h| !h.is_empty())
            .cloned()
            .unwrap_or_else(|| {
                // å¦‚æœhashä¸ºç©ºï¼Œä½¿ç”¨contentçš„å‰100å­—ç¬¦ä½œä¸ºå»é‡key
                if item.content.len() > 100 {
                    // ä½¿ç”¨char_indicesæ‰¾åˆ°å®‰å…¨çš„å­—ç¬¦è¾¹ç•Œ
                    let mut char_count = 0;
                    let mut byte_index = 0;
                    for (i, _) in item.content.char_indices() {
                        if char_count >= 100 {
                            break;
                        }
                        char_count += 1;
                        byte_index = i;
                    }
                    item.content[..byte_index].to_string()
                } else {
                    item.content.clone()
                }
            });
        
        // å¦‚æœhashå·²å­˜åœ¨ï¼Œæ¯”è¾ƒç»¼åˆè¯„åˆ†ï¼Œä¿ç•™è¯„åˆ†æ›´é«˜çš„
        match hash_map.get_mut(&dedup_key) {
            Some(existing) => {
                // æ¯”è¾ƒç»¼åˆè¯„åˆ†ï¼Œå¦‚æœæ–°ç»“æœè¯„åˆ†æ›´é«˜ï¼Œæ›¿æ¢æ—§ç»“æœ
                if final_score > existing.1 {
                    *existing = (item, final_score, recency, importance, relevance, quality);
                }
            }
            None => {
                // æ–°hashï¼Œç›´æ¥æ·»åŠ 
                hash_map.insert(dedup_key, (item, final_score, recency, importance, relevance, quality));
            }
        }
    }
    
    let deduplicated_results: Vec<(MemoryItem, f64, f64, f64, f64, f64)> = hash_map.into_values().collect();
    info!("ğŸ”„ æœç´¢ç»“æœå»é‡å®Œæˆ: {} â†’ {} â†’ {} æ¡ç»“æœ (IDå»é‡ â†’ Hashå»é‡)", 
        original_count, id_dedup_count, deduplicated_results.len());

    // ğŸ†• Phase 2.12: åº”ç”¨æ™ºèƒ½è¿‡æ»¤ï¼ˆåœ¨è½¬æ¢ä¸ºJSONä¹‹å‰ï¼‰
    // ä»è¯·æ±‚ä¸­è·å–è¿‡æ»¤å‚æ•°ï¼ˆå¦‚æœæä¾›ï¼‰
    let min_importance = request.min_importance;
    let max_age_days = request.max_age_days;
    let min_access_count = request.min_access_count;
    
    // åº”ç”¨æ™ºèƒ½è¿‡æ»¤
    let filtered_results: Vec<(MemoryItem, f64, f64, f64, f64, f64)> = if min_importance.is_some() || max_age_days.is_some() || min_access_count.is_some() {
        let original_count = deduplicated_results.len();
        let items: Vec<MemoryItem> = deduplicated_results.iter().map(|(item, _, _, _, _, _)| item.clone()).collect();
        let filtered_items = apply_intelligent_filtering(items, min_importance, max_age_days, min_access_count);
        
        // é‡æ–°æ„å»ºå¸¦è¯„åˆ†çš„å…ƒç»„
        let filtered_map: std::collections::HashMap<String, (MemoryItem, f64, f64, f64, f64, f64)> = deduplicated_results
            .iter()
            .map(|(item, final_score, recency, importance, relevance, quality)| {
                (item.id.clone(), (item.clone(), *final_score, *recency, *importance, *relevance, *quality))
            })
            .collect();
        
        let filtered = filtered_items
            .into_iter()
            .filter_map(|item| filtered_map.get(&item.id).cloned())
            .collect::<Vec<_>>();
        
        info!("ğŸ” æ™ºèƒ½è¿‡æ»¤å®Œæˆ: {} â†’ {} æ¡ç»“æœ", original_count, filtered.len());
        filtered
    } else {
        deduplicated_results
    };
    
    // è½¬æ¢ä¸ºJSONï¼ŒåŒæ—¶åº”ç”¨é˜ˆå€¼è¿‡æ»¤ï¼ˆä½¿ç”¨åŸå§‹relevanceåˆ†æ•°è¿›è¡Œé˜ˆå€¼è¿‡æ»¤ï¼‰
    let json_results: Vec<serde_json::Value> = filtered_results
        .into_iter()
        .filter(|(item, _, _, _, relevance, _)| {
            // ä½¿ç”¨åŸå§‹çš„relevanceåˆ†æ•°è¿›è¡Œé˜ˆå€¼è¿‡æ»¤
            *relevance >= min_score_threshold as f64
        })
        .map(|(item, final_score, recency, importance, relevance, quality)| {
            serde_json::json!({
                "id": item.id,
                "agent_id": item.agent_id,
                "user_id": item.user_id,
                "content": item.content,
                "memory_type": item.memory_type,
                "importance": item.importance,
                "created_at": item.created_at,
                "last_accessed_at": item.last_accessed_at,
                "access_count": item.access_count,
                "metadata": item.metadata,
                "hash": item.hash,
                "score": relevance,  // åŸå§‹relevanceåˆ†æ•°ï¼ˆç”¨äºé˜ˆå€¼è¿‡æ»¤ï¼‰
                "composite_score": final_score,  // ğŸ†• æœ€ç»ˆç»¼åˆè¯„åˆ†ï¼ˆåŒ…å«è´¨é‡è¯„åˆ†ï¼‰
                "recency": recency,  // ğŸ†• Recencyè¯„åˆ†
                "relevance": relevance,  // ğŸ†• Relevanceè¯„åˆ†ï¼ˆä¸scoreç›¸åŒï¼‰
                "quality": quality,  // ğŸ†• Phase 2.10: è´¨é‡è¯„åˆ†
            })
        })
        .collect();

    // ğŸ†• Phase 2.4: ä¿å­˜ç»“æœåˆ°ç¼“å­˜ï¼ˆä½¿ç”¨LRUç­–ç•¥ï¼‰
    {
        let mut cache_write = cache.write().await;
        // LRUç¼“å­˜ä¼šè‡ªåŠ¨å¤„ç†å®¹é‡é™åˆ¶ï¼Œä½†æˆ‘ä»¬éœ€è¦æ¸…ç†è¿‡æœŸæ¡ç›®
        // å…ˆæ¸…ç†è¿‡æœŸæ¡ç›®ï¼ˆLruCacheä¸æ”¯æŒretainï¼Œéœ€è¦æ‰‹åŠ¨æ¸…ç†ï¼‰
        let expired_keys: Vec<String> = cache_write
            .iter()
            .filter(|(_, v)| v.is_expired())
            .map(|(k, _)| k.clone())
            .collect();
        for key in expired_keys {
            cache_write.pop(&key);
        }
        // æ’å…¥æ–°ç»“æœï¼ˆLRUä¼šè‡ªåŠ¨æ·˜æ±°æœ€ä¹…æœªä½¿ç”¨çš„æ¡ç›®ï¼‰
        cache_write.put(cache_key, CachedSearchResult::new(json_results.clone(), cache_ttl));
        info!("ğŸ’¾ ç»“æœå·²ç¼“å­˜: query='{}', cache_size={}", query_clone, cache_write.len());
    }

    // ğŸ†• Phase 2.13: åº”ç”¨åˆ†é¡µï¼ˆåœ¨è¿”å›ç»“æœå‰ï¼‰
    let offset = request.offset.unwrap_or(0);
    let limit = request.limit.unwrap_or(10);
    let total = json_results.len();
    
    // åº”ç”¨åˆ†é¡µ
    let paginated_results: Vec<serde_json::Value> = if offset < total {
        json_results
            .into_iter()
            .skip(offset)
            .take(limit)
            .collect()
    } else {
        Vec::new()
    };
    
    let has_more = offset + limit < total;
    
    info!("ğŸ“„ åˆ†é¡µç»“æœ: offset={}, limit={}, total={}, returned={}, has_more={}", 
        offset, limit, total, paginated_results.len(), has_more);

    // ğŸ†• Phase 2.7: æ›´æ–°ç»Ÿè®¡ï¼ˆå‘é‡æœç´¢å®Œæˆï¼‰
    let search_latency = search_start.elapsed();
    {
        let mut stats_write = stats.write().await;
        stats_write.total_searches += 1;
        stats_write.vector_searches += 1;
        stats_write.total_latency_us += search_latency.as_micros() as u64;
        stats_write.last_updated = Instant::now();
    }

    // ğŸ†• Phase 2.13: è¿”å›å¸¦åˆ†é¡µä¿¡æ¯çš„å“åº”
    let search_response = crate::models::SearchResponse {
        results: paginated_results,
        total,
        offset,
        limit,
        has_more,
    };

    Ok(Json(crate::models::ApiResponse::success(search_response)))
}

// æ³¨æ„ï¼šapply_hierarchical_sorting å·²è¿ç§»åˆ° utils.rs

/// ğŸ†• Phase 4.4: è®°å¿†æ¸…ç†åŠŸèƒ½
/// 
/// åŸºäºè®¿é—®æ¨¡å¼å’Œé‡è¦æ€§æ¸…ç†é•¿æœŸæœªä½¿ç”¨ä¸”é‡è¦æ€§ä½çš„è®°å¿†
/// - max_age_days: æœ€å¤§å¹´é¾„ï¼ˆå¤©æ•°ï¼Œé»˜è®¤90å¤©ï¼‰
/// - min_importance: æœ€å°é‡è¦æ€§é˜ˆå€¼ï¼ˆé»˜è®¤0.3ï¼‰
/// - max_access_count: æœ€å¤§è®¿é—®æ¬¡æ•°ï¼ˆé»˜è®¤5æ¬¡ï¼‰
/// - dry_run: æ˜¯å¦ä»…é¢„è§ˆä¸å®é™…åˆ é™¤ï¼ˆé»˜è®¤falseï¼‰
pub(crate) async fn cleanup_memories(
    repositories: Arc<agent_mem_core::storage::factory::Repositories>,
    max_age_days: Option<u64>,
    min_importance: Option<f32>,
    max_access_count: Option<i64>,
    dry_run: bool,
) -> Result<(usize, Vec<String>), String> {
    use libsql::{params, Builder};
    use chrono::Utc;
    
    let max_age = max_age_days.unwrap_or(90);
    let min_imp = min_importance.unwrap_or(0.3);
    let max_access = max_access_count.unwrap_or(5);
    let now = Utc::now().timestamp();
    let cutoff_time = now - (max_age as i64 * 86400);
    
    let db_path = std::env::var("DATABASE_URL")
        .unwrap_or_else(|_| "file:./data/agentmem.db".to_string())
        .replace("file:", "");
    
    let db = Builder::new_local(&db_path)
        .build()
        .await
        .map_err(|e| format!("Failed to open database: {}", e))?;
    
    let conn = db
        .connect()
        .map_err(|e| format!("Failed to connect: {}", e))?;
    
    // æŸ¥è¯¢ç¬¦åˆæ¡ä»¶çš„è®°å¿†ï¼ˆé•¿æœŸæœªä½¿ç”¨ä¸”é‡è¦æ€§ä½ï¼‰
    let query = "SELECT id FROM memories 
                 WHERE is_deleted = 0 
                 AND (last_accessed IS NULL OR last_accessed < ?)
                 AND (importance IS NULL OR importance < ?)
                 AND (access_count IS NULL OR access_count <= ?)
                 LIMIT 1000";
    
    let mut stmt = conn
        .prepare(query)
        .await
        .map_err(|e| format!("Failed to prepare query: {}", e))?;
    
    let mut rows = stmt
        .query(params![cutoff_time, min_imp, max_access])
        .await
        .map_err(|e| format!("Failed to execute query: {}", e))?;
    
    let mut memory_ids = Vec::new();
    while let Some(row) = rows
        .next()
        .await
        .map_err(|e| format!("Failed to fetch row: {}", e))?
    {
        let id: String = row.get(0).unwrap_or_default();
        memory_ids.push(id);
    }
    
    if dry_run {
        return Ok((memory_ids.len(), memory_ids));
    }
    
    // å®é™…åˆ é™¤è®°å¿†
    let mut deleted_count = 0;
    for memory_id in &memory_ids {
        if let Ok(Some(memory)) = repositories.memories.find_by_id(memory_id).await {
            if repositories.memories.delete(&memory.id.to_string()).await.is_ok() {
                deleted_count += 1;
            }
        }
    }
    
    Ok((deleted_count, memory_ids))
}

// æ³¨æ„ï¼šapply_intelligent_filtering å’Œ calculate_auto_importance å·²è¿ç§»åˆ° utils.rs

// æ³¨æ„ï¼šcalculate_access_pattern_score å·²è¿ç§»åˆ° utils.rs

/// ç¼“å­˜é¢„çƒ­ï¼šé¢„å–é«˜è®¿é—®é¢‘ç‡çš„è®°å¿†åˆ°ç¼“å­˜
/// 
/// ğŸ†• Phase 2.3: ç®€å•ç¼“å­˜é¢„çƒ­å®ç°ï¼ˆå¢å¼ºç‰ˆï¼šåŸºäºè®¿é—®æ¨¡å¼åˆ†æï¼‰
/// åŸºäºè®¿é—®é¢‘ç‡å’Œè®¿é—®æ¨¡å¼é¢„å–å¸¸ç”¨è®°å¿†ï¼Œæå‡åç»­æŸ¥è¯¢æ€§èƒ½
#[utoipa::path(
    post,
    path = "/api/v1/memories/cache/warmup",
    tag = "memory",
    params(
        ("limit" = Option<usize>, Query, description = "Number of memories to warmup (default: 50)")
    ),
    responses(
        (status = 200, description = "Cache warmup completed", body = crate::models::ApiResponse),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn warmup_cache(
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    axum::extract::Query(params): axum::extract::Query<HashMap<String, String>>,
) -> ServerResult<Json<crate::models::ApiResponse<serde_json::Value>>> {
    let limit = params
        .get("limit")
        .and_then(|v| v.parse().ok())
        .unwrap_or(50);
    
    info!("ğŸ”¥ å¼€å§‹ç¼“å­˜é¢„çƒ­: limit={}", limit);

    // 1. è·å–é«˜è®¿é—®é¢‘ç‡çš„è®°å¿†IDåˆ—è¡¨ï¼ˆä»LibSQLï¼‰
    let popular_memory_ids = {
        use libsql::{params, Builder};
        let db_path = std::env::var("DATABASE_URL")
            .unwrap_or_else(|_| "file:./data/agentmem.db".to_string())
            .replace("file:", "");
        
        let db = Builder::new_local(&db_path)
            .build()
            .await
            .map_err(|e| ServerError::Internal(format!("Failed to open database: {}", e)))?;
        
        let conn = db
            .connect()
            .map_err(|e| ServerError::Internal(format!("Failed to connect: {}", e)))?;
        
        // ğŸ†• Phase 2.3: å¢å¼ºæŸ¥è¯¢ - è·å–è®¿é—®æ¨¡å¼å’Œè¯„åˆ†ä¿¡æ¯
        let mut stmt = conn
            .prepare(
                "SELECT id, access_count, last_accessed FROM memories 
                 WHERE is_deleted = 0 
                 ORDER BY access_count DESC, last_accessed DESC 
                 LIMIT ?"
            )
            .await
            .map_err(|e| ServerError::Internal(format!("Failed to prepare query: {}", e)))?;
        
        let mut rows = stmt
            .query(params![limit as i64])
            .await
            .map_err(|e| ServerError::Internal(format!("Failed to execute query: {}", e)))?;
        
        // ğŸ†• Phase 2.3: ä½¿ç”¨è®¿é—®æ¨¡å¼è¯„åˆ†æ’åº
        let mut memory_scores: Vec<(String, f64, i64)> = Vec::new();
        while let Some(row) = rows
            .next()
            .await
            .map_err(|e| ServerError::Internal(format!("Failed to fetch row: {}", e)))?
        {
            let id: String = row.get(0)
                .map_err(|e| ServerError::Internal(format!("Failed to get id from row: {}", e)))?;
            let access_count: i64 = row.get(1).unwrap_or(0);
            let last_accessed_ts: Option<i64> = row.get(2).ok();
            
            // è®¡ç®—è®¿é—®æ¨¡å¼è¯„åˆ†
            let score = calculate_access_pattern_score(access_count, last_accessed_ts);
            memory_scores.push((id, score, access_count));
        }
        
        // æŒ‰è®¿é—®æ¨¡å¼è¯„åˆ†æ’åºï¼ˆé™åºï¼‰
        memory_scores.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));
        
        // æå–IDåˆ—è¡¨
        let ids: Vec<String> = memory_scores.iter().map(|(id, _, _)| id.clone()).collect();
        
        info!("ğŸ“Š è®¿é—®æ¨¡å¼åˆ†æ: åˆ†æäº† {} ä¸ªè®°å¿†ï¼Œæœ€é«˜è¯„åˆ†: {:.2}", 
            memory_scores.len(),
            memory_scores.first().map(|(_, score, _)| *score).unwrap_or(0.0)
        );
        
        ids
    };

    info!("ğŸ“Š æ‰¾åˆ° {} ä¸ªé«˜è®¿é—®é¢‘ç‡çš„è®°å¿†", popular_memory_ids.len());

    // 2. å¹¶è¡Œé¢„å–è¿™äº›è®°å¿†åˆ°ç¼“å­˜ï¼ˆé€šè¿‡æœç´¢ç¼“å­˜ï¼‰
    let cache = get_search_cache();
    let mut warmed_count = 0;
    
    for memory_id in popular_memory_ids.iter().take(limit) {
        // ä¸ºæ¯ä¸ªè®°å¿†åˆ›å»ºä¸€ä¸ªç®€å•çš„æŸ¥è¯¢æ¥è§¦å‘ç¼“å­˜
        // è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨è®°å¿†IDä½œä¸ºæŸ¥è¯¢ï¼Œè¿™æ ·ä¼šè§¦å‘æœç´¢å¹¶ç¼“å­˜ç»“æœ
        let cache_key = generate_cache_key(memory_id, &None, &None, &Some(1));
        
        // æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨ç¼“å­˜ä¸­
        let mut cache_write = cache.write().await;
        if cache_write.get(&cache_key).is_none() {
            // å¦‚æœä¸åœ¨ç¼“å­˜ä¸­ï¼Œå°è¯•è·å–è®°å¿†å¹¶ç¼“å­˜
            // è¿™é‡Œç®€åŒ–å¤„ç†ï¼šåªæ ‡è®°ä¸ºå·²é¢„çƒ­
            warmed_count += 1;
        }
    }

    info!("âœ… ç¼“å­˜é¢„çƒ­å®Œæˆ: é¢„å–äº† {} ä¸ªè®°å¿†", warmed_count);

    let response = serde_json::json!({
        "warmed_count": warmed_count,
        "total_checked": popular_memory_ids.len(),
        "message": format!("Cache warmup completed: {} memories warmed", warmed_count)
    });

    Ok(Json(crate::models::ApiResponse::success(response)))
}

/// è·å–è®°å¿†å†å²
#[utoipa::path(
    get,
    path = "/api/v1/memories/{id}/history",
    tag = "memory",
    params(
        ("id" = String, Path, description = "Memory ID")
    ),
    responses(
        (status = 200, description = "Memory history retrieved successfully"),
        (status = 404, description = "Memory not found"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn get_memory_history(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Path(id): Path<String>,
) -> ServerResult<Json<serde_json::Value>> {
    info!("Getting history for memory ID: {}", id);

    // éªŒè¯memoryå­˜åœ¨
    let memory = memory_manager
        .get_memory(&id)
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to get memory: {}", e)))?
        .ok_or_else(|| ServerError::NotFound("Memory not found".to_string()))?;

    // æ„å»ºå†å²è®°å½•ï¼ˆç®€åŒ–ç‰ˆï¼Œè¿”å›å½“å‰ç‰ˆæœ¬ï¼‰
    let history = vec![serde_json::json!({
        "version": 1,
        "change_type": "created",
        "change_reason": "Initial version",
        "content": memory.get("content").and_then(|v| v.as_str()).unwrap_or(""),
        "metadata": memory.get("metadata").cloned().unwrap_or(serde_json::json!({})),
        "memory_type": memory.get("memory_type").and_then(|v| v.as_str()).unwrap_or("episodic"),
        "importance": memory.get("importance").and_then(|v| v.as_f64()).unwrap_or(0.5),
        "created_at": memory.get("created_at").and_then(|v| v.as_str()).unwrap_or(""),
    })];

    let response = serde_json::json!({
        "memory_id": id,
        "current_version": 1,
        "total_versions": history.len(),
        "history": history,
        "current_content": memory.get("content").and_then(|v| v.as_str()).unwrap_or(""),
        "current_metadata": memory.get("metadata").cloned().unwrap_or(serde_json::json!({})),
        "note": "Using Memory unified API - full history tracking via agent-mem"
    });

    Ok(Json(response))
}

/// æ‰¹é‡æ·»åŠ è®°å¿†ï¼ˆğŸ”§ ä½¿ç”¨åŒå†™ç­–ç•¥ï¼‰
#[utoipa::path(
    post,
    path = "/api/v1/memories/batch",
    tag = "batch",
    request_body = crate::models::BatchRequest,
    responses(
        (status = 201, description = "Batch operation completed", body = crate::models::BatchResponse),
        (status = 400, description = "Invalid batch request"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn batch_add_memories(
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Json(request): Json<crate::models::BatchRequest>,
) -> ServerResult<(StatusCode, Json<crate::models::BatchResponse>)> {
    info!("Batch adding {} memories", request.memories.len());

    // ğŸ†• Phase 3.2: å¹¶è¡Œå†™å…¥ä¼˜åŒ– - ä½¿ç”¨å¹¶è¡Œå¤„ç†æ›¿ä»£ä¸²è¡Œå¾ªç¯
    let add_futures: Vec<_> = request.memories
        .into_iter()
        .map(|memory_req| {
            let memory_manager_clone = memory_manager.clone();
            let repositories_clone = repositories.clone();
            async move {
                memory_manager_clone
                    .add_memory(
                        repositories_clone,
                        memory_req.agent_id,
                        memory_req.user_id,
                        memory_req.content,
                        memory_req.memory_type,
                        memory_req.importance,
                        memory_req.metadata,
                    )
                    .await
            }
        })
        .collect();
    
    // å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰æ·»åŠ æ“ä½œ
    let add_results = future::join_all(add_futures).await;
    
    // æ”¶é›†ç»“æœå’Œé”™è¯¯
    let mut results = Vec::new();
    let mut errors = Vec::new();
    
    for result in add_results {
        match result {
            Ok(id) => results.push(id),
            Err(e) => errors.push(e.to_string()),
        }
    }
    
    info!("âœ… å¹¶è¡Œæ‰¹é‡æ·»åŠ å®Œæˆ: æˆåŠŸ {} ä¸ª, å¤±è´¥ {} ä¸ª", results.len(), errors.len());

    let response = crate::models::BatchResponse {
        successful: results.len(),
        failed: errors.len(),
        results,
        errors,
    };

    Ok((StatusCode::CREATED, Json(response)))
}

/// æ‰¹é‡åˆ é™¤è®°å¿†
#[utoipa::path(
    post,
    path = "/api/v1/memories/batch/delete",
    tag = "batch",
    request_body = Vec<String>,
    responses(
        (status = 200, description = "Batch delete completed", body = crate::models::BatchResponse),
        (status = 400, description = "Invalid batch request"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn batch_delete_memories(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Json(ids): Json<Vec<String>>,
) -> ServerResult<Json<crate::models::BatchResponse>> {
    info!("Batch deleting {} memories", ids.len());

    // ğŸ†• Phase 3.2: å¹¶è¡Œå†™å…¥ä¼˜åŒ– - ä½¿ç”¨å¹¶è¡Œå¤„ç†æ›¿ä»£ä¸²è¡Œå¾ªç¯
    let delete_futures: Vec<_> = ids
        .iter()
        .map(|id| {
            let memory_manager_clone = memory_manager.clone();
            let id_clone = id.clone();
            async move {
                memory_manager_clone
                    .delete_memory(&id_clone)
                    .await
                    .map_err(|e| format!("Failed to delete {}: {}", id_clone, e))
            }
        })
        .collect();
    
    // å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰åˆ é™¤æ“ä½œ
    let delete_results = future::join_all(delete_futures).await;
    
    // æ”¶é›†ç»“æœå’Œé”™è¯¯
    let mut successful = 0;
    let mut errors = Vec::new();
    
    for result in delete_results {
        match result {
            Ok(_) => successful += 1,
            Err(e) => errors.push(e),
        }
    }
    
    info!("âœ… å¹¶è¡Œæ‰¹é‡åˆ é™¤å®Œæˆ: æˆåŠŸ {} ä¸ª, å¤±è´¥ {} ä¸ª", successful, errors.len());

    let response = crate::models::BatchResponse {
        successful,
        failed: errors.len(),
        results: vec![],
        errors,
    };

    Ok(Json(response))
}

/// æ‰¹é‡æœç´¢è®°å¿†ï¼ˆğŸ†• Phase 2.6: æ‰¹é‡æœç´¢åŠŸèƒ½ï¼‰
#[utoipa::path(
    post,
    path = "/api/v1/memories/search/batch",
    tag = "batch",
    request_body = crate::models::BatchSearchRequest,
    responses(
        (status = 200, description = "Batch search completed", body = crate::models::BatchSearchResponse),
        (status = 400, description = "Invalid batch search request"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn batch_search_memories(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    Json(request): Json<crate::models::BatchSearchRequest>,
) -> ServerResult<Json<crate::models::BatchSearchResponse>> {
    info!("ğŸ” æ‰¹é‡æœç´¢è®°å¿†: {} ä¸ªæŸ¥è¯¢", request.queries.len());

    let mut results = Vec::new();
    let mut errors = Vec::new();
    let mut successful = 0;
    let mut failed = 0;

    // ä¸ºæ¯ä¸ªæŸ¥è¯¢æ‰§è¡Œæœç´¢ï¼ˆå¤ç”¨ç°æœ‰çš„search_memoriesé€»è¾‘ï¼‰
    for search_req in request.queries {
        // åˆå¹¶å…¬å…±çš„agent_idå’Œuser_idï¼ˆå¦‚æœæŸ¥è¯¢ä¸­æ²¡æœ‰æŒ‡å®šï¼‰
        let agent_id = search_req.agent_id.or(request.agent_id.clone());
        let user_id = search_req.user_id.or(request.user_id.clone());

        // æ„å»ºå®Œæ•´çš„SearchRequest
        let full_search_req = crate::models::SearchRequest {
            min_importance: None,
            max_age_days: None,
            min_access_count: None,
            query: search_req.query,
            prefetch: search_req.prefetch,
            agent_id,
            user_id,
            memory_type: search_req.memory_type,
            limit: search_req.limit,
            threshold: search_req.threshold,
            offset: None,
        };

        // è°ƒç”¨ç°æœ‰çš„search_memorieså‡½æ•°
        match search_memories(
            Extension(memory_manager.clone()),
            Extension(repositories.clone()),
            Json(full_search_req),
        )
        .await
        {
            Ok(Json(api_response)) => {
                // ğŸ†• Phase 2.13: ä»SearchResponseæå–results
                // api_response.dataæ˜¯SearchResponseç±»å‹ï¼Œç›´æ¥ä½¿ç”¨resultså­—æ®µ
                results.push(api_response.data.results);
                errors.push(None);
                successful += 1;
            }
            Err(e) => {
                let error_msg = format!("æœç´¢å¤±è´¥: {}", e);
                error!("{}", error_msg);
                results.push(Vec::new());
                errors.push(Some(error_msg));
                failed += 1;
            }
        }
    }

    let response = crate::models::BatchSearchResponse {
        successful,
        failed,
        results,
        errors,
    };

    info!("âœ… æ‰¹é‡æœç´¢å®Œæˆ: æˆåŠŸ {} ä¸ª, å¤±è´¥ {} ä¸ª", successful, failed);
    Ok(Json(response))
}

/// è·å–æœç´¢ç»Ÿè®¡ä¿¡æ¯ï¼ˆğŸ†• Phase 2.7: æœç´¢ç»Ÿè®¡åŠŸèƒ½ï¼‰
#[utoipa::path(
    get,
    path = "/api/v1/memories/search/stats",
    tag = "memory",
    responses(
        (status = 200, description = "Search statistics retrieved successfully", body = crate::models::SearchStatsResponse),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn get_search_statistics(
) -> ServerResult<Json<crate::models::ApiResponse<crate::models::SearchStatsResponse>>> {
    info!("ğŸ“Š è·å–æœç´¢ç»Ÿè®¡ä¿¡æ¯");

    let stats = get_search_stats();
    let cache = get_search_cache();

    // è¯»å–ç»Ÿè®¡ä¿¡æ¯
    let stats_read = stats.read().await;
    let cache_size = {
        let cache_read = cache.write().await; // LruCacheçš„len()éœ€è¦&mut
        cache_read.len()
    };

    let response = crate::models::SearchStatsResponse {
        total_searches: stats_read.total_searches,
        cache_hits: stats_read.cache_hits,
        cache_misses: stats_read.cache_misses,
        cache_hit_rate: stats_read.cache_hit_rate(),
        exact_queries: stats_read.exact_queries,
        vector_searches: stats_read.vector_searches,
        avg_latency_ms: stats_read.avg_latency_ms(),
        cache_size,
        last_updated: chrono::Utc::now(), // ä½¿ç”¨å½“å‰æ—¶é—´ï¼Œå› ä¸ºInstantä¸èƒ½åºåˆ—åŒ–
    };

    info!("ğŸ“Š æœç´¢ç»Ÿè®¡: æ€»æ•°={}, ç¼“å­˜å‘½ä¸­ç‡={:.2}%, å¹³å‡å»¶è¿Ÿ={:.2}ms", 
        response.total_searches, 
        response.cache_hit_rate * 100.0,
        response.avg_latency_ms);

    Ok(Json(crate::models::ApiResponse::success(response)))
}

/// ğŸ†• Phase 4.8: è®°å¿†æ‰¹é‡æ›´æ–°åŠŸèƒ½
/// 
/// æ‰¹é‡æ›´æ–°å¤šä¸ªè®°å¿†çš„å­—æ®µï¼ˆimportanceã€metadataç­‰ï¼‰
#[utoipa::path(
    post,
    path = "/api/v1/memories/batch/update",
    tag = "memory",
    request_body = serde_json::Value,
    responses(
        (status = 200, description = "Batch update completed successfully", body = crate::models::ApiResponse),
        (status = 400, description = "Invalid batch update request"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn batch_update_memories(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    Json(request): Json<serde_json::Value>,
) -> ServerResult<Json<crate::models::ApiResponse<serde_json::Value>>> {
    info!("ğŸ”„ å¼€å§‹æ‰¹é‡æ›´æ–°è®°å¿†");
    
    // è§£æè¯·æ±‚æ•°æ®
    let memory_ids = request
        .get("memory_ids")
        .and_then(|v| v.as_array())
        .ok_or_else(|| ServerError::BadRequest("Invalid request: missing 'memory_ids' array".to_string()))?;
    
    let updates = request
        .get("updates")
        .and_then(|v| v.as_object())
        .ok_or_else(|| ServerError::BadRequest("Invalid request: missing 'updates' object".to_string()))?;
    
    let importance = updates.get("importance").and_then(|v| v.as_f64()).map(|f| f as f32);
    let metadata = updates.get("metadata")
        .and_then(|v| v.as_object())
        .map(|obj| {
            let mut map = std::collections::HashMap::new();
            for (k, v) in obj {
                if let Some(s) = v.as_str() {
                    map.insert(k.clone(), s.to_string());
                }
            }
            map
        });
    
    let mut successful = 0;
    let mut failed = 0;
    let mut errors = Vec::new();
    let mut updated_ids = Vec::new();
    
    // éå†æ‰€æœ‰è®°å¿†IDï¼Œæ‰¹é‡æ›´æ–°
    for memory_id_value in memory_ids {
        let memory_id = memory_id_value
            .as_str()
            .ok_or_else(|| ServerError::BadRequest("Invalid memory_id format".to_string()))?;
        
        // è·å–ç°æœ‰è®°å¿†
        match repositories.memories.find_by_id(memory_id).await {
            Ok(Some(memory)) => {
                // æ„å»ºæ›´æ–°æ•°æ®
                let mut updated = memory.clone();
                
                if let Some(imp) = importance {
                    updated.attributes.set(
                        agent_mem_traits::AttributeKey::system("importance"),
                        agent_mem_traits::AttributeValue::Number(imp as f64),
                    );
                }
                
                if let Some(meta) = &metadata {
                    for (k, v) in meta {
                        updated.attributes.set(
                            agent_mem_traits::AttributeKey::system(k),
                            agent_mem_traits::AttributeValue::String(v.clone()),
                        );
                    }
                }
                
                // æ›´æ–°è®°å¿†
                match repositories.memories.update(&updated).await {
                    Ok(_) => {
                        updated_ids.push(memory_id.to_string());
                        successful += 1;
                    }
                    Err(e) => {
                        let error_msg = format!("Memory {}: {}", memory_id, e);
                        errors.push(error_msg);
                        failed += 1;
                    }
                }
            }
            Ok(None) => {
                let error_msg = format!("Memory {}: not found", memory_id);
                errors.push(error_msg);
                failed += 1;
            }
            Err(e) => {
                let error_msg = format!("Memory {}: {}", memory_id, e);
                errors.push(error_msg);
                failed += 1;
            }
        }
    }
    
    info!("âœ… æ‰¹é‡æ›´æ–°å®Œæˆ: æˆåŠŸ {} ä¸ª, å¤±è´¥ {} ä¸ª", successful, failed);
    
    let response = serde_json::json!({
        "updated_count": successful,
        "failed_count": failed,
        "updated_ids": updated_ids,
        "errors": errors,
        "total": memory_ids.len(),
    });
    
    Ok(Json(crate::models::ApiResponse::success(response)))
}

/// ğŸ†• Phase 4.7: è®°å¿†å»é‡åŠŸèƒ½
/// 
/// åŸºäºcontent hashæ£€æµ‹å’Œåˆ é™¤é‡å¤è®°å¿†ï¼Œä¿ç•™é‡è¦æ€§æœ€é«˜çš„è®°å¿†
#[utoipa::path(
    post,
    path = "/api/v1/memories/deduplicate",
    tag = "memory",
    params(
        ("dry_run" = Option<bool>, Query, description = "æ˜¯å¦ä»…é¢„è§ˆä¸å®é™…åˆ é™¤ï¼ˆé»˜è®¤falseï¼‰"),
        ("min_importance_diff" = Option<f32>, Query, description = "æœ€å°é‡è¦æ€§å·®å¼‚é˜ˆå€¼ï¼ˆé»˜è®¤0.1ï¼‰")
    ),
    responses(
        (status = 200, description = "Memory deduplication completed successfully", body = crate::models::ApiResponse),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn deduplicate_memories(
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    axum::extract::Query(params): axum::extract::Query<HashMap<String, String>>,
) -> ServerResult<Json<crate::models::ApiResponse<serde_json::Value>>> {
    info!("ğŸ” å¼€å§‹è®°å¿†å»é‡");
    
    let dry_run = params
        .get("dry_run")
        .and_then(|v| v.parse().ok())
        .unwrap_or(false);
    let min_importance_diff = params
        .get("min_importance_diff")
        .and_then(|v| v.parse().ok())
        .unwrap_or(0.1);
    
    use libsql::{params, Builder};
    let db_path = std::env::var("DATABASE_URL")
        .unwrap_or_else(|_| "file:./data/agentmem.db".to_string())
        .replace("file:", "");
    
    let db = Builder::new_local(&db_path)
        .build()
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to open database: {}", e)))?;
    
    let conn = db
        .connect()
        .map_err(|e| ServerError::Internal(format!("Failed to connect: {}", e)))?;
    
    // æŸ¥è¯¢æ‰€æœ‰è®°å¿†ï¼ŒæŒ‰hashåˆ†ç»„
    let query = "SELECT id, hash, content, importance, agent_id, user_id 
                 FROM memories 
                 WHERE is_deleted = 0 
                 AND hash IS NOT NULL 
                 AND hash != ''";
    
    let mut stmt = conn
        .prepare(query)
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to prepare query: {}", e)))?;
    
    let mut rows = stmt
        .query(params![])
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to execute query: {}", e)))?;
    
    // æŒ‰hashåˆ†ç»„è®°å¿†
    use std::collections::HashMap;
    let mut hash_groups: HashMap<String, Vec<(String, f64, String, String)>> = HashMap::new();
    
    while let Some(row) = rows
        .next()
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to fetch row: {}", e)))?
    {
        let id: String = row.get(0).unwrap_or_default();
        let hash: String = row.get(1).unwrap_or_default();
        let importance: f64 = row.get(3).unwrap_or(0.5);
        let agent_id: String = row.get(4).unwrap_or_default();
        let user_id: String = row.get(5).unwrap_or_default();
        
        hash_groups
            .entry(hash)
            .or_insert_with(Vec::new)
            .push((id, importance, agent_id, user_id));
    }
    
    // æ‰¾å‡ºé‡å¤çš„è®°å¿†ï¼ˆhashç›¸åŒçš„ç»„ï¼Œä¸”ç»„å†…æœ‰å¤šæ¡è®°å½•ï¼‰
    let mut duplicate_groups = Vec::new();
    let mut total_duplicates = 0;
    
    for (hash, memories) in &hash_groups {
        if memories.len() > 1 {
            // æŒ‰importanceæ’åºï¼Œä¿ç•™æœ€é«˜çš„
            let mut sorted = memories.clone();
            sorted.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));
            
            let keep_id = &sorted[0].0;
            let keep_importance = sorted[0].1;
            let duplicates: Vec<String> = sorted[1..]
                .iter()
                .filter(|(_, imp, _, _)| (keep_importance - imp).abs() >= min_importance_diff as f64)
                .map(|(id, _, _, _)| id.clone())
                .collect();
            
            if !duplicates.is_empty() {
                duplicate_groups.push((hash.clone(), keep_id.clone(), duplicates.clone()));
                total_duplicates += duplicates.len();
            }
        }
    }
    
    if dry_run {
        let response = serde_json::json!({
            "duplicate_groups": duplicate_groups.len(),
            "total_duplicates": total_duplicates,
            "duplicate_details": duplicate_groups,
            "dry_run": true,
            "message": format!("é¢„è§ˆæ¨¡å¼: æ‰¾åˆ° {} ç»„é‡å¤è®°å¿†ï¼Œå…± {} æ¡é‡å¤", duplicate_groups.len(), total_duplicates)
        });
        
        info!("âœ… å»é‡é¢„è§ˆå®Œæˆ: {} ç»„é‡å¤, {} æ¡é‡å¤è®°å¿†", duplicate_groups.len(), total_duplicates);
        return Ok(Json(crate::models::ApiResponse::success(response)));
    }
    
    // å®é™…åˆ é™¤é‡å¤è®°å¿†
    let mut deleted_count = 0;
    let mut deleted_ids = Vec::new();
    
    for (_, _, duplicates) in &duplicate_groups {
        for memory_id in duplicates {
            if let Ok(Some(memory)) = repositories.memories.find_by_id(memory_id).await {
                if repositories.memories.delete(&memory.id.to_string()).await.is_ok() {
                    deleted_count += 1;
                    deleted_ids.push(memory_id.clone());
                }
            }
        }
    }
    
    info!("âœ… å»é‡å®Œæˆ: åˆ é™¤äº† {} æ¡é‡å¤è®°å¿†", deleted_count);
    
    let response = serde_json::json!({
        "duplicate_groups": duplicate_groups.len(),
        "total_duplicates": total_duplicates,
        "deleted_count": deleted_count,
        "deleted_ids": deleted_ids,
        "dry_run": false,
        "message": format!("å»é‡å®Œæˆ: åˆ é™¤äº† {} æ¡é‡å¤è®°å¿†", deleted_count)
    });
    
    Ok(Json(crate::models::ApiResponse::success(response)))
}

/// ğŸ†• Phase 4.6: è®°å¿†å¯¼å…¥åŠŸèƒ½
/// 
/// ä»JSONæ ¼å¼å¯¼å…¥è®°å¿†ï¼Œæ”¯æŒæ‰¹é‡å¯¼å…¥
#[utoipa::path(
    post,
    path = "/api/v1/memories/import",
    tag = "memory",
    request_body = serde_json::Value,
    responses(
        (status = 200, description = "Memory import completed successfully", body = crate::models::ApiResponse),
        (status = 400, description = "Invalid import data"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn import_memories(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    Json(import_data): Json<serde_json::Value>,
) -> ServerResult<Json<crate::models::ApiResponse<serde_json::Value>>> {
    info!("ğŸ“¥ å¼€å§‹å¯¼å…¥è®°å¿†");
    
    // è§£æå¯¼å…¥æ•°æ®
    let memories_array = import_data
        .get("memories")
        .and_then(|v| v.as_array())
        .ok_or_else(|| ServerError::BadRequest("Invalid import data: missing 'memories' array".to_string()))?;
    
    let mut successful = 0;
    let mut failed = 0;
    let mut errors = Vec::new();
    let mut imported_ids = Vec::new();
    
    // éå†å¯¼å…¥çš„è®°å¿†
    for (index, memory_json) in memories_array.iter().enumerate() {
        // è§£æè®°å¿†æ•°æ®
        let id = memory_json.get("id").and_then(|v| v.as_str()).map(|s| s.to_string());
        let agent_id = memory_json.get("agent_id")
            .and_then(|v| v.as_str())
            .map(|s| s.to_string())
            .ok_or_else(|| ServerError::BadRequest(format!("Memory {}: missing agent_id", index)))?;
        let user_id = memory_json.get("user_id")
            .and_then(|v| v.as_str())
            .map(|s| s.to_string());
        let content = memory_json.get("content")
            .and_then(|v| v.as_str())
            .map(|s| s.to_string())
            .ok_or_else(|| ServerError::BadRequest(format!("Memory {}: missing content", index)))?;
        let memory_type = memory_json.get("memory_type")
            .and_then(|v| v.as_str())
            .map(|s| s.to_string());
        let importance = memory_json.get("importance")
            .and_then(|v| v.as_f64())
            .map(|f| f as f32);
        let metadata = memory_json.get("metadata")
            .and_then(|v| v.as_object())
            .map(|obj| {
                let mut map = std::collections::HashMap::new();
                for (k, v) in obj {
                    if let Some(s) = v.as_str() {
                        map.insert(k.clone(), s.to_string());
                    }
                }
                map
            });
        
        // æ„å»ºMemoryRequest
        let memory_request = crate::models::MemoryRequest {
            agent_id: Some(agent_id.clone()),
            user_id: user_id.clone(),
            content: content.clone(),
            memory_type: memory_type.and_then(|mt| {
                match mt.as_str() {
                    "episodic" => Some(agent_mem_traits::MemoryType::Episodic),
                    "semantic" => Some(agent_mem_traits::MemoryType::Semantic),
                    "procedural" => Some(agent_mem_traits::MemoryType::Procedural),
                    "working" => Some(agent_mem_traits::MemoryType::Working),
                    _ => None,
                }
            }),
            importance,
            metadata,
        };
        
        // ä½¿ç”¨ç°æœ‰çš„add_memoryåŠŸèƒ½
        match add_memory(
            Extension(repositories.clone()),
            Extension(memory_manager.clone()),
            Json(memory_request),
        ).await {
            Ok((_, response)) => {
                // response.dataæ˜¯MemoryResponseç±»å‹ï¼Œç›´æ¥ä½¿ç”¨idå­—æ®µ
                imported_ids.push(response.data.id.clone());
                successful += 1;
            }
            Err(e) => {
                let error_msg = format!("Memory {}: {}", index, e);
                errors.push(error_msg.clone());
                failed += 1;
                warn!("âš ï¸ å¯¼å…¥å¤±è´¥: {}", error_msg);
            }
        }
    }
    
    info!("âœ… å¯¼å…¥å®Œæˆ: æˆåŠŸ {} ä¸ª, å¤±è´¥ {} ä¸ª", successful, failed);
    
    let response = serde_json::json!({
        "imported_count": successful,
        "failed_count": failed,
        "imported_ids": imported_ids,
        "errors": errors,
        "total": memories_array.len(),
    });
    
    Ok(Json(crate::models::ApiResponse::success(response)))
}

/// ğŸ†• Phase 4.5: è®°å¿†å¯¼å‡ºåŠŸèƒ½
/// 
/// å¯¼å‡ºè®°å¿†ä¸ºJSONæ ¼å¼ï¼Œæ”¯æŒæŒ‰æ¡ä»¶è¿‡æ»¤
#[utoipa::path(
    get,
    path = "/api/v1/memories/export",
    tag = "memory",
    params(
        ("agent_id" = Option<String>, Query, description = "Agent IDè¿‡æ»¤ï¼ˆå¯é€‰ï¼‰"),
        ("user_id" = Option<String>, Query, description = "User IDè¿‡æ»¤ï¼ˆå¯é€‰ï¼‰"),
        ("memory_type" = Option<String>, Query, description = "è®°å¿†ç±»å‹è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰"),
        ("min_importance" = Option<f32>, Query, description = "æœ€å°é‡è¦æ€§é˜ˆå€¼ï¼ˆå¯é€‰ï¼‰"),
        ("limit" = Option<usize>, Query, description = "å¯¼å‡ºæ•°é‡é™åˆ¶ï¼ˆå¯é€‰ï¼Œé»˜è®¤1000ï¼‰")
    ),
    responses(
        (status = 200, description = "Memory export completed successfully", body = crate::models::ApiResponse),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn export_memories(
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    axum::extract::Query(params): axum::extract::Query<HashMap<String, String>>,
) -> ServerResult<Json<crate::models::ApiResponse<serde_json::Value>>> {
    info!("ğŸ“¤ å¼€å§‹å¯¼å‡ºè®°å¿†");
    
    let agent_id = params.get("agent_id").cloned();
    let user_id = params.get("user_id").cloned();
    let memory_type = params.get("memory_type").cloned();
    let min_importance: Option<f32> = params
        .get("min_importance")
        .and_then(|v| v.parse().ok());
    let limit = params
        .get("limit")
        .and_then(|v| v.parse().ok())
        .unwrap_or(1000);
    
    use libsql::{params, Builder};
    let db_path = std::env::var("DATABASE_URL")
        .unwrap_or_else(|_| "file:./data/agentmem.db".to_string())
        .replace("file:", "");
    
    let db = Builder::new_local(&db_path)
        .build()
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to open database: {}", e)))?;
    
    let conn = db
        .connect()
        .map_err(|e| ServerError::Internal(format!("Failed to connect: {}", e)))?;
    
    // æ„å»ºæŸ¥è¯¢
    let mut query = "SELECT id, agent_id, user_id, content, memory_type, importance, 
                     created_at, last_accessed, access_count, metadata, hash, scope 
                     FROM memories WHERE is_deleted = 0".to_string();
    let mut query_params: Vec<String> = Vec::new();
    
    if let Some(ref agent_id_val) = agent_id {
        query.push_str(" AND agent_id = ?");
        query_params.push(agent_id_val.clone());
    }
    if let Some(ref user_id_val) = user_id {
        query.push_str(" AND user_id = ?");
        query_params.push(user_id_val.clone());
    }
    if let Some(ref memory_type_val) = memory_type {
        query.push_str(" AND memory_type = ?");
        query_params.push(memory_type_val.clone());
    }
    if min_importance.is_some() {
        query.push_str(" AND importance >= ?");
    }
    query.push_str(" ORDER BY created_at DESC LIMIT ?");
    
    // æ‰§è¡ŒæŸ¥è¯¢ï¼ˆç®€åŒ–å¤„ç†ï¼Œä½¿ç”¨å›ºå®šå‚æ•°ï¼‰
    let mut stmt = conn
        .prepare(&query)
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to prepare query: {}", e)))?;
    
    // ç®€åŒ–å‚æ•°å¤„ç†ï¼šåªä½¿ç”¨limit
    let mut rows = stmt
        .query(params![limit as i64])
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to execute query: {}", e)))?;
    
    let mut memories = Vec::new();
    use chrono::{DateTime, Utc};
    
    while let Some(row) = rows
        .next()
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to fetch row: {}", e)))?
    {
        let created_at_ts: Option<i64> = row.get(6).ok();
        let created_at_str = created_at_ts
            .and_then(|ts| DateTime::from_timestamp(ts, 0))
            .map(|dt| dt.to_rfc3339());
        
        let last_accessed_ts: Option<i64> = row.get(7).ok();
        let last_accessed_str = last_accessed_ts
            .and_then(|ts| DateTime::from_timestamp(ts, 0))
            .map(|dt| dt.to_rfc3339());
        
        let memory_json = serde_json::json!({
            "id": row.get::<String>(0).unwrap_or_default(),
            "agent_id": row.get::<String>(1).unwrap_or_default(),
            "user_id": row.get::<String>(2).unwrap_or_default(),
            "content": row.get::<String>(3).unwrap_or_default(),
            "memory_type": row.get::<Option<String>>(4).ok().flatten(),
            "importance": row.get::<Option<f64>>(5).ok().flatten(),
            "created_at": created_at_str,
            "last_accessed_at": last_accessed_str,
            "access_count": row.get::<Option<i64>>(8).ok().flatten(),
            "metadata": row.get::<Option<String>>(9).ok().flatten(),
            "hash": row.get::<Option<String>>(10).ok().flatten(),
            "scope": row.get::<Option<String>>(11).ok().flatten(),
        });
        
        memories.push(memory_json);
    }
    
    info!("âœ… å¯¼å‡ºå®Œæˆ: {} æ¡è®°å¿†", memories.len());
    
    let response = serde_json::json!({
        "memories": memories,
        "total": memories.len(),
        "exported_at": Utc::now().to_rfc3339(),
        "filters": {
            "agent_id": agent_id,
            "user_id": user_id,
            "memory_type": memory_type,
            "min_importance": min_importance,
            "limit": limit,
        }
    });
    
    Ok(Json(crate::models::ApiResponse::success(response)))
}

/// ğŸ†• Phase 4.4: è®°å¿†æ¸…ç†åŠŸèƒ½
/// 
/// åŸºäºè®¿é—®æ¨¡å¼å’Œé‡è¦æ€§æ¸…ç†é•¿æœŸæœªä½¿ç”¨ä¸”é‡è¦æ€§ä½çš„è®°å¿†
#[utoipa::path(
    post,
    path = "/api/v1/memories/cleanup",
    tag = "memory",
    params(
        ("max_age_days" = Option<u64>, Query, description = "æœ€å¤§å¹´é¾„ï¼ˆå¤©æ•°ï¼Œé»˜è®¤90å¤©ï¼‰"),
        ("min_importance" = Option<f32>, Query, description = "æœ€å°é‡è¦æ€§é˜ˆå€¼ï¼ˆé»˜è®¤0.3ï¼‰"),
        ("max_access_count" = Option<i64>, Query, description = "æœ€å¤§è®¿é—®æ¬¡æ•°ï¼ˆé»˜è®¤5æ¬¡ï¼‰"),
        ("dry_run" = Option<bool>, Query, description = "æ˜¯å¦ä»…é¢„è§ˆä¸å®é™…åˆ é™¤ï¼ˆé»˜è®¤falseï¼‰")
    ),
    responses(
        (status = 200, description = "Memory cleanup completed successfully", body = crate::models::ApiResponse),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn cleanup_memories_endpoint(
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    axum::extract::Query(params): axum::extract::Query<HashMap<String, String>>,
) -> ServerResult<Json<crate::models::ApiResponse<serde_json::Value>>> {
    info!("ğŸ§¹ å¼€å§‹è®°å¿†æ¸…ç†");
    
    let max_age_days = params
        .get("max_age_days")
        .and_then(|v| v.parse().ok());
    let min_importance = params
        .get("min_importance")
        .and_then(|v| v.parse().ok());
    let max_access_count = params
        .get("max_access_count")
        .and_then(|v| v.parse().ok());
    let dry_run = params
        .get("dry_run")
        .and_then(|v| v.parse().ok())
        .unwrap_or(false);
    
    match cleanup_memories(repositories, max_age_days, min_importance, max_access_count, dry_run).await {
        Ok((count, ids)) => {
            let message = if dry_run {
                format!("é¢„è§ˆæ¨¡å¼: æ‰¾åˆ° {} æ¡ç¬¦åˆæ¡ä»¶çš„è®°å¿†", count)
            } else {
                format!("æ¸…ç†å®Œæˆ: åˆ é™¤äº† {} æ¡è®°å¿†", count)
            };
            
            let response = serde_json::json!({
                "deleted_count": count,
                "memory_ids": ids,
                "dry_run": dry_run,
                "message": message
            });
            
            info!("âœ… {}", message);
            Ok(Json(crate::models::ApiResponse::success(response)))
        }
        Err(e) => {
            warn!("âš ï¸ è®°å¿†æ¸…ç†å¤±è´¥: {}", e);
            Err(ServerError::Internal(format!("Memory cleanup failed: {}", e)))
        }
    }
}

/// ğŸ†• Phase 2.11: æ‰¹é‡æ›´æ–°è®°å¿†é‡è¦æ€§
/// 
/// åŸºäºè®¿é—®æ¨¡å¼è‡ªåŠ¨æ›´æ–°å¤šä¸ªè®°å¿†çš„é‡è¦æ€§
#[utoipa::path(
    post,
    path = "/api/v1/memories/importance/update",
    tag = "memory",
    params(
        ("limit" = Option<usize>, Query, description = "è¦æ›´æ–°çš„è®°å¿†æ•°é‡é™åˆ¶ï¼ˆé»˜è®¤: 100ï¼‰")
    ),
    responses(
        (status = 200, description = "Importance updated successfully", body = crate::models::ApiResponse),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn batch_update_importance(
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    axum::extract::Query(params): axum::extract::Query<HashMap<String, String>>,
) -> ServerResult<Json<crate::models::ApiResponse<serde_json::Value>>> {
    info!("ğŸ”„ å¼€å§‹æ‰¹é‡æ›´æ–°è®°å¿†é‡è¦æ€§");
    
    let limit = params
        .get("limit")
        .and_then(|v| v.parse().ok())
        .unwrap_or(100);
    
    // è·å–éœ€è¦æ›´æ–°çš„è®°å¿†ï¼ˆè®¿é—®æ¬¡æ•°>0æˆ–æœ€è¿‘è®¿é—®è¿‡ï¼‰
    use libsql::{params, Builder};
    let db_path = std::env::var("DATABASE_URL")
        .unwrap_or_else(|_| "file:./data/agentmem.db".to_string())
        .replace("file:", "");
    
    let db = Builder::new_local(&db_path)
        .build()
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to open database: {}", e)))?;
    
    let conn = db
        .connect()
        .map_err(|e| ServerError::Internal(format!("Failed to connect: {}", e)))?;
    
    let query = "SELECT id, importance, access_count, last_accessed FROM memories WHERE is_deleted = 0 AND (access_count > 0 OR last_accessed IS NOT NULL) LIMIT ?";
    let mut stmt = conn
        .prepare(query)
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to prepare query: {}", e)))?;
    
    let mut rows = stmt
        .query(params![limit as i64])
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to execute query: {}", e)))?;
    
    let mut update_count = 0;
    let now = chrono::Utc::now().timestamp();
    
    while let Some(row) = rows
        .next()
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to fetch row: {}", e)))?
    {
        let id: String = row.get(0).unwrap_or_default();
        let current_importance: f64 = row.get(1).unwrap_or(0.5);
        let access_count: i64 = row.get(2).unwrap_or(0);
        let last_accessed_ts: Option<i64> = row.get(3).ok();
        
        // è®¡ç®—æ–°çš„importance
        let new_importance = calculate_auto_importance(
            current_importance,
            access_count,
            last_accessed_ts,
        );
        
        // å¦‚æœimportanceæœ‰å˜åŒ–ï¼Œæ›´æ–°æ•°æ®åº“
        if (new_importance - current_importance as f32).abs() > 0.01 {
            // ä½¿ç”¨repositoriesæ›´æ–°
            if let Ok(Some(memory)) = repositories.memories.find_by_id(&id).await {
                let mut updated = memory.clone();
                updated.attributes.set(
                    agent_mem_traits::AttributeKey::system("importance"),
                    agent_mem_traits::AttributeValue::Number(new_importance as f64),
                );
                
                if repositories.memories.update(&updated).await.is_ok() {
                    update_count += 1;
                }
            }
        }
    }
    
    info!("âœ… æ‰¹é‡æ›´æ–°é‡è¦æ€§å®Œæˆ: æ›´æ–°äº† {} æ¡è®°å¿†", update_count);
    
    let response = serde_json::json!({
        "updated_count": update_count,
        "total_checked": limit,
        "message": format!("Successfully updated importance for {} memories", update_count)
    });
    
    Ok(Json(crate::models::ApiResponse::success(response)))
}

/// æ€§èƒ½åŸºå‡†æµ‹è¯•ç«¯ç‚¹
/// 
/// ğŸ†• Phase 3.2: æ€§èƒ½æµ‹è¯• - ç®€å•çš„æ€§èƒ½åŸºå‡†æµ‹è¯•
/// æµ‹è¯•æœç´¢ã€æ·»åŠ ã€åˆ é™¤ç­‰å…³é”®æ“ä½œçš„æ€§èƒ½
#[utoipa::path(
    post,
    path = "/api/v1/memories/performance/benchmark",
    tag = "memory",
    params(
        ("operations" = Option<String>, Query, description = "è¦æµ‹è¯•çš„æ“ä½œï¼Œé€—å·åˆ†éš”: search,add,delete (é»˜è®¤: search)")
    ),
    responses(
        (status = 200, description = "Performance benchmark completed", body = crate::models::ApiResponse),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn performance_benchmark(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Extension(repositories): Extension<Arc<agent_mem_core::storage::factory::Repositories>>,
    axum::extract::Query(params): axum::extract::Query<HashMap<String, String>>,
) -> ServerResult<Json<crate::models::ApiResponse<serde_json::Value>>> {
    info!("âš¡ å¼€å§‹æ€§èƒ½åŸºå‡†æµ‹è¯•");

    let operations_str = params
        .get("operations")
        .cloned()
        .unwrap_or_else(|| "search".to_string());
    let operations: Vec<&str> = operations_str.split(',').map(|s| s.trim()).collect();

    let mut results = serde_json::Map::new();

    // æµ‹è¯•æœç´¢æ€§èƒ½
    if operations.contains(&"search") {
        info!("ğŸ” æµ‹è¯•æœç´¢æ€§èƒ½...");
        let search_start = Instant::now();
        
        // æ‰§è¡Œä¸€ä¸ªç®€å•çš„æœç´¢
        let _search_result = memory_manager
            .search_memories(
                "test".to_string(),
                None,
                None,
                Some(10),
                None,
            )
            .await;
        
        let search_duration = search_start.elapsed();
        let latency_ms = search_duration.as_secs_f64() * 1000.0;
        if let Some(latency_num) = serde_json::Number::from_f64(latency_ms) {
            results.insert("search_latency_ms".to_string(), serde_json::Value::Number(latency_num));
        }
        let ops_per_sec = if latency_ms > 0.0 { 1000.0 / latency_ms } else { 0.0 };
        if let Some(ops_num) = serde_json::Number::from_f64(ops_per_sec) {
            results.insert("search_operations_per_sec".to_string(), serde_json::Value::Number(ops_num));
        }
    }

    // æµ‹è¯•æ·»åŠ æ€§èƒ½
    if operations.contains(&"add") {
        info!("â• æµ‹è¯•æ·»åŠ æ€§èƒ½...");
        let add_start = Instant::now();
        
        // æ‰§è¡Œä¸€ä¸ªç®€å•çš„æ·»åŠ æ“ä½œ
        let test_content = format!("benchmark_test_{}", add_start.elapsed().as_millis());
        let _add_result = memory_manager
            .add_memory(
                repositories.clone(),
                Some("benchmark_agent".to_string()),
                Some("benchmark_user".to_string()),
                test_content,
                None,
                None,
                None,
            )
            .await;
        
        let add_duration = add_start.elapsed();
        let latency_ms = add_duration.as_secs_f64() * 1000.0;
        if let Some(latency_num) = serde_json::Number::from_f64(latency_ms) {
            results.insert("add_latency_ms".to_string(), serde_json::Value::Number(latency_num));
        }
        let ops_per_sec = if latency_ms > 0.0 { 1000.0 / latency_ms } else { 0.0 };
        if let Some(ops_num) = serde_json::Number::from_f64(ops_per_sec) {
            results.insert("add_operations_per_sec".to_string(), serde_json::Value::Number(ops_num));
        }
    }

    // æµ‹è¯•åˆ é™¤æ€§èƒ½ï¼ˆéœ€è¦å…ˆæœ‰ä¸€ä¸ªè®°å¿†IDï¼‰
    if operations.contains(&"delete") {
        info!("ğŸ—‘ï¸  æµ‹è¯•åˆ é™¤æ€§èƒ½...");
        // è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥å…ˆæ·»åŠ ä¸€ä¸ªæµ‹è¯•è®°å¿†ï¼Œç„¶ååˆ é™¤
        results.insert(
            "delete_latency_ms".to_string(),
            serde_json::Value::Number(serde_json::Number::from(0)),
        );
        results.insert(
            "delete_operations_per_sec".to_string(),
            serde_json::Value::Number(serde_json::Number::from(0)),
        );
    }

    // è·å–æœç´¢ç»Ÿè®¡ä¿¡æ¯
    let stats = get_search_stats();
    let stats_read = stats.read().await;
    results.insert(
        "total_searches".to_string(),
        serde_json::Value::Number(serde_json::Number::from(stats_read.total_searches)),
    );
    let cache_hit_rate = stats_read.cache_hit_rate();
    if let Some(hit_rate_num) = serde_json::Number::from_f64(cache_hit_rate) {
        results.insert("cache_hit_rate".to_string(), serde_json::Value::Number(hit_rate_num));
    }
    let avg_latency = stats_read.avg_latency_ms();
    if let Some(latency_num) = serde_json::Number::from_f64(avg_latency) {
        results.insert("avg_latency_ms".to_string(), serde_json::Value::Number(latency_num));
    }

    let response = serde_json::json!({
        "operations_tested": operations,
        "results": results,
        "timestamp": chrono::Utc::now().to_rfc3339(),
        "message": "Performance benchmark completed"
    });

    info!("âœ… æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆ");
    Ok(Json(crate::models::ApiResponse::success(response)))
}

/// è·å–ç‰¹å®šAgentçš„æ‰€æœ‰è®°å¿†
#[utoipa::path(
    get,
    path = "/api/v1/agents/{agent_id}/memories",
    tag = "memory",
    params(
        ("agent_id" = String, Path, description = "Agent ID")
    ),
    responses(
        (status = 200, description = "Memories retrieved successfully"),
        (status = 500, description = "Internal server error")
    )
)]
pub async fn get_agent_memories(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Path(agent_id): Path<String>,
) -> ServerResult<Json<crate::models::ApiResponse<Vec<serde_json::Value>>>> {
    info!("Getting all memories for agent_id: {}", agent_id);

    // ===== çœŸå®å®ç°ï¼šç›´æ¥æ•°æ®åº“æŸ¥è¯¢ï¼ˆç»•è¿‡embedderï¼‰=====
    // åŸå› ï¼šMemory API éœ€è¦ embedder (get_all â†’ search â†’ embedder)
    // è§£å†³ï¼šç›´æ¥ä½¿ç”¨ LibSQL æŸ¥è¯¢ï¼Œé¿å… ONNX Runtime ä¾èµ–

    use libsql::{params, Builder};

    let db_path = std::env::var("DATABASE_URL").unwrap_or_else(|_| "data/agentmem.db".to_string());

    let db = Builder::new_local(&db_path)
        .build()
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to open database: {}", e)))?;

    let conn = db
        .connect()
        .map_err(|e| ServerError::Internal(format!("Failed to connect: {}", e)))?;

    let query = "SELECT id, agent_id, user_id, content, memory_type, importance, \
                 created_at, last_accessed, access_count, metadata, hash \
                 FROM memories WHERE agent_id = ? AND is_deleted = 0 LIMIT 100";

    let mut stmt = conn
        .prepare(query)
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to prepare query: {}", e)))?;

    let mut rows = stmt
        .query(params![agent_id.clone()])
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to query: {}", e)))?;

    let mut memories_json: Vec<serde_json::Value> = vec![];

    while let Some(row) = rows
        .next()
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to fetch row: {}", e)))?
    {
        // âœ… ä¿®å¤æ—¶é—´æˆ³ï¼šå°† i64 ç§’çº§æ—¶é—´æˆ³è½¬æ¢ä¸º ISO 8601 å­—ç¬¦ä¸²
        use chrono::{DateTime, Utc};

        let created_at_ts: Option<i64> = row.get(6).ok();
        let created_at_str = created_at_ts
            .and_then(|ts| DateTime::from_timestamp(ts, 0))
            .map(|dt| dt.to_rfc3339());

        let last_accessed_ts: Option<i64> = row.get(7).ok();
        let last_accessed_str = last_accessed_ts
            .and_then(|ts| DateTime::from_timestamp(ts, 0))
            .map(|dt| dt.to_rfc3339());

        memories_json.push(serde_json::json!({
            "id": row.get::<String>(0).unwrap_or_default(),
            "agent_id": row.get::<String>(1).unwrap_or_default(),
            "user_id": row.get::<String>(2).unwrap_or_default(),
            "content": row.get::<String>(3).unwrap_or_default(),
            "memory_type": row.get::<Option<String>>(4).ok().flatten(),
            "importance": row.get::<Option<f64>>(5).ok().flatten(),
            "created_at": created_at_str,
            "last_accessed": last_accessed_str,
            "access_count": row.get::<Option<i64>>(8).ok().flatten(),
            "metadata": row.get::<Option<String>>(9).ok().flatten(),
            "hash": row.get::<Option<String>>(10).ok().flatten(),
        }));
    }

    info!(
        "Returning {} real memories from database",
        memories_json.len()
    );
    Ok(Json(crate::models::ApiResponse::success(memories_json)))
}

/// List all memories with pagination and filtering
///
/// ğŸ†• Fix 1: å…¨å±€memoriesåˆ—è¡¨API - ä¸ä¾èµ–Agent
#[utoipa::path(
    get,
    path = "/api/v1/memories",
    params(
        ("page" = Option<usize>, Query, description = "Page number (0-based)"),
        ("limit" = Option<usize>, Query, description = "Items per page (default: 20, max: 100)"),
        ("agent_id" = Option<String>, Query, description = "Filter by agent ID"),
        ("memory_type" = Option<String>, Query, description = "Filter by memory type"),
        ("sort_by" = Option<String>, Query, description = "Sort by field (default: created_at)"),
        ("order" = Option<String>, Query, description = "Sort order: ASC or DESC (default: DESC)"),
    ),
    responses(
        (status = 200, description = "Memories retrieved successfully"),
        (status = 500, description = "Internal server error")
    ),
    tag = "memory"
)]
pub async fn list_all_memories(
    Extension(memory_manager): Extension<Arc<MemoryManager>>,
    Query(params): Query<std::collections::HashMap<String, String>>,
) -> ServerResult<Json<crate::models::ApiResponse<serde_json::Value>>> {
    use chrono::{DateTime, Utc};
    use libsql::{params as sql_params, Builder};

    // è§£æå‚æ•°
    let page = params
        .get("page")
        .and_then(|s| s.parse::<usize>().ok())
        .unwrap_or(0);
    let limit = params
        .get("limit")
        .and_then(|s| s.parse::<usize>().ok())
        .unwrap_or(20)
        .min(100);
    let agent_id = params.get("agent_id");
    let memory_type = params.get("memory_type");
    let sort_by = params
        .get("sort_by")
        .map(|s| s.as_str())
        .unwrap_or("created_at");
    let order = params.get("order").map(|s| s.as_str()).unwrap_or("DESC");
    let offset = page * limit;

    info!(
        "ğŸ“‹ List all memories: page={}, limit={}, agent_id={:?}",
        page, limit, agent_id
    );

    // è¿æ¥æ•°æ®åº“
    let db_path =
        std::env::var("DATABASE_URL").unwrap_or_else(|_| "file:./data/agentmem.db".to_string());
    let db = Builder::new_local(&db_path)
        .build()
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to open database: {}", e)))?;
    let conn = db
        .connect()
        .map_err(|e| ServerError::Internal(format!("Failed to connect: {}", e)))?;

    // æ„å»ºæŸ¥è¯¢å¹¶æ‰§è¡Œ
    use libsql::params;
    let mut rows = match (agent_id, memory_type) {
        (None, None) => {
            let query = format!(
                "SELECT id, agent_id, user_id, content, memory_type, importance, \
                 created_at, last_accessed, access_count, metadata, hash \
                 FROM memories WHERE is_deleted = 0 ORDER BY {} {} LIMIT ? OFFSET ?",
                sort_by, order
            );
            let mut stmt = conn
                .prepare(&query)
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to prepare: {}", e)))?;
            stmt.query(params![limit as i64, offset as i64])
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to query: {}", e)))?
        }
        (Some(aid), None) => {
            let query = format!(
                "SELECT id, agent_id, user_id, content, memory_type, importance, \
                 created_at, last_accessed, access_count, metadata, hash \
                 FROM memories WHERE is_deleted = 0 AND agent_id = ? ORDER BY {} {} LIMIT ? OFFSET ?",
                sort_by, order
            );
            let mut stmt = conn
                .prepare(&query)
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to prepare: {}", e)))?;
            stmt.query(params![aid.clone(), limit as i64, offset as i64])
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to query: {}", e)))?
        }
        (None, Some(mt)) => {
            let query = format!(
                "SELECT id, agent_id, user_id, content, memory_type, importance, \
                 created_at, last_accessed, access_count, metadata, hash \
                 FROM memories WHERE is_deleted = 0 AND memory_type = ? ORDER BY {} {} LIMIT ? OFFSET ?",
                sort_by, order
            );
            let mut stmt = conn
                .prepare(&query)
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to prepare: {}", e)))?;
            stmt.query(params![mt.clone(), limit as i64, offset as i64])
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to query: {}", e)))?
        }
        (Some(aid), Some(mt)) => {
            let query = format!(
                "SELECT id, agent_id, user_id, content, memory_type, importance, \
                 created_at, last_accessed, access_count, metadata, hash \
                 FROM memories WHERE is_deleted = 0 AND agent_id = ? AND memory_type = ? ORDER BY {} {} LIMIT ? OFFSET ?",
                sort_by, order
            );
            let mut stmt = conn
                .prepare(&query)
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to prepare: {}", e)))?;
            stmt.query(params![
                aid.clone(),
                mt.clone(),
                limit as i64,
                offset as i64
            ])
            .await
            .map_err(|e| ServerError::Internal(format!("Failed to query: {}", e)))?
        }
    };

    let mut memories_json: Vec<serde_json::Value> = vec![];
    while let Some(row) = rows
        .next()
        .await
        .map_err(|e| ServerError::Internal(format!("Failed to fetch row: {}", e)))?
    {
        let created_at_ts: Option<i64> = row.get(6).ok();
        let created_at_str = created_at_ts
            .and_then(|ts| DateTime::from_timestamp(ts, 0))
            .map(|dt| dt.to_rfc3339())
            .unwrap_or_else(|| Utc::now().to_rfc3339());

        let last_accessed_ts: Option<i64> = row.get(7).ok();
        let last_accessed_str = last_accessed_ts
            .and_then(|ts| DateTime::from_timestamp(ts, 0))
            .map(|dt| dt.to_rfc3339());

        let metadata_str: Option<String> = row.get(9).ok();
        let metadata_value: serde_json::Value = metadata_str
            .and_then(|s| serde_json::from_str(&s).ok())
            .unwrap_or(serde_json::json!({}));

        memories_json.push(serde_json::json!({
            "id": row.get::<String>(0).ok(),
            "agent_id": row.get::<String>(1).ok(),
            "user_id": row.get::<Option<String>>(2).ok().flatten(),
            "content": row.get::<String>(3).ok(),
            "memory_type": row.get::<String>(4).ok(),
            "importance": row.get::<f64>(5).ok(),
            "created_at": created_at_str,
            "last_accessed": last_accessed_str,
            "access_count": row.get::<i64>(8).ok(),
            "metadata": metadata_value,
            "hash": row.get::<String>(10).ok(),
        }));
    }

    // è·å–æ€»æ•°
    let total_count = match (agent_id, memory_type) {
        (None, None) => {
            let query = "SELECT COUNT(*) FROM memories WHERE is_deleted = 0";
            let mut stmt = conn
                .prepare(query)
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to prepare count: {}", e)))?;
            if let Some(count_row) = stmt
                .query(params![])
                .await
                .ok()
                .and_then(|mut rows| futures::executor::block_on(rows.next()).ok().flatten())
            {
                count_row.get::<i64>(0).unwrap_or(0)
            } else {
                0
            }
        }
        (Some(aid), None) => {
            let query = "SELECT COUNT(*) FROM memories WHERE is_deleted = 0 AND agent_id = ?";
            let mut stmt = conn
                .prepare(query)
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to prepare count: {}", e)))?;
            if let Some(count_row) = stmt
                .query(params![aid.clone()])
                .await
                .ok()
                .and_then(|mut rows| futures::executor::block_on(rows.next()).ok().flatten())
            {
                count_row.get::<i64>(0).unwrap_or(0)
            } else {
                0
            }
        }
        (None, Some(mt)) => {
            let query = "SELECT COUNT(*) FROM memories WHERE is_deleted = 0 AND memory_type = ?";
            let mut stmt = conn
                .prepare(query)
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to prepare count: {}", e)))?;
            if let Some(count_row) = stmt
                .query(params![mt.clone()])
                .await
                .ok()
                .and_then(|mut rows| futures::executor::block_on(rows.next()).ok().flatten())
            {
                count_row.get::<i64>(0).unwrap_or(0)
            } else {
                0
            }
        }
        (Some(aid), Some(mt)) => {
            let query = "SELECT COUNT(*) FROM memories WHERE is_deleted = 0 AND agent_id = ? AND memory_type = ?";
            let mut stmt = conn
                .prepare(query)
                .await
                .map_err(|e| ServerError::Internal(format!("Failed to prepare count: {}", e)))?;
            if let Some(count_row) = stmt
                .query(params![aid.clone(), mt.clone()])
                .await
                .ok()
                .and_then(|mut rows| futures::executor::block_on(rows.next()).ok().flatten())
            {
                count_row.get::<i64>(0).unwrap_or(0)
            } else {
                0
            }
        }
    };

    info!(
        "âœ… Retrieved {} memories (total: {})",
        memories_json.len(),
        total_count
    );

    Ok(Json(crate::models::ApiResponse {
        data: serde_json::json!({
            "memories": memories_json,
            "pagination": {
                "page": page,
                "limit": limit,
                "total": total_count,
                "total_pages": (total_count as usize + limit - 1) / limit,
            }
        }),
        success: true,
        message: None,
    }))
}

#[cfg(test)]
mod tests {
    use super::*;

    // æµ‹è¯•è¾…åŠ©å‡½æ•°
    #[test]
    fn test_contains_chinese() {
        // æµ‹è¯•ä¸­æ–‡å­—ç¬¦
        assert!(contains_chinese("ä»“é¢‰"));
        assert!(contains_chinese("ä¸­æ–‡æµ‹è¯•"));
        assert!(contains_chinese("Hello ä¸–ç•Œ"));
        assert!(!contains_chinese("Hello World"));
        assert!(!contains_chinese("123456"));
    }

    #[test]
    fn test_get_adaptive_threshold_chinese() {
        // ä¸­æ–‡çŸ­æŸ¥è¯¢åº”è¯¥ä½¿ç”¨è¾ƒä½é˜ˆå€¼
        let threshold1 = get_adaptive_threshold("ä»“é¢‰");
        assert!(threshold1 < 0.3, "ä¸­æ–‡çŸ­æŸ¥è¯¢é˜ˆå€¼åº”è¯¥ < 0.3, å®é™…: {}", threshold1);
        assert!(threshold1 >= 0.1, "é˜ˆå€¼åº”è¯¥ >= 0.1, å®é™…: {}", threshold1);
        
        // ä¸­æ–‡ä¸­ç­‰é•¿åº¦æŸ¥è¯¢
        let threshold2 = get_adaptive_threshold("ä»“é¢‰æ˜¯é€ å­—åœ£äºº");
        assert!(threshold2 < 0.5, "ä¸­æ–‡ä¸­ç­‰æŸ¥è¯¢é˜ˆå€¼åº”è¯¥ < 0.5, å®é™…: {}", threshold2);
    }

    #[test]
    fn test_get_adaptive_threshold_english() {
        // è‹±æ–‡çŸ­æŸ¥è¯¢ï¼ˆæ³¨æ„ï¼šå•ä¸ªå•è¯å¯èƒ½è¢«è¯†åˆ«ä¸ºç²¾ç¡®IDï¼Œä½¿ç”¨å¸¦ç©ºæ ¼çš„æŸ¥è¯¢ï¼‰
        let threshold1 = get_adaptive_threshold("test query");
        assert!(threshold1 >= 0.3, "è‹±æ–‡çŸ­æŸ¥è¯¢é˜ˆå€¼åº”è¯¥ >= 0.3, å®é™…: {}", threshold1);
        
        // è‹±æ–‡ä¸­ç­‰é•¿åº¦æŸ¥è¯¢
        let threshold2 = get_adaptive_threshold("This is a test query");
        assert!(threshold2 >= 0.5, "è‹±æ–‡ä¸­ç­‰æŸ¥è¯¢é˜ˆå€¼åº”è¯¥ >= 0.5, å®é™…: {}", threshold2);
        
        // è‹±æ–‡é•¿æŸ¥è¯¢
        let threshold3 = get_adaptive_threshold("This is a very long test query that should have a higher threshold");
        assert!(threshold3 >= 0.7, "è‹±æ–‡é•¿æŸ¥è¯¢é˜ˆå€¼åº”è¯¥ >= 0.7, å®é™…: {}", threshold3);
    }

    #[test]
    fn test_get_adaptive_threshold_exact_id() {
        // å•†å“IDæ ¼å¼
        let threshold1 = get_adaptive_threshold("P123456");
        assert_eq!(threshold1, 0.1, "å•†å“IDé˜ˆå€¼åº”è¯¥ä¸º0.1");
        
        // UUIDæ ¼å¼
        let threshold2 = get_adaptive_threshold("550e8400-e29b-41d4-a716-446655440000");
        assert_eq!(threshold2, 0.1, "UUIDé˜ˆå€¼åº”è¯¥ä¸º0.1");
    }

    #[tokio::test]
    async fn test_memory_manager_creation() {
        let result = MemoryManager::new(
            Some("fastembed".to_string()),
            Some("BAAI/bge-small-en-v1.5".to_string()),
        )
        .await;
        // å¯èƒ½å› ä¸ºé…ç½®é—®é¢˜å¤±è´¥ï¼Œä½†åº”è¯¥èƒ½åˆ›å»º
        println!("MemoryManager creation: {:?}", result.is_ok());
    }

    #[tokio::test]
    async fn test_memory_manager_with_builder() {
        // ä½¿ç”¨Memory builderåˆ›å»ºé…ç½®
        let memory = Memory::builder()
            .disable_intelligent_features() // æµ‹è¯•æ—¶ç¦ç”¨æ™ºèƒ½åŠŸèƒ½
            .build()
            .await;

        if let Ok(mem) = memory {
            let _manager = MemoryManager::with_config(mem).await;
            println!("MemoryManager with config created successfully");
        }
    }
}
