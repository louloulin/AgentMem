//! AgentOrchestrator å·¥å‚æ¨¡å—
//!
//! æä¾›åˆ›å»º AgentOrchestrator å®ä¾‹çš„å·¥å‚æ–¹æ³•ï¼Œ
//! ä¾› Chat API å’Œ Agents API å…±äº«ä½¿ç”¨ã€‚

use crate::error::{ServerError, ServerResult};
use agent_mem_core::{
    engine::{MemoryEngine, MemoryEngineConfig},
    orchestrator::{AgentOrchestrator, OrchestratorConfig},
    storage::factory::Repositories,
    storage::models::Agent,
};
use agent_mem_llm::LLMClient;
use agent_mem_tools::ToolExecutor;
use agent_mem_traits::LLMConfig;
use std::sync::Arc;
use tracing::{debug, error, info};

/// ä» Agent é…ç½®ä¸­è§£æ LLM é…ç½®
pub fn parse_llm_config(agent: &Agent) -> ServerResult<LLMConfig> {
    // agent.llm_config æ˜¯ Option<JSON> æ ¼å¼
    let llm_config_value = agent
        .llm_config
        .clone()
        .ok_or_else(|| ServerError::bad_request("Agent LLM config not set"))?;

    let mut llm_config: LLMConfig = serde_json::from_value(llm_config_value)
        .map_err(|e| ServerError::internal_error(format!("Failed to parse LLM config: {}", e)))?;

    // éªŒè¯å¿…è¦å­—æ®µ
    if llm_config.provider.is_empty() {
        return Err(ServerError::bad_request("LLM provider not configured"));
    }

    if llm_config.model.is_empty() {
        return Err(ServerError::bad_request("LLM model not configured"));
    }

    // ğŸ”§ ä»ç¯å¢ƒå˜é‡è¯»å–API keyï¼ˆå¦‚æœé…ç½®ä¸­æ²¡æœ‰ï¼‰
    if llm_config.api_key.is_none() {
        let env_var_name = format!("{}_API_KEY", llm_config.provider.to_uppercase());
        if let Ok(api_key) = std::env::var(&env_var_name) {
            debug!("Loaded API key from environment variable: {}", env_var_name);
            llm_config.api_key = Some(api_key);
        } else {
            debug!("No API key found in environment variable: {}", env_var_name);
        }
    }

    debug!(
        "Parsed LLM config: provider={}, model={}, has_api_key={}",
        llm_config.provider,
        llm_config.model,
        llm_config.api_key.is_some()
    );

    Ok(llm_config)
}

/// åˆ›å»º AgentOrchestrator å®ä¾‹
///
/// è¿™ä¸ªå‡½æ•°åˆ›å»ºä¸€ä¸ªå®Œæ•´é…ç½®çš„ AgentOrchestratorï¼ŒåŒ…æ‹¬ï¼š
/// - LLMClientï¼ˆåŸºäº agent çš„ llm_configï¼‰
/// - MemoryEngineï¼ˆç”¨äºè®°å¿†ç®¡ç†ï¼‰
/// - MessageRepositoryï¼ˆç”¨äºæ¶ˆæ¯å­˜å‚¨ï¼‰
/// - ToolExecutorï¼ˆç”¨äºå·¥å…·è°ƒç”¨ï¼‰
///
/// # Arguments
///
/// * `agent` - Agent å®ä¾‹ï¼ŒåŒ…å« LLM é…ç½®
/// * `repositories` - æ•°æ®ä»“åº“é›†åˆ
///
/// # Returns
///
/// è¿”å›é…ç½®å¥½çš„ AgentOrchestrator å®ä¾‹
pub async fn create_orchestrator(
    agent: &Agent,
    repositories: &Arc<Repositories>,
) -> ServerResult<AgentOrchestrator> {
    info!("Creating AgentOrchestrator for agent: {}", agent.id);

    // 1. è§£æ LLM é…ç½®
    let llm_config = parse_llm_config(agent)?;

    // 2. åˆ›å»º LLMClient
    let llm_client =
        Arc::new(LLMClient::new(&llm_config).map_err(|e| {
            ServerError::internal_error(format!("Failed to create LLM client: {}", e))
        })?);
    debug!("Created LLMClient with provider: {}", llm_config.provider);

    // 3. åˆ›å»º MemoryEngineï¼ˆæ³¨å…¥ LibSQL memory_repository ä»¥æ”¯æŒæŒä¹…åŒ–æœç´¢ï¼‰
    let memory_engine_config = MemoryEngineConfig::default();
    let memory_repository = repositories.memories.clone();
    let memory_engine = Arc::new(MemoryEngine::with_repository(
        memory_engine_config,
        memory_repository,
    ));
    info!("Created MemoryEngine with LibSQL repository for persistent memory search");

    // 4. è·å– MessageRepository
    let message_repo = repositories.messages.clone();
    debug!("Got MessageRepository");

    // 5. åˆ›å»º ToolExecutor å¹¶æ³¨å†Œå†…ç½®å·¥å…·
    let tool_executor = Arc::new(ToolExecutor::new());
    debug!("Created ToolExecutor");

    // æ³¨å†Œæ‰€æœ‰å†…ç½®å·¥å…·
    use agent_mem_tools::builtin::register_all_builtin_tools;
    register_all_builtin_tools(&tool_executor)
        .await
        .map_err(|e| {
            error!("Failed to register builtin tools: {}", e);
            ServerError::internal_error(format!("Failed to register builtin tools: {}", e))
        })?;
    info!("Registered all builtin tools");

    // 6. åˆ›å»º OrchestratorConfig
    let orchestrator_config = OrchestratorConfig {
        max_tool_rounds: 5,
        max_memories: 10,
        auto_extract_memories: true,
        memory_extraction_threshold: 0.5,
        enable_tool_calling: true, // âœ… å¯ç”¨å·¥å…·è°ƒç”¨
        enable_adaptive: false,    // âœ… Task 1.1-1.2ä¼˜åŒ–åå¯å¯ç”¨
        token_budget: 8000,        // âœ… Tokené¢„ç®—
        ttfb_threshold_ms: 500,    // âœ… TTFBé˜ˆå€¼ï¼ˆæ¯«ç§’ï¼‰
    };
    debug!("Created OrchestratorConfig: {:?}", orchestrator_config);

    // 7. è·å– Working Memory Storeï¼ˆç»Ÿä¸€æŠ½è±¡ï¼Œä¸å…¶ä»– repositories å¹³çº§ï¼‰
    // âœ… ç›´æ¥ä» repositories è·å–ï¼Œä¿æŒæŠ½è±¡å±‚æ¬¡ä¸€è‡´
    let working_store = Some(repositories.working_memory.clone());
    debug!("âœ… Got WorkingMemoryStore from repositories (uses unified memories table)");

    // 8. åˆ›å»º AgentOrchestrator
    let orchestrator = AgentOrchestrator::new(
        orchestrator_config,
        memory_engine,
        message_repo,
        llm_client,
        tool_executor,
        working_store,
    );

    info!(
        "Successfully created AgentOrchestrator with Working Memory support for agent: {}",
        agent.id
    );
    Ok(orchestrator)
}

#[cfg(test)]
mod tests {
    use super::*;
    use serde_json::json;

    fn create_test_agent(llm_config: Option<serde_json::Value>) -> Agent {
        Agent {
            id: "test-agent".to_string(),
            organization_id: "test-org".to_string(),
            agent_type: Some("chat".to_string()),
            name: Some("Test Agent".to_string()),
            description: Some("Test".to_string()),
            system: None,
            topic: None,
            message_ids: None,
            metadata_: None,
            llm_config,
            embedding_config: None,
            tool_rules: None,
            mcp_tools: None,
            state: Some("idle".to_string()),
            last_active_at: None,
            error_message: None,
            is_deleted: false,
            created_at: chrono::Utc::now(),
            updated_at: chrono::Utc::now(),
            created_by_id: Some("test-user".to_string()),
            last_updated_by_id: Some("test-user".to_string()),
        }
    }

    #[test]
    fn test_parse_llm_config_success() {
        let agent = create_test_agent(Some(json!({
            "provider": "openai",
            "model": "gpt-4",
            "api_key": "test-key"
        })));

        let result = parse_llm_config(&agent);
        assert!(result.is_ok());

        let config = result.unwrap();
        assert_eq!(config.provider, "openai");
        assert_eq!(config.model, "gpt-4");
    }

    #[test]
    fn test_parse_llm_config_missing_provider() {
        let agent = create_test_agent(Some(json!({
            "provider": "",
            "model": "gpt-4"
        })));

        let result = parse_llm_config(&agent);
        assert!(result.is_err());
    }

    #[test]
    fn test_parse_llm_config_missing_model() {
        let agent = create_test_agent(Some(json!({
            "provider": "openai",
            "model": ""
        })));

        let result = parse_llm_config(&agent);
        assert!(result.is_err());
    }

    #[test]
    fn test_parse_llm_config_none() {
        let agent = create_test_agent(None);

        let result = parse_llm_config(&agent);
        assert!(result.is_err());
    }
}
