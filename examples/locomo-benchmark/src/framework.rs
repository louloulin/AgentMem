//! LOCOMOæµ‹è¯•æ¡†æ¶æ ¸å¿ƒ

use crate::datasets::{DatasetLoader, ConversationSession};
use crate::metrics::PerformanceMetrics;
use crate::test_cases::{
    SingleHopTest, MultiHopTest, TemporalTest, OpenDomainTest, AdversarialTest,
};
use agent_mem::Memory;
use anyhow::Result;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;

/// æµ‹è¯•é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TestConfig {
    /// æµ‹è¯•æ•°æ®é›†è·¯å¾„
    pub dataset_path: String,
    /// æ˜¯å¦å¯ç”¨è¯¦ç»†è¾“å‡º
    pub verbose: bool,
    /// LLMé…ç½®
    pub llm_config: Option<LlmConfig>,
}

/// LLMé…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LlmConfig {
    /// LLM provider (openai, anthropic, etc.)
    pub provider: String,
    /// API key
    pub api_key: Option<String>,
    /// Model name
    pub model: String,
}

impl Default for TestConfig {
    fn default() -> Self {
        Self {
            dataset_path: "data".to_string(),
            verbose: true,
            llm_config: None,
        }
    }
}

/// æµ‹è¯•ç»“æœ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TestResult {
    /// æµ‹è¯•ç±»åˆ«
    pub category: String,
    /// æ€»æµ‹è¯•æ•°
    pub total_tests: usize,
    /// é€šè¿‡æµ‹è¯•æ•°
    pub passed_tests: usize,
    /// å‡†ç¡®æ€§å¾—åˆ†
    pub accuracy_score: f64,
    /// è¯¦ç»†æŒ‡æ ‡
    pub metrics: HashMap<String, f64>,
    /// æ€§èƒ½æŒ‡æ ‡
    pub performance: PerformanceMetrics,
    /// é”™è¯¯æ¡ˆä¾‹
    pub error_cases: Vec<ErrorCase>,
}

/// é”™è¯¯æ¡ˆä¾‹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ErrorCase {
    /// é—®é¢˜ID
    pub question_id: String,
    /// é—®é¢˜
    pub question: String,
    /// æœŸæœ›ç­”æ¡ˆ
    pub expected_answer: String,
    /// å®é™…ç­”æ¡ˆ
    pub actual_answer: String,
    /// é”™è¯¯åŸå› 
    pub error_reason: String,
}

/// æ€»ä½“æµ‹è¯•ç»“æœ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OverallTestResults {
    /// å„åˆ†ç±»æµ‹è¯•ç»“æœ
    pub category_results: HashMap<String, TestResult>,
    /// æ€»ä½“å¾—åˆ†
    pub overall_score: f64,
    /// æ€»ä½“æ€§èƒ½æŒ‡æ ‡
    pub overall_performance: PerformanceMetrics,
    /// æµ‹è¯•æ—¶é—´
    pub test_duration_secs: f64,
}

/// LOCOMOæµ‹è¯•æ¡†æ¶
pub struct LocomoTestFramework {
    config: TestConfig,
    memory: Arc<Memory>,
}

impl LocomoTestFramework {
    /// åˆ›å»ºæ–°çš„æµ‹è¯•æ¡†æ¶
    pub fn new() -> Result<Self> {
        let config = TestConfig::default();
        
        // åˆ›å»ºMemoryå®ä¾‹
        let memory = tokio::runtime::Runtime::new()?
            .block_on(async {
                Memory::builder()
                    .with_storage("memory://")
                    .with_embedder("fastembed", "BAAI/bge-small-en-v1.5")
                    .build()
                    .await
            })?;

        Self::with_config(config)
    }

    /// ä½¿ç”¨è‡ªå®šä¹‰é…ç½®åˆ›å»º
    pub fn with_config(config: TestConfig) -> Result<Self> {
        let memory = tokio::runtime::Runtime::new()?
            .block_on(async {
                Memory::builder()
                    .with_storage("memory://")
                    .with_embedder("fastembed", "BAAI/bge-small-en-v1.5")
                    .build()
                    .await
            })?;

        Ok(Self {
            config,
            memory: Arc::new(memory),
        })
    }

    /// è¿è¡Œæ‰€æœ‰æµ‹è¯•
    pub async fn run_all_tests(&self) -> Result<OverallTestResults> {
        use std::time::Instant;
        let start_time = Instant::now();

        println!("ğŸ“‹ åŠ è½½æµ‹è¯•æ•°æ®é›†...");
        let dataset_loader = DatasetLoader::new(&self.config.dataset_path);
        let datasets = dataset_loader.load_all().await?;

        let mut category_results = HashMap::new();

        // 1. Single-hopæ¨ç†æµ‹è¯•
        println!("\nğŸ” è¿è¡ŒSingle-hopæ¨ç†æµ‹è¯•...");
        let single_hop_result = self.run_single_hop_test(&datasets.single_hop).await?;
        category_results.insert("single_hop".to_string(), single_hop_result);

        // 2. Multi-hopæ¨ç†æµ‹è¯•
        println!("\nğŸ”— è¿è¡ŒMulti-hopæ¨ç†æµ‹è¯•...");
        let multi_hop_result = self.run_multi_hop_test(&datasets.multi_hop).await?;
        category_results.insert("multi_hop".to_string(), multi_hop_result);

        // 3. Temporalæ¨ç†æµ‹è¯•
        println!("\nâ° è¿è¡ŒTemporalæ¨ç†æµ‹è¯•...");
        let temporal_result = self.run_temporal_test(&datasets.temporal).await?;
        category_results.insert("temporal".to_string(), temporal_result);

        // 4. Open-domainçŸ¥è¯†æµ‹è¯•
        println!("\nğŸŒ è¿è¡ŒOpen-domainçŸ¥è¯†æµ‹è¯•...");
        let open_domain_result = self.run_open_domain_test(&datasets.open_domain).await?;
        category_results.insert("open_domain".to_string(), open_domain_result);

        // 5. Adversarialé—®é¢˜æµ‹è¯•
        println!("\nğŸ›¡ï¸ è¿è¡ŒAdversarialé—®é¢˜æµ‹è¯•...");
        let adversarial_result = self.run_adversarial_test(&datasets.adversarial).await?;
        category_results.insert("adversarial".to_string(), adversarial_result);

        // è®¡ç®—æ€»ä½“å¾—åˆ†
        let overall_score = self.calculate_overall_score(&category_results);
        let overall_performance = self.calculate_overall_performance(&category_results);
        let test_duration_secs = start_time.elapsed().as_secs_f64();

        Ok(OverallTestResults {
            category_results,
            overall_score,
            overall_performance,
            test_duration_secs,
        })
    }

    /// è¿è¡ŒSingle-hopæµ‹è¯•
    async fn run_single_hop_test(
        &self,
        test_data: &[ConversationSession],
    ) -> Result<TestResult> {
        let test = SingleHopTest::new(Arc::clone(&self.memory));
        test.run(test_data).await
    }

    /// è¿è¡ŒMulti-hopæµ‹è¯•
    async fn run_multi_hop_test(
        &self,
        test_data: &[ConversationSession],
    ) -> Result<TestResult> {
        let test = MultiHopTest::new(Arc::clone(&self.memory));
        test.run(test_data).await
    }

    /// è¿è¡ŒTemporalæµ‹è¯•
    async fn run_temporal_test(
        &self,
        test_data: &[ConversationSession],
    ) -> Result<TestResult> {
        let test = TemporalTest::new(Arc::clone(&self.memory));
        test.run(test_data).await
    }

    /// è¿è¡ŒOpen-domainæµ‹è¯•
    async fn run_open_domain_test(
        &self,
        test_data: &[ConversationSession],
    ) -> Result<TestResult> {
        let test = OpenDomainTest::new(Arc::clone(&self.memory));
        test.run(test_data).await
    }

    /// è¿è¡ŒAdversarialæµ‹è¯•
    async fn run_adversarial_test(
        &self,
        test_data: &[ConversationSession],
    ) -> Result<TestResult> {
        let test = AdversarialTest::new(Arc::clone(&self.memory));
        test.run(test_data).await
    }

    /// è®¡ç®—æ€»ä½“å¾—åˆ†
    fn calculate_overall_score(&self, results: &HashMap<String, TestResult>) -> f64 {
        let scores: Vec<f64> = results.values().map(|r| r.accuracy_score).collect();
        if scores.is_empty() {
            return 0.0;
        }
        scores.iter().sum::<f64>() / scores.len() as f64
    }

    /// è®¡ç®—æ€»ä½“æ€§èƒ½æŒ‡æ ‡
    fn calculate_overall_performance(
        &self,
        results: &HashMap<String, TestResult>,
    ) -> PerformanceMetrics {
        let mut all_search_latencies = Vec::new();
        let mut all_total_latencies = Vec::new();
        let mut total_tokens = 0;
        let mut count = 0;

        for result in results.values() {
            all_search_latencies.push(result.performance.avg_search_latency_ms);
            all_total_latencies.push(
                result.performance.avg_search_latency_ms
                    + result.performance.avg_generation_latency_ms,
            );
            total_tokens += result.performance.avg_tokens;
            count += 1;
        }

        // è®¡ç®—P95å»¶è¿Ÿ
        all_search_latencies.sort_by(|a, b| a.partial_cmp(b).unwrap());
        all_total_latencies.sort_by(|a, b| a.partial_cmp(b).unwrap());

        let p95_search = if !all_search_latencies.is_empty() {
            let index = (all_search_latencies.len() as f64 * 0.95) as usize;
            all_search_latencies[index.min(all_search_latencies.len() - 1)]
        } else {
            0.0
        };

        let p95_total = if !all_total_latencies.is_empty() {
            let index = (all_total_latencies.len() as f64 * 0.95) as usize;
            all_total_latencies[index.min(all_total_latencies.len() - 1)]
        } else {
            0.0
        };

        PerformanceMetrics {
            avg_search_latency_ms: if count > 0 {
                all_search_latencies.iter().sum::<f64>() / count as f64
            } else {
                0.0
            },
            avg_generation_latency_ms: if count > 0 {
                results
                    .values()
                    .map(|r| r.performance.avg_generation_latency_ms)
                    .sum::<f64>()
                    / count as f64
            } else {
                0.0
            },
            p95_search_latency_ms: p95_search,
            p95_total_latency_ms: p95_total,
            avg_tokens: if count > 0 { total_tokens / count } else { 0 },
        }
    }
}
