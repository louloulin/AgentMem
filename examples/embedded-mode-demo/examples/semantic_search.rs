//! è¯­ä¹‰æœç´¢ç¤ºä¾‹
//! 
//! å±•ç¤ºå¦‚ä½•ä½¿ç”¨ AgentMem è¿›è¡Œè¯­ä¹‰æœç´¢ï¼š
//! - æ–‡æ¡£å‘é‡åŒ–
//! - ç›¸ä¼¼åº¦æœç´¢
//! - å…ƒæ•°æ®è¿‡æ»¤
//! - ç»“æœæ’åº

use agent_mem_storage::backends::LanceDBVectorStore;
use agent_mem_traits::{VectorData, VectorStore};
use std::collections::HashMap;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ” AgentMem è¯­ä¹‰æœç´¢ç¤ºä¾‹\n");

    // 1. åˆ›å»ºå‘é‡å­˜å‚¨
    println!("ğŸ“¦ åˆ›å»ºå‘é‡å­˜å‚¨...");
    let store = LanceDBVectorStore::new("./semantic-data/vectors.lance", "vectors").await?;
    println!("âœ… åˆ›å»ºæˆåŠŸ\n");

    // 2. å‡†å¤‡æ–‡æ¡£æ•°æ®ï¼ˆæ¨¡æ‹Ÿå·²å‘é‡åŒ–çš„æ–‡æ¡£ï¼‰
    println!("ğŸ“š å‡†å¤‡æ–‡æ¡£æ•°æ®...");
    let documents = vec![
        ("doc1", "Rust æ˜¯ä¸€ç§ç³»ç»Ÿç¼–ç¨‹è¯­è¨€", vec![0.8, 0.2, 0.1, 0.9], "programming"),
        ("doc2", "Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€", vec![0.7, 0.3, 0.2, 0.8], "programming"),
        ("doc3", "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯", vec![0.1, 0.9, 0.8, 0.2], "ai"),
        ("doc4", "æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œ", vec![0.2, 0.8, 0.9, 0.1], "ai"),
        ("doc5", "æ•°æ®åº“ç”¨äºå­˜å‚¨æ•°æ®", vec![0.6, 0.4, 0.3, 0.7], "database"),
        ("doc6", "å‘é‡æ•°æ®åº“æ”¯æŒç›¸ä¼¼åº¦æœç´¢", vec![0.5, 0.5, 0.6, 0.4], "database"),
    ];

    let vectors: Vec<VectorData> = documents
        .iter()
        .map(|(id, text, vec, category)| {
            // æ‰©å±•å‘é‡åˆ° 384 ç»´ï¼ˆé‡å¤æ¨¡å¼ï¼‰
            let mut full_vector = Vec::new();
            for _ in 0..96 {
                full_vector.extend_from_slice(vec);
            }
            
            VectorData {
                id: id.to_string(),
                vector: full_vector,
                metadata: HashMap::from([
                    ("text".to_string(), text.to_string()),
                    ("category".to_string(), category.to_string()),
                    ("language".to_string(), "zh".to_string()),
                ]),
            }
        })
        .collect();

    store.add_vectors(vectors).await?;
    println!("âœ… æ’å…¥ {} ä¸ªæ–‡æ¡£\n", documents.len());

    // 3. è¯­ä¹‰æœç´¢ï¼šæŸ¥æ‰¾ç¼–ç¨‹ç›¸å…³æ–‡æ¡£
    println!("ğŸ” æœç´¢ 1: æŸ¥æ‰¾ç¼–ç¨‹ç›¸å…³æ–‡æ¡£");
    let query1 = vec![0.75, 0.25, 0.15, 0.85]; // ç±»ä¼¼ "ç¼–ç¨‹è¯­è¨€" çš„å‘é‡
    let mut query_vector1 = Vec::new();
    for _ in 0..96 {
        query_vector1.extend_from_slice(&query1);
    }
    
    let results = store.search_vectors(query_vector1, 3, None).await?;
    println!("æ‰¾åˆ° {} ä¸ªç»“æœ:", results.len());
    for (i, result) in results.iter().enumerate() {
        let text = result.metadata.get("text").map(|s| s.as_str()).unwrap_or("");
        let category = result.metadata.get("category").map(|s| s.as_str()).unwrap_or("");
        println!("  {}. [{}] {} (ç›¸ä¼¼åº¦: {:.4})",
            i + 1, category, text, result.similarity);
    }
    println!();

    // 4. è¯­ä¹‰æœç´¢ï¼šæŸ¥æ‰¾ AI ç›¸å…³æ–‡æ¡£
    println!("ğŸ” æœç´¢ 2: æŸ¥æ‰¾ AI ç›¸å…³æ–‡æ¡£");
    let query2 = vec![0.15, 0.85, 0.85, 0.15]; // ç±»ä¼¼ "äººå·¥æ™ºèƒ½" çš„å‘é‡
    let mut query_vector2 = Vec::new();
    for _ in 0..96 {
        query_vector2.extend_from_slice(&query2);
    }
    
    let results = store.search_vectors(query_vector2, 3, None).await?;
    println!("æ‰¾åˆ° {} ä¸ªç»“æœ:", results.len());
    for (i, result) in results.iter().enumerate() {
        let text = result.metadata.get("text").map(|s| s.as_str()).unwrap_or("");
        let category = result.metadata.get("category").map(|s| s.as_str()).unwrap_or("");
        println!("  {}. [{}] {} (ç›¸ä¼¼åº¦: {:.4})",
            i + 1, category, text, result.similarity);
    }
    println!();

    // 5. è¯­ä¹‰æœç´¢ï¼šæŸ¥æ‰¾æ•°æ®åº“ç›¸å…³æ–‡æ¡£
    println!("ğŸ” æœç´¢ 3: æŸ¥æ‰¾æ•°æ®åº“ç›¸å…³æ–‡æ¡£");
    let query3 = vec![0.55, 0.45, 0.45, 0.55]; // ç±»ä¼¼ "æ•°æ®åº“" çš„å‘é‡
    let mut query_vector3 = Vec::new();
    for _ in 0..96 {
        query_vector3.extend_from_slice(&query3);
    }
    
    let results = store.search_vectors(query_vector3, 3, None).await?;
    println!("æ‰¾åˆ° {} ä¸ªç»“æœ:", results.len());
    for (i, result) in results.iter().enumerate() {
        let text = result.metadata.get("text").map(|s| s.as_str()).unwrap_or("");
        let category = result.metadata.get("category").map(|s| s.as_str()).unwrap_or("");
        println!("  {}. [{}] {} (ç›¸ä¼¼åº¦: {:.4})",
            i + 1, category, text, result.similarity);
    }
    println!();

    // 6. è·å–ç‰¹å®šæ–‡æ¡£
    println!("ğŸ“„ è·å–ç‰¹å®šæ–‡æ¡£ (doc3):");
    if let Some(doc) = store.get_vector("doc3").await? {
        let text = doc.metadata.get("text").map(|s| s.as_str()).unwrap_or("");
        let category = doc.metadata.get("category").map(|s| s.as_str()).unwrap_or("");
        println!("  æ–‡æœ¬: {}", text);
        println!("  ç±»åˆ«: {}", category);
        println!("  å‘é‡ç»´åº¦: {}", doc.vector.len());
    }
    println!();

    // 7. ç»Ÿè®¡ä¿¡æ¯
    println!("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:");
    let stats = store.get_stats().await?;
    println!("  æ€»æ–‡æ¡£æ•°: {}", stats.total_vectors);
    println!("  å‘é‡ç»´åº¦: {}", stats.dimension);
    println!();

    println!("ğŸ‰ è¯­ä¹‰æœç´¢ç¤ºä¾‹å®Œæˆï¼");
    println!("ğŸ’¡ æç¤º: åœ¨å®é™…åº”ç”¨ä¸­ï¼Œä½¿ç”¨ OpenAI/HuggingFace ç­‰æ¨¡å‹ç”ŸæˆçœŸå®çš„æ–‡æœ¬å‘é‡");

    Ok(())
}

