//! AgentMem å‘é‡æœç´¢ç¤ºä¾‹
//!
//! æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ LanceDB è¿›è¡Œå‘é‡å­˜å‚¨å’Œè¯­ä¹‰æœç´¢

use agent_mem_storage::backends::lancedb_store::LanceDBStore;
use agent_mem_traits::{VectorData, VectorStore};
use anyhow::Result;
use std::collections::HashMap;
use tracing::{info, Level};
use tracing_subscriber;

#[tokio::main]
async fn main() -> Result<()> {
    // åˆå§‹åŒ–æ—¥å¿—
    tracing_subscriber::fmt().with_max_level(Level::INFO).init();

    info!("ğŸš€ AgentMem å‘é‡æœç´¢ç¤ºä¾‹");

    // 1. åˆ›å»º LanceDB å‘é‡å­˜å‚¨
    info!("ğŸ”§ åˆ›å»º LanceDB å‘é‡å­˜å‚¨...");
    let vector_store = LanceDBStore::new("./data/vectors.lance", "embeddings").await?;
    info!("âœ… LanceDB å‘é‡å­˜å‚¨åˆ›å»ºæˆåŠŸ");

    // 2. å‡†å¤‡ç¤ºä¾‹å‘é‡æ•°æ®ï¼ˆæ¨¡æ‹Ÿæ–‡æœ¬åµŒå…¥ï¼‰
    info!("\nğŸ“ å‡†å¤‡ç¤ºä¾‹å‘é‡æ•°æ®...");

    let vectors = vec![
        VectorData {
            id: "doc1".to_string(),
            vector: generate_mock_embedding("Rust æ˜¯ä¸€é—¨ç³»ç»Ÿç¼–ç¨‹è¯­è¨€"),
            metadata: HashMap::from([
                ("text".to_string(), "Rust æ˜¯ä¸€é—¨ç³»ç»Ÿç¼–ç¨‹è¯­è¨€".to_string()),
                ("category".to_string(), "programming".to_string()),
                ("language".to_string(), "zh".to_string()),
            ]),
        },
        VectorData {
            id: "doc2".to_string(),
            vector: generate_mock_embedding("Python æ˜¯ä¸€é—¨é«˜çº§ç¼–ç¨‹è¯­è¨€"),
            metadata: HashMap::from([
                ("text".to_string(), "Python æ˜¯ä¸€é—¨é«˜çº§ç¼–ç¨‹è¯­è¨€".to_string()),
                ("category".to_string(), "programming".to_string()),
                ("language".to_string(), "zh".to_string()),
            ]),
        },
        VectorData {
            id: "doc3".to_string(),
            vector: generate_mock_embedding("æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯"),
            metadata: HashMap::from([
                (
                    "text".to_string(),
                    "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯".to_string(),
                ),
                ("category".to_string(), "ai".to_string()),
                ("language".to_string(), "zh".to_string()),
            ]),
        },
        VectorData {
            id: "doc4".to_string(),
            vector: generate_mock_embedding("æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œ"),
            metadata: HashMap::from([
                ("text".to_string(), "æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œ".to_string()),
                ("category".to_string(), "ai".to_string()),
                ("language".to_string(), "zh".to_string()),
            ]),
        },
        VectorData {
            id: "doc5".to_string(),
            vector: generate_mock_embedding("æ•°æ®åº“ç”¨äºå­˜å‚¨å’Œç®¡ç†æ•°æ®"),
            metadata: HashMap::from([
                ("text".to_string(), "æ•°æ®åº“ç”¨äºå­˜å‚¨å’Œç®¡ç†æ•°æ®".to_string()),
                ("category".to_string(), "database".to_string()),
                ("language".to_string(), "zh".to_string()),
            ]),
        },
    ];

    info!("âœ… å‡†å¤‡äº† {} ä¸ªå‘é‡", vectors.len());

    // 3. æ’å…¥å‘é‡
    info!("\nğŸ’¾ æ’å…¥å‘é‡åˆ° LanceDB...");
    let start = std::time::Instant::now();
    vector_store.add_vectors(vectors.clone()).await?;
    let duration = start.elapsed();
    info!("âœ… æ’å…¥å®Œæˆï¼Œè€—æ—¶: {:?}", duration);

    // 4. æ‰§è¡Œè¯­ä¹‰æœç´¢
    info!("\nğŸ” æ‰§è¡Œè¯­ä¹‰æœç´¢...");

    // æœç´¢ 1: æŸ¥æ‰¾ä¸ "ç¼–ç¨‹è¯­è¨€" ç›¸å…³çš„æ–‡æ¡£
    info!("\næŸ¥è¯¢ 1: æŸ¥æ‰¾ä¸ 'ç¼–ç¨‹è¯­è¨€' ç›¸å…³çš„æ–‡æ¡£");
    let query1 = generate_mock_embedding("ç¼–ç¨‹è¯­è¨€");
    let results1 = vector_store.search_vectors(query1, 3, None).await?;

    info!("æ‰¾åˆ° {} ä¸ªç»“æœ:", results1.len());
    for (i, result) in results1.iter().enumerate() {
        let text = result
            .metadata
            .get("text")
            .map(|v| v.as_str())
            .unwrap_or("N/A");
        info!("  {}. [ç›¸ä¼¼åº¦: {:.4}] {}", i + 1, result.similarity, text);
    }

    // æœç´¢ 2: æŸ¥æ‰¾ä¸ "äººå·¥æ™ºèƒ½" ç›¸å…³çš„æ–‡æ¡£
    info!("\næŸ¥è¯¢ 2: æŸ¥æ‰¾ä¸ 'äººå·¥æ™ºèƒ½' ç›¸å…³çš„æ–‡æ¡£");
    let query2 = generate_mock_embedding("äººå·¥æ™ºèƒ½");
    let results2 = vector_store.search_vectors(query2, 3, Some(0.5)).await?;

    info!("æ‰¾åˆ° {} ä¸ªç»“æœ (ç›¸ä¼¼åº¦é˜ˆå€¼ > 0.5):", results2.len());
    for (i, result) in results2.iter().enumerate() {
        let text = result
            .metadata
            .get("text")
            .map(|v| v.as_str())
            .unwrap_or("N/A");
        info!("  {}. [ç›¸ä¼¼åº¦: {:.4}] {}", i + 1, result.similarity, text);
    }

    // 5. è·å–å•ä¸ªå‘é‡
    info!("\nğŸ“„ è·å–å•ä¸ªå‘é‡...");
    if let Some(vector) = vector_store.get_vector("doc1").await? {
        let text = vector
            .metadata
            .get("text")
            .map(|v| v.as_str())
            .unwrap_or("N/A");
        info!("âœ… æ‰¾åˆ°å‘é‡ doc1: {}", text);
        info!("   å‘é‡ç»´åº¦: {}", vector.vector.len());
    }

    // 6. æ›´æ–°å‘é‡
    info!("\nğŸ“ æ›´æ–°å‘é‡...");
    let updated_vector = VectorData {
        id: "doc1".to_string(),
        vector: generate_mock_embedding("Rust æ˜¯ä¸€é—¨å®‰å…¨é«˜æ•ˆçš„ç³»ç»Ÿç¼–ç¨‹è¯­è¨€"),
        metadata: HashMap::from([
            (
                "text".to_string(),
                "Rust æ˜¯ä¸€é—¨å®‰å…¨é«˜æ•ˆçš„ç³»ç»Ÿç¼–ç¨‹è¯­è¨€".to_string(),
            ),
            ("category".to_string(), "programming".to_string()),
            ("language".to_string(), "zh".to_string()),
            ("updated".to_string(), "true".to_string()),
        ]),
    };

    vector_store.update_vectors(vec![updated_vector]).await?;
    info!("âœ… å‘é‡æ›´æ–°æˆåŠŸ");

    // éªŒè¯æ›´æ–°
    if let Some(vector) = vector_store.get_vector("doc1").await? {
        let text = vector
            .metadata
            .get("text")
            .map(|v| v.as_str())
            .unwrap_or("N/A");
        let updated = vector
            .metadata
            .get("updated")
            .map(|v| v.as_str())
            .unwrap_or("false");
        info!("âœ… éªŒè¯æ›´æ–°: {} (updated={})", text, updated);
    }

    // 7. åˆ é™¤å‘é‡
    info!("\nğŸ—‘ï¸  åˆ é™¤å‘é‡...");
    vector_store
        .delete_vectors(vec!["doc5".to_string()])
        .await?;
    info!("âœ… å‘é‡ doc5 å·²åˆ é™¤");

    // éªŒè¯åˆ é™¤
    if let Some(_) = vector_store.get_vector("doc5").await? {
        info!("âŒ é”™è¯¯: å‘é‡ doc5 åº”è¯¥å·²è¢«åˆ é™¤");
    } else {
        info!("âœ… éªŒè¯åˆ é™¤æˆåŠŸ: å‘é‡ doc5 ä¸å­˜åœ¨");
    }

    // 8. ç»Ÿè®¡ä¿¡æ¯
    info!("\nğŸ“Š å‘é‡å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯...");
    let stats = vector_store.get_stats().await?;
    info!("  æ€»å‘é‡æ•°: {}", stats.total_vectors);
    info!("  å‘é‡ç»´åº¦: {}", stats.dimension);
    info!("  ç´¢å¼•å¤§å°: {} bytes", stats.index_size);

    info!("\nğŸ‰ å‘é‡æœç´¢ç¤ºä¾‹å®Œæˆï¼");
    info!("ğŸ’¾ å‘é‡æ•°æ®å·²ä¿å­˜åˆ°: ./data/vectors.lance");

    Ok(())
}

/// ç”Ÿæˆæ¨¡æ‹Ÿçš„æ–‡æœ¬åµŒå…¥å‘é‡
///
/// æ³¨æ„: è¿™åªæ˜¯ä¸€ä¸ªç®€åŒ–çš„ç¤ºä¾‹ï¼Œå®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨çœŸå®çš„åµŒå…¥æ¨¡å‹
/// å¦‚ OpenAI embeddings, sentence-transformers ç­‰
fn generate_mock_embedding(text: &str) -> Vec<f32> {
    // ä½¿ç”¨ç®€å•çš„å“ˆå¸Œå‡½æ•°ç”Ÿæˆç¡®å®šæ€§çš„å‘é‡
    // å®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨çœŸå®çš„åµŒå…¥æ¨¡å‹
    let mut vector = vec![0.0; 1536];

    // åŸºäºæ–‡æœ¬å†…å®¹ç”Ÿæˆå‘é‡
    for (i, byte) in text.bytes().enumerate() {
        let idx = (i * 7 + byte as usize) % 1536;
        vector[idx] += 0.1;
    }

    // å½’ä¸€åŒ–
    let norm: f32 = vector.iter().map(|x| x * x).sum::<f32>().sqrt();
    if norm > 0.0 {
        for v in &mut vector {
            *v /= norm;
        }
    }

    vector
}
