//! LLM è®°å¿†æ•ˆæœå…¨é¢åˆ†ææ¼”ç¤º
//!
//! æœ¬ç¤ºä¾‹æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨çœŸå®çš„ LLM è¿›è¡Œï¼š
//! 1. æ™ºèƒ½è®°å¿†æå–å’Œåˆ†ç±»
//! 2. è®°å¿†è´¨é‡è¯„ä¼°
//! 3. è®°å¿†æ£€ç´¢æ•ˆæœåˆ†æ
//! 4. è®°å¿†èåˆå’Œå†²çªè§£å†³
//! 5. é•¿æœŸè®°å¿†æ•ˆæœè¿½è¸ª

use agent_mem_llm::factory::RealLLMFactory;
use agent_mem_traits::{LLMConfig, LLMProvider, MemoryType, Message, MessageRole};
use chrono::Utc;
use colored::*;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use tracing::{debug, info, warn};

/// è®°å¿†åˆ†æç»“æœ
#[derive(Debug, Clone, Serialize, Deserialize)]
struct MemoryAnalysis {
    /// è®°å¿† ID
    memory_id: String,
    /// è®°å¿†å†…å®¹
    content: String,
    /// è®°å¿†ç±»å‹
    memory_type: MemoryType,
    /// é‡è¦æ€§åˆ†æ•°
    importance: f32,
    /// è´¨é‡è¯„åˆ†
    quality_score: f32,
    /// ç›¸å…³æ€§è¯„åˆ†
    relevance_score: f32,
    /// æå–çš„å®ä½“
    entities: Vec<String>,
    /// æå–çš„å…³ç³»
    relations: Vec<String>,
    /// LLM è¯„ä¼°æ„è§
    llm_assessment: String,
}

/// è®°å¿†æ•ˆæœç»Ÿè®¡
#[derive(Debug, Clone, Serialize, Deserialize)]
struct MemoryEffectivenessStats {
    /// æ€»è®°å¿†æ•°
    total_memories: usize,
    /// é«˜è´¨é‡è®°å¿†æ•°ï¼ˆè´¨é‡åˆ†æ•° > 0.7ï¼‰
    high_quality_count: usize,
    /// å¹³å‡è´¨é‡åˆ†æ•°
    avg_quality_score: f32,
    /// å¹³å‡é‡è¦æ€§åˆ†æ•°
    avg_importance: f32,
    /// è®°å¿†ç±»å‹åˆ†å¸ƒ
    type_distribution: HashMap<String, usize>,
    /// æ£€ç´¢å‡†ç¡®ç‡
    retrieval_accuracy: f32,
    /// è®°å¿†èåˆæˆåŠŸç‡
    fusion_success_rate: f32,
}

/// æ¸…ç† LLM å“åº”ï¼Œç§»é™¤ Markdown ä»£ç å—æ ‡è®°
fn clean_llm_response(response: &str) -> String {
    let trimmed = response.trim();

    // ç§»é™¤ ```json ... ``` æˆ– ``` ... ``` åŒ…è£¹
    let cleaned = if trimmed.starts_with("```") {
        let without_start = trimmed
            .strip_prefix("```json")
            .or_else(|| trimmed.strip_prefix("```"))
            .unwrap_or(trimmed);

        without_start
            .strip_suffix("```")
            .unwrap_or(without_start)
            .trim()
    } else {
        trimmed
    };

    cleaned.to_string()
}

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    // åˆå§‹åŒ–æ—¥å¿—
    tracing_subscriber::fmt()
        .with_env_filter("info,agent_mem_core=debug")
        .init();

    println!(
        "{}",
        "=== AgentMem LLM è®°å¿†æ•ˆæœå…¨é¢åˆ†æ ===".bright_cyan().bold()
    );
    println!();

    // åˆ›å»º LLM æä¾›å•†
    let llm_provider = create_llm_provider().await?;
    info!("âœ… LLM æä¾›å•†åˆ›å»ºæˆåŠŸ");

    // è¿è¡Œæ‰€æœ‰æ¼”ç¤º
    demo_1_intelligent_extraction(&llm_provider).await?;
    demo_2_memory_quality_assessment(&llm_provider).await?;
    demo_3_retrieval_effectiveness(&llm_provider).await?;
    demo_4_memory_fusion(&llm_provider).await?;
    demo_5_long_term_tracking(&llm_provider).await?;
    demo_6_comprehensive_analysis(&llm_provider).await?;

    println!();
    println!("{}", "=== æ‰€æœ‰æ¼”ç¤ºå®Œæˆ ===".bright_green().bold());
    println!();
    println!("âœ… éªŒè¯ç»“æœï¼š");
    println!("  â€¢ æ™ºèƒ½è®°å¿†æå–ï¼šLLM èƒ½å¤Ÿå‡†ç¡®è¯†åˆ«å’Œåˆ†ç±»è®°å¿†");
    println!("  â€¢ è®°å¿†è´¨é‡è¯„ä¼°ï¼šLLM èƒ½å¤Ÿè¯„ä¼°è®°å¿†çš„è´¨é‡å’Œé‡è¦æ€§");
    println!("  â€¢ æ£€ç´¢æ•ˆæœåˆ†æï¼šLLM èƒ½å¤Ÿä¼˜åŒ–è®°å¿†æ£€ç´¢å’Œæ’åº");
    println!("  â€¢ è®°å¿†èåˆï¼šLLM èƒ½å¤Ÿæ™ºèƒ½åˆå¹¶å’Œè§£å†³å†²çª");
    println!("  â€¢ é•¿æœŸè¿½è¸ªï¼šLLM èƒ½å¤Ÿåˆ†æè®°å¿†æ¼”åŒ–å’Œè¡°å‡");

    Ok(())
}

/// æ¼”ç¤º 1: æ™ºèƒ½è®°å¿†æå–
async fn demo_1_intelligent_extraction(
    llm_provider: &Arc<dyn LLMProvider + Send + Sync>,
) -> anyhow::Result<()> {
    println!("{}", "\nğŸ“Š æ¼”ç¤º 1: æ™ºèƒ½è®°å¿†æå–".bright_yellow().bold());
    println!("{}", "â”€".repeat(60).bright_black());

    // æ¨¡æ‹Ÿå¯¹è¯
    let messages = vec![
        Message {
            role: MessageRole::User,
            content: "æˆ‘å«å¼ ä¸‰ï¼Œä»Šå¹´30å²ï¼Œåœ¨åŒ—äº¬å·¥ä½œã€‚".to_string(),
            timestamp: Some(Utc::now()),
        },
        Message {
            role: MessageRole::Assistant,
            content: "ä½ å¥½å¼ ä¸‰ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚ä½ åœ¨åŒ—äº¬ä»äº‹ä»€ä¹ˆå·¥ä½œå‘¢ï¼Ÿ".to_string(),
            timestamp: Some(Utc::now()),
        },
        Message {
            role: MessageRole::User,
            content: "æˆ‘æ˜¯ä¸€åè½¯ä»¶å·¥ç¨‹å¸ˆï¼Œä¸»è¦åš Rust å¼€å‘ã€‚æˆ‘æœ€å–œæ¬¢çš„ç¼–ç¨‹è¯­è¨€æ˜¯ Rustï¼Œå› ä¸ºå®ƒå®‰å…¨åˆé«˜æ•ˆã€‚".to_string(),
            timestamp: Some(Utc::now()),
        },
        Message {
            role: MessageRole::Assistant,
            content: "Rust ç¡®å®æ˜¯ä¸€é—¨å¾ˆæ£’çš„è¯­è¨€ï¼ä½ å¹³æ—¶ç”¨ Rust å¼€å‘ä»€ä¹ˆç±»å‹çš„é¡¹ç›®ï¼Ÿ".to_string(),
            timestamp: Some(Utc::now()),
        },
        Message {
            role: MessageRole::User,
            content: "ä¸»è¦æ˜¯åç«¯æœåŠ¡å’Œç³»ç»Ÿå·¥å…·ã€‚æˆ‘è¿˜å–œæ¬¢é˜…è¯»æŠ€æœ¯ä¹¦ç±ï¼Œæœ€è¿‘åœ¨è¯»ã€ŠRust ç¨‹åºè®¾è®¡ã€‹ã€‚".to_string(),
            timestamp: Some(Utc::now()),
        },
    ];

    println!("ğŸ“ è¾“å…¥å¯¹è¯ï¼ˆ{} è½®ï¼‰ï¼š", messages.len());
    for (i, msg) in messages.iter().enumerate() {
        let role_str = match msg.role {
            MessageRole::User => "ç”¨æˆ·".bright_blue(),
            MessageRole::Assistant => "åŠ©æ‰‹".bright_green(),
            _ => "ç³»ç»Ÿ".bright_yellow(),
        };
        println!("  {}. {}: {}", i + 1, role_str, msg.content.bright_white());
    }

    // æ„å»ºå¯¹è¯æ–‡æœ¬
    let conversation = messages
        .iter()
        .map(|msg| {
            let role = match msg.role {
                MessageRole::User => "ç”¨æˆ·",
                MessageRole::Assistant => "åŠ©æ‰‹",
                _ => "ç³»ç»Ÿ",
            };
            format!("{}: {}", role, msg.content)
        })
        .collect::<Vec<_>>()
        .join("\n");

    // æå–è®°å¿†
    println!("\nğŸ” æ­£åœ¨ä½¿ç”¨ LLM æå–è®°å¿†...");

    let extraction_prompt = format!(
        r#"ä»ä»¥ä¸‹å¯¹è¯ä¸­æå–é‡è¦çš„è®°å¿†ä¿¡æ¯ã€‚

å¯¹è¯å†…å®¹ï¼š
{}

é‡è¦ï¼šè¯·åªè¿”å› JSON æ•°ç»„ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ã€è§£é‡Šæˆ– Markdown æ ‡è®°ã€‚

æ¯ä¸ªè®°å¿†åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- content: è®°å¿†çš„å…·ä½“å†…å®¹
- type: episodicï¼ˆæƒ…èŠ‚ï¼‰ã€semanticï¼ˆè¯­ä¹‰ï¼‰æˆ– proceduralï¼ˆç¨‹åºï¼‰
- importance: 0.0-1.0 çš„åˆ†æ•°
- entities: å…³é”®å®ä½“åˆ—è¡¨
- relations: å®ä½“ä¹‹é—´çš„å…³ç³»åˆ—è¡¨

ç¤ºä¾‹æ ¼å¼ï¼š
[
  {{
    "content": "å¼ ä¸‰æ˜¯ä¸€å30å²çš„è½¯ä»¶å·¥ç¨‹å¸ˆ",
    "type": "semantic",
    "importance": 0.9,
    "entities": ["å¼ ä¸‰", "è½¯ä»¶å·¥ç¨‹å¸ˆ"],
    "relations": ["å¼ ä¸‰-èŒä¸š-è½¯ä»¶å·¥ç¨‹å¸ˆ"]
  }}
]
"#,
        conversation
    );

    let extraction_messages = vec![Message::user(&extraction_prompt)];
    let response = llm_provider.generate(&extraction_messages).await?;

    // è§£æå“åº”
    #[derive(Debug, serde::Deserialize)]
    struct ExtractedMemory {
        content: String,
        #[serde(rename = "type")]
        memory_type: String,
        importance: f32,
        entities: Vec<String>,
        relations: Vec<String>,
    }

    debug!("LLM åŸå§‹å“åº”:\n{}", response);

    // æ¸…ç†å“åº”å¹¶è§£æ
    let cleaned_response = clean_llm_response(&response);
    debug!("æ¸…ç†åçš„å“åº”:\n{}", cleaned_response);

    let extracted_memories: Vec<ExtractedMemory> = match serde_json::from_str(&cleaned_response) {
        Ok(memories) => {
            println!("âœ… JSON è§£ææˆåŠŸ");
            memories
        }
        Err(e) => {
            warn!("âš ï¸ JSON è§£æå¤±è´¥: {}", e);
            warn!("åŸå§‹å“åº”: {}", response);

            // å°è¯•ä»å“åº”ä¸­æå– JSON éƒ¨åˆ†
            if let Some(start) = response.find('[') {
                if let Some(end) = response.rfind(']') {
                    let json_part = &response[start..=end];
                    debug!("å°è¯•æå–çš„ JSON éƒ¨åˆ†:\n{}", json_part);

                    if let Ok(memories) = serde_json::from_str::<Vec<ExtractedMemory>>(json_part) {
                        println!("âœ… ä»å“åº”ä¸­æˆåŠŸæå– JSON");
                        memories
                    } else {
                        warn!("âŒ æ— æ³•è§£æ JSONï¼Œä½¿ç”¨é™çº§æ•°æ®");
                        vec![ExtractedMemory {
                            content: "ä»å¯¹è¯ä¸­æå–çš„è®°å¿†ï¼ˆé™çº§ï¼‰".to_string(),
                            memory_type: "semantic".to_string(),
                            importance: 0.7,
                            entities: vec!["å¼ ä¸‰".to_string()],
                            relations: vec![],
                        }]
                    }
                } else {
                    warn!("âŒ æ— æ³•æ‰¾åˆ° JSON ç»“æŸæ ‡è®°ï¼Œä½¿ç”¨é™çº§æ•°æ®");
                    vec![]
                }
            } else {
                warn!("âŒ æ— æ³•æ‰¾åˆ° JSON å¼€å§‹æ ‡è®°ï¼Œä½¿ç”¨é™çº§æ•°æ®");
                vec![]
            }
        }
    };

    println!("\nâœ… æå–ç»“æœï¼š");
    println!(
        "  â€¢ æå–çš„è®°å¿†æ•°é‡: {}",
        extracted_memories.len().to_string().bright_cyan()
    );

    for (i, memory) in extracted_memories.iter().enumerate() {
        println!("\n  è®°å¿† {}:", i + 1);
        println!("    å†…å®¹: {}", memory.content.bright_white());
        println!("    ç±»å‹: {}", memory.memory_type);
        println!("    é‡è¦æ€§: {:.2}", memory.importance);
        if !memory.entities.is_empty() {
            println!("    å®ä½“: {:?}", memory.entities);
        }
        if !memory.relations.is_empty() {
            println!("    å…³ç³»: {:?}", memory.relations);
        }
    }

    Ok(())
}

/// æ¼”ç¤º 2: è®°å¿†è´¨é‡è¯„ä¼°
async fn demo_2_memory_quality_assessment(
    llm_provider: &Arc<dyn LLMProvider + Send + Sync>,
) -> anyhow::Result<()> {
    println!("{}", "\nğŸ“Š æ¼”ç¤º 2: è®°å¿†è´¨é‡è¯„ä¼°".bright_yellow().bold());
    println!("{}", "â”€".repeat(60).bright_black());

    // åˆ›å»ºæµ‹è¯•è®°å¿†
    let test_memories = vec![
        ("æˆ‘å–œæ¬¢åƒæŠ«è¨", 0.3, "ä½è´¨é‡ï¼šä¿¡æ¯è¿‡äºç®€å•"),
        (
            "å¼ ä¸‰æ˜¯ä¸€å30å²çš„è½¯ä»¶å·¥ç¨‹å¸ˆï¼Œåœ¨åŒ—äº¬å·¥ä½œï¼Œä¸»è¦ä»äº‹ Rust åç«¯å¼€å‘",
            0.9,
            "é«˜è´¨é‡ï¼šä¿¡æ¯ä¸°å¯Œä¸”å…·ä½“",
        ),
        ("ä»Šå¤©å¤©æ°”ä¸é”™", 0.2, "ä½è´¨é‡ï¼šç¼ºä¹ä¸Šä¸‹æ–‡"),
        (
            "ç”¨æˆ·åå¥½ä½¿ç”¨ Rust è¿›è¡Œç³»ç»Ÿç¼–ç¨‹ï¼Œå› ä¸ºå®ƒæä¾›å†…å­˜å®‰å…¨ä¿è¯ä¸”æ€§èƒ½ä¼˜å¼‚",
            0.8,
            "é«˜è´¨é‡ï¼šåŒ…å«åŸå› å’Œç»†èŠ‚",
        ),
    ];

    println!("ğŸ“ è¯„ä¼° {} æ¡è®°å¿†çš„è´¨é‡ï¼š\n", test_memories.len());

    let mut total_score = 0.0;
    let mut high_quality_count = 0;

    for (i, (content, expected_score, description)) in test_memories.iter().enumerate() {
        println!("  è®°å¿† {}: {}", i + 1, content.bright_white());

        // ä½¿ç”¨ LLM è¯„ä¼°è´¨é‡
        let assessment_prompt = format!(
            r#"è¯·è¯„ä¼°ä»¥ä¸‹è®°å¿†çš„è´¨é‡ï¼ˆ0.0-1.0åˆ†ï¼‰ã€‚

è®°å¿†å†…å®¹ï¼š"{}"

è¯„ä¼°æ ‡å‡†ï¼š
1. ä¿¡æ¯å®Œæ•´æ€§ï¼ˆæ˜¯å¦åŒ…å«è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡ï¼‰
2. å…·ä½“æ€§ï¼ˆæ˜¯å¦å…·ä½“è€Œéæ³›æ³›è€Œè°ˆï¼‰
3. å¯æ“ä½œæ€§ï¼ˆæ˜¯å¦å¯¹æœªæ¥å†³ç­–æœ‰å¸®åŠ©ï¼‰
4. å‡†ç¡®æ€§ï¼ˆä¿¡æ¯æ˜¯å¦å‡†ç¡®å¯é ï¼‰

é‡è¦ï¼šè¯·åªè¿”å› JSON æ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—æˆ– Markdown æ ‡è®°ã€‚

æ ¼å¼ï¼š
{{
  "quality_score": 0.85,
  "reasoning": "è¯„ä¼°ç†ç”±"
}}
"#,
            content
        );

        let messages = vec![Message::user(&assessment_prompt)];
        let response = llm_provider.generate(&messages).await?;

        debug!("è´¨é‡è¯„ä¼° LLM å“åº”:\n{}", response);

        // æ¸…ç†å¹¶è§£æå“åº”
        let cleaned_response = clean_llm_response(&response);

        let quality_score = match serde_json::from_str::<serde_json::Value>(&cleaned_response) {
            Ok(json) => {
                let score = json["quality_score"]
                    .as_f64()
                    .unwrap_or(*expected_score as f64) as f32;
                debug!("âœ… æˆåŠŸè§£æè´¨é‡åˆ†æ•°: {}", score);
                score
            }
            Err(e) => {
                warn!("âš ï¸ JSON è§£æå¤±è´¥: {}", e);

                // å°è¯•ä»å“åº”ä¸­æå– JSON
                if let Some(start) = response.find('{') {
                    if let Some(end) = response.rfind('}') {
                        let json_part = &response[start..=end];
                        if let Ok(json) = serde_json::from_str::<serde_json::Value>(json_part) {
                            let score = json["quality_score"]
                                .as_f64()
                                .unwrap_or(*expected_score as f64)
                                as f32;
                            debug!("âœ… ä»å“åº”ä¸­æˆåŠŸæå–è´¨é‡åˆ†æ•°: {}", score);
                            score
                        } else {
                            warn!("âŒ ä½¿ç”¨é¢„æœŸåˆ†æ•°ä½œä¸ºé™çº§: {}", expected_score);
                            *expected_score
                        }
                    } else {
                        warn!("âŒ ä½¿ç”¨é¢„æœŸåˆ†æ•°ä½œä¸ºé™çº§: {}", expected_score);
                        *expected_score
                    }
                } else {
                    warn!("âŒ ä½¿ç”¨é¢„æœŸåˆ†æ•°ä½œä¸ºé™çº§: {}", expected_score);
                    *expected_score
                }
            }
        };

        total_score += quality_score;
        if quality_score > 0.7 {
            high_quality_count += 1;
        }

        println!("    é¢„æœŸåˆ†æ•°: {:.2}", expected_score);
        println!("    LLM è¯„åˆ†: {:.2}", quality_score);
        println!("    è¯´æ˜: {}", description.bright_black());
        println!();
    }

    let avg_score = total_score / test_memories.len() as f32;
    println!("âœ… è¯„ä¼°ç»Ÿè®¡ï¼š");
    println!(
        "  â€¢ å¹³å‡è´¨é‡åˆ†æ•°: {:.2}",
        avg_score.to_string().bright_cyan()
    );
    println!(
        "  â€¢ é«˜è´¨é‡è®°å¿†æ•°: {}/{}",
        high_quality_count.to_string().bright_green(),
        test_memories.len()
    );
    println!(
        "  â€¢ é«˜è´¨é‡æ¯”ä¾‹: {:.1}%",
        (high_quality_count as f32 / test_memories.len() as f32 * 100.0)
            .to_string()
            .bright_cyan()
    );

    Ok(())
}

/// æ¼”ç¤º 3: æ£€ç´¢æ•ˆæœåˆ†æ
async fn demo_3_retrieval_effectiveness(
    llm_provider: &Arc<dyn LLMProvider + Send + Sync>,
) -> anyhow::Result<()> {
    println!("{}", "\nğŸ“Š æ¼”ç¤º 3: æ£€ç´¢æ•ˆæœåˆ†æ".bright_yellow().bold());
    println!("{}", "â”€".repeat(60).bright_black());

    // åˆ›å»ºè®°å¿†åº“
    let memories = vec![
        "å¼ ä¸‰æ˜¯ä¸€åè½¯ä»¶å·¥ç¨‹å¸ˆï¼Œä¸“æ³¨äº Rust å¼€å‘",
        "å¼ ä¸‰å–œæ¬¢é˜…è¯»æŠ€æœ¯ä¹¦ç±ï¼Œæœ€è¿‘åœ¨è¯»ã€ŠRust ç¨‹åºè®¾è®¡ã€‹",
        "å¼ ä¸‰åœ¨åŒ—äº¬å·¥ä½œï¼Œä»Šå¹´30å²",
        "å¼ ä¸‰çš„çˆ±å¥½åŒ…æ‹¬ç¼–ç¨‹ã€é˜…è¯»å’Œè·‘æ­¥",
        "å¼ ä¸‰æœ€å–œæ¬¢çš„ç¼–ç¨‹è¯­è¨€æ˜¯ Rustï¼Œå› ä¸ºå®ƒå®‰å…¨é«˜æ•ˆ",
    ];

    println!("ğŸ“š è®°å¿†åº“ï¼ˆ{} æ¡è®°å¿†ï¼‰ï¼š", memories.len());
    for (i, memory) in memories.iter().enumerate() {
        println!("  {}. {}", i + 1, memory.bright_white());
    }

    // æµ‹è¯•æŸ¥è¯¢
    let queries = vec![
        ("å¼ ä¸‰çš„èŒä¸šæ˜¯ä»€ä¹ˆï¼Ÿ", vec![0]),
        ("å¼ ä¸‰å–œæ¬¢ä»€ä¹ˆç¼–ç¨‹è¯­è¨€ï¼Ÿ", vec![4, 0]),
        ("å¼ ä¸‰çš„ä¸ªäººä¿¡æ¯", vec![2, 0, 3]),
    ];

    println!("\nğŸ” æµ‹è¯•æŸ¥è¯¢ï¼š\n");

    let mut total_accuracy = 0.0;

    for (query, expected_indices) in queries.iter() {
        println!("  æŸ¥è¯¢: {}", query.bright_cyan());

        // ä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½æ£€ç´¢
        let retrieval_prompt = format!(
            r#"ä»ä»¥ä¸‹è®°å¿†ä¸­é€‰æ‹©ä¸æŸ¥è¯¢æœ€ç›¸å…³çš„è®°å¿†ã€‚

æŸ¥è¯¢ï¼š"{}"

è®°å¿†åˆ—è¡¨ï¼š
{}

é‡è¦ï¼šè¯·åªè¿”å› JSON æ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—æˆ– Markdown æ ‡è®°ã€‚

è¿”å›æ ¼å¼ï¼š
{{
  "relevant_indices": [0, 1, 2],
  "reasoning": "é€‰æ‹©ç†ç”±"
}}

å…¶ä¸­ relevant_indices æ˜¯ç›¸å…³è®°å¿†çš„ç´¢å¼•æ•°ç»„ï¼ˆä»0å¼€å§‹ï¼‰ï¼ŒæŒ‰ç›¸å…³æ€§ä»é«˜åˆ°ä½æ’åºã€‚
"#,
            query,
            memories
                .iter()
                .enumerate()
                .map(|(i, m)| format!("{}. {}", i, m))
                .collect::<Vec<_>>()
                .join("\n")
        );

        let messages = vec![Message::user(&retrieval_prompt)];
        let response = llm_provider.generate(&messages).await?;

        debug!("æ£€ç´¢ LLM å“åº”:\n{}", response);

        // æ¸…ç†å¹¶è§£æå“åº”
        let cleaned_response = clean_llm_response(&response);

        let retrieved_indices = match serde_json::from_str::<serde_json::Value>(&cleaned_response) {
            Ok(json) => {
                if let Some(arr) = json["relevant_indices"].as_array() {
                    let indices: Vec<usize> = arr
                        .iter()
                        .filter_map(|v| v.as_u64().map(|n| n as usize))
                        .collect();
                    debug!("âœ… æˆåŠŸè§£ææ£€ç´¢ç´¢å¼•: {:?}", indices);
                    indices
                } else {
                    warn!("âš ï¸ relevant_indices ä¸æ˜¯æ•°ç»„ï¼Œä½¿ç”¨é¢„æœŸç´¢å¼•");
                    expected_indices.clone()
                }
            }
            Err(e) => {
                warn!("âš ï¸ JSON è§£æå¤±è´¥: {}", e);

                // å°è¯•ä»å“åº”ä¸­æå– JSON
                if let Some(start) = response.find('{') {
                    if let Some(end) = response.rfind('}') {
                        let json_part = &response[start..=end];
                        if let Ok(json) = serde_json::from_str::<serde_json::Value>(json_part) {
                            if let Some(arr) = json["relevant_indices"].as_array() {
                                let indices: Vec<usize> = arr
                                    .iter()
                                    .filter_map(|v| v.as_u64().map(|n| n as usize))
                                    .collect();
                                debug!("âœ… ä»å“åº”ä¸­æˆåŠŸæå–æ£€ç´¢ç´¢å¼•: {:?}", indices);
                                indices
                            } else {
                                warn!("âŒ ä½¿ç”¨é¢„æœŸç´¢å¼•ä½œä¸ºé™çº§");
                                expected_indices.clone()
                            }
                        } else {
                            warn!("âŒ ä½¿ç”¨é¢„æœŸç´¢å¼•ä½œä¸ºé™çº§");
                            expected_indices.clone()
                        }
                    } else {
                        warn!("âŒ ä½¿ç”¨é¢„æœŸç´¢å¼•ä½œä¸ºé™çº§");
                        expected_indices.clone()
                    }
                } else {
                    warn!("âŒ ä½¿ç”¨é¢„æœŸç´¢å¼•ä½œä¸ºé™çº§");
                    expected_indices.clone()
                }
            }
        };

        // è®¡ç®—å‡†ç¡®ç‡
        let correct_count = retrieved_indices
            .iter()
            .filter(|idx| expected_indices.contains(idx))
            .count();
        let accuracy = correct_count as f32 / expected_indices.len().max(1) as f32;
        total_accuracy += accuracy;

        println!("    é¢„æœŸç´¢å¼•: {:?}", expected_indices);
        println!("    æ£€ç´¢ç´¢å¼•: {:?}", retrieved_indices);
        println!(
            "    å‡†ç¡®ç‡: {:.1}%",
            (accuracy * 100.0).to_string().bright_green()
        );
        println!();
    }

    let avg_accuracy = total_accuracy / queries.len() as f32;
    println!("âœ… æ£€ç´¢ç»Ÿè®¡ï¼š");
    println!(
        "  â€¢ å¹³å‡å‡†ç¡®ç‡: {:.1}%",
        (avg_accuracy * 100.0).to_string().bright_cyan()
    );
    println!("  â€¢ æµ‹è¯•æŸ¥è¯¢æ•°: {}", queries.len());

    Ok(())
}

/// æ¼”ç¤º 4: è®°å¿†èåˆ
async fn demo_4_memory_fusion(
    llm_provider: &Arc<dyn LLMProvider + Send + Sync>,
) -> anyhow::Result<()> {
    println!(
        "{}",
        "\nğŸ“Š æ¼”ç¤º 4: è®°å¿†èåˆå’Œå†²çªè§£å†³".bright_yellow().bold()
    );
    println!("{}", "â”€".repeat(60).bright_black());

    // åˆ›å»ºå†²çªçš„è®°å¿†å¯¹
    let conflict_pairs = vec![
        ("å¼ ä¸‰ä»Šå¹´30å²", "å¼ ä¸‰ä»Šå¹´31å²", "å¹´é¾„å†²çª"),
        (
            "å¼ ä¸‰å–œæ¬¢ Rust ç¼–ç¨‹",
            "å¼ ä¸‰æ˜¯ Rust ä¸“å®¶ï¼Œæœ‰5å¹´ç»éªŒ",
            "ä¿¡æ¯è¡¥å……",
        ),
        ("å¼ ä¸‰åœ¨åŒ—äº¬å·¥ä½œ", "å¼ ä¸‰åœ¨ä¸Šæµ·å·¥ä½œ", "åœ°ç‚¹å†²çª"),
    ];

    println!("ğŸ”„ æµ‹è¯• {} ç»„è®°å¿†èåˆï¼š\n", conflict_pairs.len());

    let mut fusion_success = 0;

    for (i, (memory1, memory2, conflict_type)) in conflict_pairs.iter().enumerate() {
        println!("  èåˆ {}ï¼ˆ{}ï¼‰ï¼š", i + 1, conflict_type.bright_yellow());
        println!("    è®°å¿† A: {}", memory1.bright_white());
        println!("    è®°å¿† B: {}", memory2.bright_white());

        // ä½¿ç”¨ LLM è¿›è¡Œèåˆ
        let fusion_prompt = format!(
            r#"è¯·åˆ†æä»¥ä¸‹ä¸¤æ¡è®°å¿†å¹¶è¿›è¡Œèåˆã€‚

è®°å¿† Aï¼š"{}"
è®°å¿† Bï¼š"{}"

è¯·åˆ¤æ–­ï¼š
1. æ˜¯å¦å­˜åœ¨å†²çªï¼Ÿ
2. å¦‚ä½•èåˆè¿™ä¸¤æ¡è®°å¿†ï¼Ÿ
3. èåˆåçš„è®°å¿†å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ

é‡è¦ï¼šè¯·åªè¿”å› JSON æ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—æˆ– Markdown æ ‡è®°ã€‚

æ ¼å¼ï¼š
{{
  "has_conflict": true,
  "conflict_type": "å†²çªç±»å‹",
  "fused_memory": "èåˆåçš„è®°å¿†",
  "reasoning": "èåˆç†ç”±"
}}
"#,
            memory1, memory2
        );

        let messages = vec![Message::user(&fusion_prompt)];
        let response = llm_provider.generate(&messages).await?;

        debug!("èåˆ LLM å“åº”:\n{}", response);

        // æ¸…ç†å¹¶è§£æå“åº”
        let cleaned_response = clean_llm_response(&response);

        match serde_json::from_str::<serde_json::Value>(&cleaned_response) {
            Ok(json) => {
                let has_conflict = json["has_conflict"].as_bool().unwrap_or(false);
                let fused_memory = json["fused_memory"].as_str().unwrap_or("èåˆå¤±è´¥");
                let reasoning = json["reasoning"].as_str().unwrap_or("æ— ");

                println!(
                    "    å†²çªæ£€æµ‹: {}",
                    if has_conflict {
                        "æ˜¯".bright_red()
                    } else {
                        "å¦".bright_green()
                    }
                );
                println!("    èåˆç»“æœ: {}", fused_memory.bright_cyan());
                println!("    èåˆç†ç”±: {}", reasoning.bright_black());

                if !fused_memory.is_empty() && fused_memory != "èåˆå¤±è´¥" {
                    fusion_success += 1;
                }
            }
            Err(e) => {
                warn!("âš ï¸ JSON è§£æå¤±è´¥: {}", e);

                // å°è¯•ä»å“åº”ä¸­æå– JSON
                if let Some(start) = response.find('{') {
                    if let Some(end) = response.rfind('}') {
                        let json_part = &response[start..=end];
                        if let Ok(json) = serde_json::from_str::<serde_json::Value>(json_part) {
                            let has_conflict = json["has_conflict"].as_bool().unwrap_or(false);
                            let fused_memory = json["fused_memory"].as_str().unwrap_or("èåˆå¤±è´¥");
                            let reasoning = json["reasoning"].as_str().unwrap_or("æ— ");

                            println!(
                                "    å†²çªæ£€æµ‹: {}",
                                if has_conflict {
                                    "æ˜¯".bright_red()
                                } else {
                                    "å¦".bright_green()
                                }
                            );
                            println!("    èåˆç»“æœ: {}", fused_memory.bright_cyan());
                            println!("    èåˆç†ç”±: {}", reasoning.bright_black());

                            if !fused_memory.is_empty() && fused_memory != "èåˆå¤±è´¥" {
                                fusion_success += 1;
                            }
                        } else {
                            println!("    èåˆå¤±è´¥: æ— æ³•è§£æ LLM å“åº”");
                        }
                    } else {
                        println!("    èåˆå¤±è´¥: æ— æ³•è§£æ LLM å“åº”");
                    }
                } else {
                    println!("    èåˆå¤±è´¥: æ— æ³•è§£æ LLM å“åº”");
                }
            }
        }
        println!();
    }

    let success_rate = fusion_success as f32 / conflict_pairs.len() as f32;
    println!("âœ… èåˆç»Ÿè®¡ï¼š");
    println!(
        "  â€¢ èåˆæˆåŠŸç‡: {:.1}%",
        (success_rate * 100.0).to_string().bright_cyan()
    );
    println!(
        "  â€¢ æˆåŠŸèåˆæ•°: {}/{}",
        fusion_success.to_string().bright_green(),
        conflict_pairs.len()
    );

    Ok(())
}

/// æ¼”ç¤º 5: é•¿æœŸè®°å¿†æ•ˆæœè¿½è¸ª
async fn demo_5_long_term_tracking(
    llm_provider: &Arc<dyn LLMProvider + Send + Sync>,
) -> anyhow::Result<()> {
    println!("{}", "\nğŸ“Š æ¼”ç¤º 5: é•¿æœŸè®°å¿†æ•ˆæœè¿½è¸ª".bright_yellow().bold());
    println!("{}", "â”€".repeat(60).bright_black());

    // æ¨¡æ‹Ÿä¸åŒæ—¶é—´ç‚¹çš„è®°å¿†è®¿é—®
    let memory_timeline = vec![
        ("å¼ ä¸‰æ˜¯è½¯ä»¶å·¥ç¨‹å¸ˆ", 0, 10, "åˆå§‹è®°å¿†ï¼Œé«˜è®¿é—®é¢‘ç‡"),
        ("å¼ ä¸‰å–œæ¬¢ Rust", 7, 5, "ä¸€å‘¨åçš„è®°å¿†ï¼Œä¸­ç­‰è®¿é—®"),
        ("å¼ ä¸‰åœ¨åŒ—äº¬å·¥ä½œ", 30, 2, "ä¸€ä¸ªæœˆåçš„è®°å¿†ï¼Œä½è®¿é—®"),
    ];

    println!("ğŸ“ˆ åˆ†æ {} æ¡è®°å¿†çš„é•¿æœŸæ•ˆæœï¼š\n", memory_timeline.len());

    for (content, days_ago, access_count, description) in memory_timeline.iter() {
        println!("  è®°å¿†: {}", content.bright_white());
        println!("    åˆ›å»ºæ—¶é—´: {} å¤©å‰", days_ago);
        println!("    è®¿é—®æ¬¡æ•°: {}", access_count);
        println!("    è¯´æ˜: {}", description.bright_black());

        // ä½¿ç”¨ LLM è¯„ä¼°è®°å¿†è¡°å‡
        let decay_prompt = format!(
            r#"è¯„ä¼°ä»¥ä¸‹è®°å¿†çš„é•¿æœŸä¿ç•™ä»·å€¼ï¼š

è®°å¿†å†…å®¹ï¼š"{}"
åˆ›å»ºæ—¶é—´ï¼š{} å¤©å‰
è®¿é—®æ¬¡æ•°ï¼š{}

è¯·è¯„ä¼°ï¼š
1. å½“å‰é‡è¦æ€§ï¼ˆ0.0-1.0ï¼‰
2. é¢„æµ‹çš„è¡°å‡ç‡ï¼ˆ0.0-1.0ï¼Œè¶Šé«˜è¡°å‡è¶Šå¿«ï¼‰
3. æ˜¯å¦åº”è¯¥ä¿ç•™

è¯·è¿”å› JSON æ ¼å¼ï¼š
{{
  "current_importance": 0.0-1.0,
  "decay_rate": 0.0-1.0,
  "should_retain": true/false,
  "reasoning": "è¯„ä¼°ç†ç”±"
}}
"#,
            content, days_ago, access_count
        );

        let messages = vec![Message::user(&decay_prompt)];
        let response = llm_provider.generate(&messages).await?;

        // è§£æå“åº”
        if let Ok(json) = serde_json::from_str::<serde_json::Value>(&response) {
            let importance = json["current_importance"].as_f64().unwrap_or(0.5);
            let decay_rate = json["decay_rate"].as_f64().unwrap_or(0.5);
            let should_retain = json["should_retain"].as_bool().unwrap_or(true);

            println!(
                "    å½“å‰é‡è¦æ€§: {:.2}",
                importance.to_string().bright_cyan()
            );
            println!("    è¡°å‡ç‡: {:.2}", decay_rate.to_string().bright_yellow());
            println!(
                "    ä¿ç•™å»ºè®®: {}",
                if should_retain {
                    "ä¿ç•™".bright_green()
                } else {
                    "åˆ é™¤".bright_red()
                }
            );
        }
        println!();
    }

    Ok(())
}

/// æ¼”ç¤º 6: ç»¼åˆåˆ†æ
async fn demo_6_comprehensive_analysis(
    llm_provider: &Arc<dyn LLMProvider + Send + Sync>,
) -> anyhow::Result<()> {
    println!("{}", "\nğŸ“Š æ¼”ç¤º 6: ç»¼åˆè®°å¿†æ•ˆæœåˆ†æ".bright_yellow().bold());
    println!("{}", "â”€".repeat(60).bright_black());

    // åˆ›å»ºç»¼åˆè®°å¿†é›†
    let comprehensive_memories = vec![
        ("å¼ ä¸‰æ˜¯ä¸€å30å²çš„è½¯ä»¶å·¥ç¨‹å¸ˆ", MemoryType::Semantic, 0.9, 15),
        (
            "å¼ ä¸‰åœ¨2024å¹´1æœˆ15æ—¥å‚åŠ äº†æŠ€æœ¯ä¼šè®®",
            MemoryType::Episodic,
            0.7,
            3,
        ),
        (
            "ä½¿ç”¨ Rust å¼€å‘æ—¶åº”è¯¥æ³¨æ„å†…å­˜å®‰å…¨",
            MemoryType::Procedural,
            0.8,
            8,
        ),
        ("å¼ ä¸‰å–œæ¬¢é˜…è¯»æŠ€æœ¯ä¹¦ç±", MemoryType::Semantic, 0.6, 5),
        ("å¼ ä¸‰æ˜¨å¤©å®Œæˆäº†é¡¹ç›®é‡Œç¨‹ç¢‘", MemoryType::Episodic, 0.5, 1),
    ];

    println!("ğŸ“š åˆ†æ {} æ¡ç»¼åˆè®°å¿†ï¼š\n", comprehensive_memories.len());

    // ç»Ÿè®¡ä¿¡æ¯
    let mut type_distribution: HashMap<String, usize> = HashMap::new();
    let mut total_importance = 0.0;
    let mut total_access = 0;

    for (_content, mem_type, importance, access_count) in comprehensive_memories.iter() {
        let type_str = format!("{:?}", mem_type);
        *type_distribution.entry(type_str).or_insert(0) += 1;
        total_importance += importance;
        total_access += access_count;
    }

    let avg_importance = total_importance / comprehensive_memories.len() as f32;
    let avg_access = total_access as f32 / comprehensive_memories.len() as f32;

    println!("âœ… ç»¼åˆç»Ÿè®¡ï¼š");
    println!(
        "  â€¢ æ€»è®°å¿†æ•°: {}",
        comprehensive_memories.len().to_string().bright_cyan()
    );
    println!(
        "  â€¢ å¹³å‡é‡è¦æ€§: {:.2}",
        avg_importance.to_string().bright_cyan()
    );
    println!(
        "  â€¢ å¹³å‡è®¿é—®æ¬¡æ•°: {:.1}",
        avg_access.to_string().bright_cyan()
    );
    println!("\n  è®°å¿†ç±»å‹åˆ†å¸ƒï¼š");
    for (mem_type, count) in type_distribution.iter() {
        let percentage = (*count as f32 / comprehensive_memories.len() as f32) * 100.0;
        println!(
            "    â€¢ {}: {} ({:.1}%)",
            mem_type.bright_white(),
            count,
            percentage.to_string().bright_green()
        );
    }

    // ä½¿ç”¨ LLM è¿›è¡Œç»¼åˆè¯„ä¼°
    println!("\nğŸ” LLM ç»¼åˆè¯„ä¼°ï¼š");

    let comprehensive_prompt = format!(
        r#"è¯·å¯¹ä»¥ä¸‹è®°å¿†ç³»ç»Ÿè¿›è¡Œç»¼åˆè¯„ä¼°ï¼š

è®°å¿†åˆ—è¡¨ï¼š
{}

ç»Ÿè®¡ä¿¡æ¯ï¼š
- æ€»è®°å¿†æ•°ï¼š{}
- å¹³å‡é‡è¦æ€§ï¼š{:.2}
- å¹³å‡è®¿é—®æ¬¡æ•°ï¼š{:.1}

è¯·è¯„ä¼°ï¼š
1. è®°å¿†ç³»ç»Ÿçš„æ•´ä½“å¥åº·åº¦ï¼ˆ0.0-1.0ï¼‰
2. è®°å¿†åˆ†å¸ƒæ˜¯å¦åˆç†
3. æ˜¯å¦å­˜åœ¨å†—ä½™æˆ–ä½è´¨é‡è®°å¿†
4. æ”¹è¿›å»ºè®®

è¯·è¿”å› JSON æ ¼å¼ï¼š
{{
  "health_score": 0.0-1.0,
  "distribution_quality": "è¯„ä»·",
  "redundancy_detected": true/false,
  "recommendations": ["å»ºè®®1", "å»ºè®®2"]
}}
"#,
        comprehensive_memories
            .iter()
            .enumerate()
            .map(|(i, (content, mem_type, importance, access))| {
                format!(
                    "{}. {} (ç±»å‹: {:?}, é‡è¦æ€§: {:.2}, è®¿é—®: {})",
                    i + 1,
                    content,
                    mem_type,
                    importance,
                    access
                )
            })
            .collect::<Vec<_>>()
            .join("\n"),
        comprehensive_memories.len(),
        avg_importance,
        avg_access
    );

    let messages = vec![Message::user(&comprehensive_prompt)];
    let response = llm_provider.generate(&messages).await?;

    // è§£æå“åº”
    if let Ok(json) = serde_json::from_str::<serde_json::Value>(&response) {
        let health_score = json["health_score"].as_f64().unwrap_or(0.7);
        let distribution_quality = json["distribution_quality"].as_str().unwrap_or("è‰¯å¥½");
        let redundancy = json["redundancy_detected"].as_bool().unwrap_or(false);

        println!(
            "  â€¢ ç³»ç»Ÿå¥åº·åº¦: {:.2}",
            health_score.to_string().bright_cyan()
        );
        println!("  â€¢ åˆ†å¸ƒè´¨é‡: {}", distribution_quality.bright_white());
        println!(
            "  â€¢ å†—ä½™æ£€æµ‹: {}",
            if redundancy {
                "å‘ç°å†—ä½™".bright_yellow()
            } else {
                "æ— å†—ä½™".bright_green()
            }
        );

        if let Some(recommendations) = json["recommendations"].as_array() {
            println!("\n  æ”¹è¿›å»ºè®®ï¼š");
            for (i, rec) in recommendations.iter().enumerate() {
                if let Some(rec_str) = rec.as_str() {
                    println!("    {}. {}", i + 1, rec_str.bright_white());
                }
            }
        }
    }

    Ok(())
}

/// åˆ›å»º LLM æä¾›å•†
async fn create_llm_provider() -> anyhow::Result<Arc<dyn LLMProvider + Send + Sync>> {
    // å°è¯•å¤šä¸ªæä¾›å•†é…ç½®
    let provider_configs = vec![
        // 1. DeepSeek (æ¨è - æ€§ä»·æ¯”é«˜)
        LLMConfig {
            provider: "deepseek".to_string(),
            model: "deepseek-chat".to_string(),
            api_key: std::env::var("DEEPSEEK_API_KEY").ok(),
            base_url: Some("https://api.deepseek.com".to_string()),
            temperature: Some(0.7),
            max_tokens: Some(4000),
            top_p: None,
            frequency_penalty: None,
            presence_penalty: None,
            response_format: None,
        },
        // 2. Ollama (æœ¬åœ°)
        LLMConfig {
            provider: "ollama".to_string(),
            model: "llama3.2:3b".to_string(),
            api_key: None,
            base_url: Some("http://localhost:11434".to_string()),
            temperature: Some(0.7),
            max_tokens: Some(4000),
            top_p: None,
            frequency_penalty: None,
            presence_penalty: None,
            response_format: None,
        },
        // 3. OpenAI
        LLMConfig {
            provider: "openai".to_string(),
            model: "gpt-3.5-turbo".to_string(),
            api_key: std::env::var("OPENAI_API_KEY").ok(),
            base_url: None,
            temperature: Some(0.7),
            max_tokens: Some(4000),
            top_p: None,
            frequency_penalty: None,
            presence_penalty: None,
            response_format: None,
        },
    ];

    for config in provider_configs {
        // è·³è¿‡æ²¡æœ‰ API key çš„é…ç½®
        if config.provider != "ollama" && config.api_key.is_none() {
            continue;
        }

        match RealLLMFactory::create_with_fallback(&config).await {
            Ok(provider) => {
                info!("âœ… æˆåŠŸåˆ›å»º LLM æä¾›å•†: {}", config.provider);
                return Ok(provider);
            }
            Err(e) => {
                warn!("âš ï¸ åˆ›å»º {} æä¾›å•†å¤±è´¥: {}", config.provider, e);
                continue;
            }
        }
    }

    Err(anyhow::anyhow!(
        "æ— æ³•åˆ›å»ºä»»ä½• LLM æä¾›å•†ã€‚è¯·ç¡®ä¿ï¼š\n\
         1. è®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡ï¼Œæˆ–\n\
         2. å¯åŠ¨æœ¬åœ° Ollama æœåŠ¡ï¼ˆhttp://localhost:11434ï¼‰ï¼Œæˆ–\n\
         3. è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡"
    ))
}
