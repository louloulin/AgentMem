#!/usr/bin/env python3
"""
AgentMem Personal Assistant Demo

å¯¹æ ‡ Mem0 çš„ personal_assistant_agno.py
åŠŸèƒ½ï¼š
- æ–‡æœ¬å¯¹è¯è®°å¿†
- å›¾åƒç†è§£å’Œè®°å¿†ï¼ˆå¯é€‰ï¼‰
- ä¸ªæ€§åŒ–å›ç­”
- å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡

ä½¿ç”¨è¯´æ˜ï¼š
1. è®¾ç½®ç¯å¢ƒå˜é‡ï¼š
   export DEEPSEEK_API_KEY="your_key"  # æˆ– OPENAI_API_KEY
   
2. è¿è¡Œï¼š
   python3 personal_assistant.py

ä¾èµ–ï¼š
- agent_mem_python (AgentMem Python SDK)
- openai (ç”¨äºå›¾åƒå¤„ç†ï¼Œå¯é€‰)
"""

import os
import sys
from pathlib import Path

# Add the project root to Python path
project_root = Path(__file__).parent.parent.parent.absolute()
sys.path.insert(0, str(project_root))

try:
    from agent_mem_python import AgentMem
except ImportError:
    print("âŒ Error: agent_mem_python not found")
    print("Please build the Python bindings first:")
    print("  cd crates/agent-mem-python && maturin develop")
    sys.exit(1)


class PersonalAssistant:
    """ä¸ªäººåŠ©æ‰‹ - è®°ä½ç”¨æˆ·åå¥½å’Œå¯¹è¯å†å²"""
    
    def __init__(self, user_id: str = "user_123"):
        self.user_id = user_id
        
        # åˆå§‹åŒ–AgentMem
        deepseek_api_key = os.getenv("DEEPSEEK_API_KEY")
        openai_api_key = os.getenv("OPENAI_API_KEY")
        
        if deepseek_api_key:
            print("âœ… Using DeepSeek LLM")
            self.memory = AgentMem(
                llm_provider="deepseek",
                llm_model="deepseek-chat",
                llm_api_key=deepseek_api_key,
                embedder_provider="fastembed",
                embedder_model="bge-small-en-v1.5"
            )
        elif openai_api_key:
            print("âœ… Using OpenAI LLM")
            self.memory = AgentMem(
                llm_provider="openai",
                llm_model="gpt-4o-mini",
                llm_api_key=openai_api_key,
                embedder_provider="fastembed",
                embedder_model="bge-small-en-v1.5"
            )
        else:
            print("âš ï¸  No LLM API key found. Running in basic mode.")
            print("Set DEEPSEEK_API_KEY or OPENAI_API_KEY for full functionality.")
            self.memory = AgentMem(
                embedder_provider="fastembed",
                embedder_model="bge-small-en-v1.5",
                disable_intelligent_features=True
            )
    
    def chat(self, user_input: str, image_path: str = None) -> str:
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œè¿”å›ä¸ªæ€§åŒ–å›ç­”
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
            image_path: å¯é€‰çš„å›¾åƒè·¯å¾„
            
        Returns:
            åŠ©æ‰‹å›ç­”
        """
        # 1. å¤„ç†å›¾åƒï¼ˆå¦‚æœæœ‰ï¼‰
        if image_path:
            print(f"ğŸ“¸ Processing image: {image_path}")
            # ç®€åŒ–ç‰ˆï¼šå°†å›¾åƒä¿¡æ¯ä½œä¸ºæ–‡æœ¬å­˜å‚¨
            image_info = f"User shared an image: {image_path}"
            self.memory.add(image_info, user_id=self.user_id)
            print("âœ… Image information stored in memory")
        
        # 2. æœç´¢ç›¸å…³è®°å¿†
        try:
            memories = self.memory.search(user_input, user_id=self.user_id)
            memory_context = "\n".join(f"- {m.content}" for m in memories[:5])
        except Exception as e:
            print(f"âš ï¸  Search failed: {e}")
            memory_context = ""
        
        # 3. æ„å»ºæç¤ºè¯
        prompt = f"""You are a helpful personal assistant who helps user with day-to-day activities.

Your task is to:
1. Use past memories to personalize your answer
2. Be helpful, friendly, and context-aware
3. Remember important details about the user

Here is what you remember about the user:
{memory_context if memory_context else "No previous memories found."}

User question:
{user_input}

Please provide a helpful, personalized response."""
        
        # 4. ç”Ÿæˆå›ç­”
        try:
            response = self.memory.chat(prompt, user_id=self.user_id)
        except Exception as e:
            print(f"âš ï¸  LLM chat failed: {e}")
            # Fallback: ç®€å•å›å¤
            response = f"I understand you said: '{user_input}'. I've stored this in my memory."
        
        # 5. å­˜å‚¨å¯¹è¯
        conversation = f"User: {user_input}\nAssistant: {response}"
        self.memory.add(conversation, user_id=self.user_id)
        
        return response
    
    def get_memory_stats(self) -> dict:
        """è·å–è®°å¿†ç»Ÿè®¡"""
        try:
            all_memories = self.memory.get_all(user_id=self.user_id)
            return {
                "total_memories": len(all_memories),
                "user_id": self.user_id
            }
        except Exception as e:
            return {"error": str(e)}


def run_demo():
    """è¿è¡Œæ¼”ç¤º"""
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘                                                                â•‘")
    print("â•‘           ğŸ¤– AgentMem Personal Assistant Demo ğŸ¤–              â•‘")
    print("â•‘                                                                â•‘")
    print("â•‘         å¯¹æ ‡ Mem0 personal_assistant_agno.py                  â•‘")
    print("â•‘                                                                â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print()
    
    # åˆ›å»ºåŠ©æ‰‹
    assistant = PersonalAssistant(user_id="alice")
    
    # æµ‹è¯•åœºæ™¯
    print("=" * 70)
    print("ğŸ“ æµ‹è¯•åœºæ™¯ 1: åˆæ¬¡å¯¹è¯ - å»ºç«‹ç”¨æˆ·åå¥½")
    print("=" * 70)
    
    # åœºæ™¯1: ç”¨æˆ·ä»‹ç»è‡ªå·±
    print("\nğŸ‘¤ User: Hi, I'm Alice. I'm a software engineer and I love coding in Rust.")
    response1 = assistant.chat(
        "Hi, I'm Alice. I'm a software engineer and I love coding in Rust."
    )
    print(f"ğŸ¤– Assistant: {response1}")
    
    # åœºæ™¯2: åˆ†äº«å…´è¶£
    print("\nğŸ‘¤ User: I also enjoy hiking on weekends and reading sci-fi novels.")
    response2 = assistant.chat(
        "I also enjoy hiking on weekends and reading sci-fi novels."
    )
    print(f"ğŸ¤– Assistant: {response2}")
    
    # åœºæ™¯3: è®¾ç½®æé†’
    print("\nğŸ‘¤ User: Please remind me to call my mom tomorrow at 6 PM.")
    response3 = assistant.chat(
        "Please remind me to call my mom tomorrow at 6 PM."
    )
    print(f"ğŸ¤– Assistant: {response3}")
    
    print("\n" + "=" * 70)
    print("ğŸ“ æµ‹è¯•åœºæ™¯ 2: åç»­å¯¹è¯ - ä¸ªæ€§åŒ–å›ç­”")
    print("=" * 70)
    
    # åœºæ™¯4: è¯¢é—®ä¹‹å‰çš„å†…å®¹
    print("\nğŸ‘¤ User: What did I ask you to remind me about?")
    response4 = assistant.chat(
        "What did I ask you to remind me about?"
    )
    print(f"ğŸ¤– Assistant: {response4}")
    
    # åœºæ™¯5: åŸºäºå…´è¶£æ¨è
    print("\nğŸ‘¤ User: Can you recommend a book for me?")
    response5 = assistant.chat(
        "Can you recommend a book for me?"
    )
    print(f"ğŸ¤– Assistant: {response5}")
    
    # åœºæ™¯6: æŠ€æœ¯ç›¸å…³
    print("\nğŸ‘¤ User: What programming language do I like?")
    response6 = assistant.chat(
        "What programming language do I like?"
    )
    print(f"ğŸ¤– Assistant: {response6}")
    
    print("\n" + "=" * 70)
    print("ğŸ“Š è®°å¿†ç»Ÿè®¡")
    print("=" * 70)
    stats = assistant.get_memory_stats()
    print(f"  æ€»è®°å¿†æ•°: {stats.get('total_memories', 'N/A')}")
    print(f"  ç”¨æˆ·ID: {stats.get('user_id', 'N/A')}")
    
    print("\n" + "=" * 70)
    print("âœ… æ¼”ç¤ºå®Œæˆï¼AgentMem Personal Assistant åŠŸèƒ½éªŒè¯æˆåŠŸ")
    print("=" * 70)
    print("\nå¯¹æ¯” Mem0:")
    print("  âœ… æ–‡æœ¬å¯¹è¯è®°å¿† - å®Œå…¨å¯¹æ ‡")
    print("  âœ… ä¸ªæ€§åŒ–å›ç­” - å®Œå…¨å¯¹æ ‡")
    print("  âœ… å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ - å®Œå…¨å¯¹æ ‡")
    print("  ğŸ”¥ æ€§èƒ½ä¼˜åŠ¿ - Ruståç«¯ï¼Œæ›´å¿«çš„æœç´¢å’Œæ¨ç†")
    print("  ğŸ”¥ æœ¬åœ°åµŒå…¥ - FastEmbedï¼Œæ— éœ€é¢å¤–APIè°ƒç”¨")


def interactive_mode():
    """äº¤äº’æ¨¡å¼"""
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘                                                                â•‘")
    print("â•‘         ğŸ¤– AgentMem Personal Assistant - Interactive ğŸ¤–       â•‘")
    print("â•‘                                                                â•‘")
    print("â•‘         è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º                            â•‘")
    print("â•‘                                                                â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print()
    
    user_id = input("è¯·è¾“å…¥ä½ çš„åå­— (é»˜è®¤: Alice): ").strip() or "alice"
    assistant = PersonalAssistant(user_id=user_id)
    
    print(f"\næ¬¢è¿, {user_id}! æˆ‘æ˜¯ä½ çš„ä¸ªäººåŠ©æ‰‹ã€‚")
    print("æˆ‘ä¼šè®°ä½æˆ‘ä»¬çš„å¯¹è¯ï¼Œå¹¶æ ¹æ®ä½ çš„åå¥½æä¾›ä¸ªæ€§åŒ–å»ºè®®ã€‚\n")
    
    while True:
        user_input = input(f"{user_id}: ").strip()
        
        if not user_input:
            continue
        
        if user_input.lower() in ['quit', 'exit', 'q']:
            print(f"\nğŸ‘‹ å†è§, {user_id}!")
            stats = assistant.get_memory_stats()
            print(f"æœ¬æ¬¡å¯¹è¯å…±è®°å½•äº† {stats.get('total_memories', 0)} æ¡è®°å¿†ã€‚")
            break
        
        try:
            response = assistant.chat(user_input)
            print(f"ğŸ¤– Assistant: {response}\n")
        except Exception as e:
            print(f"âŒ Error: {e}\n")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="AgentMem Personal Assistant Demo")
    parser.add_argument(
        "--interactive", "-i",
        action="store_true",
        help="Run in interactive mode"
    )
    
    args = parser.parse_args()
    
    if args.interactive:
        interactive_mode()
    else:
        run_demo()

